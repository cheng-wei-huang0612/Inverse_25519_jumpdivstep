
# qhasm: int64 input_0

# qhasm: int64 input_1

# qhasm: int64 input_2

# qhasm: int64 input_3

# qhasm: int64 input_4

# qhasm: int64 input_5

# qhasm: stack64 input_6

# qhasm: stack64 input_7

# qhasm: int64 caller_r11

# qhasm: int64 caller_r12

# qhasm: int64 caller_r13

# qhasm: int64 caller_r14

# qhasm: int64 caller_r15

# qhasm: int64 caller_rbx

# qhasm: int64 caller_rbp

# qhasm: int64 m

# qhasm: int64 f

# qhasm: int64 g

# qhasm: int64 u

# qhasm: int64 v

# qhasm: int64 r

# qhasm: int64 s

# qhasm: int64 uvrs

# qhasm: int64 fuv

# qhasm: int64 grs

# qhasm: int64 mnew

# qhasm: int64 z

# qhasm: int64 loop

# qhasm: int64 rax

# qhasm: int64 rdx

# qhasm: int64 h

# qhasm: int64 oldg

# qhasm: int64 i

# qhasm: int64 j

# qhasm: int64 f0

# qhasm: int64 g0

# qhasm: int64 table

# qhasm: int64 minv

# qhasm: stack64 stack_minv

# qhasm: int64 rtimesoldv

# qhasm: int64 stimesolds

# qhasm: stack64 stack_out

# qhasm: stack256 stack_m1

# qhasm: stack64 stack_m

# qhasm: stack256 stack_fxgx

# qhasm: stack256 stack_uuss

# qhasm: stack256 stack_vvrr

# qhasm: stack256 stack_fygy

# qhasm: stack64 stack_fuv

# qhasm: stack64 stack_f

# qhasm: reg256 carryy

# qhasm: reg256 minvx4

# qhasm: reg256 d0

# qhasm: reg256 d1

# qhasm: reg256 d2

# qhasm: reg256 out0

# qhasm: int64 a0

# qhasm: int64 t0

# qhasm: reg256 mod0

# qhasm: stack256 stack_mod0

# qhasm: reg256 FVGS0

# qhasm: reg256 GSFV0

# qhasm: stack256 stack_FVGS0

# qhasm: reg256 out1

# qhasm: reg256 out1plus

# qhasm: reg256 out2plus2

# qhasm: int64 a1

# qhasm: int64 t1

# qhasm: reg256 mod1

# qhasm: stack256 stack_mod1

# qhasm: reg256 FVGS1

# qhasm: reg256 GSFV1

# qhasm: stack256 stack_FVGS1

# qhasm: reg256 out2

# qhasm: reg256 out2plus

# qhasm: reg256 out3plus2

# qhasm: int64 a2

# qhasm: int64 t2

# qhasm: reg256 mod2

# qhasm: stack256 stack_mod2

# qhasm: reg256 FVGS2

# qhasm: reg256 GSFV2

# qhasm: stack256 stack_FVGS2

# qhasm: reg256 out3

# qhasm: reg256 out3plus

# qhasm: reg256 out4plus2

# qhasm: int64 a3

# qhasm: int64 t3

# qhasm: reg256 mod3

# qhasm: stack256 stack_mod3

# qhasm: reg256 FVGS3

# qhasm: reg256 GSFV3

# qhasm: stack256 stack_FVGS3

# qhasm: reg256 out4

# qhasm: reg256 out4plus

# qhasm: reg256 out5plus2

# qhasm: int64 a4

# qhasm: int64 t4

# qhasm: reg256 mod4

# qhasm: stack256 stack_mod4

# qhasm: reg256 FVGS4

# qhasm: reg256 GSFV4

# qhasm: stack256 stack_FVGS4

# qhasm: reg256 out5

# qhasm: reg256 out5plus

# qhasm: reg256 out6plus2

# qhasm: int64 a5

# qhasm: int64 t5

# qhasm: reg256 mod5

# qhasm: stack256 stack_mod5

# qhasm: reg256 FVGS5

# qhasm: reg256 GSFV5

# qhasm: stack256 stack_FVGS5

# qhasm: reg256 out6

# qhasm: reg256 out6plus

# qhasm: reg256 out7plus2

# qhasm: int64 a6

# qhasm: int64 t6

# qhasm: reg256 mod6

# qhasm: stack256 stack_mod6

# qhasm: reg256 FVGS6

# qhasm: reg256 GSFV6

# qhasm: stack256 stack_FVGS6

# qhasm: reg256 out7

# qhasm: reg256 out7plus

# qhasm: reg256 out8plus2

# qhasm: int64 a7

# qhasm: int64 t7

# qhasm: reg256 mod7

# qhasm: stack256 stack_mod7

# qhasm: reg256 FVGS7

# qhasm: reg256 GSFV7

# qhasm: stack256 stack_FVGS7

# qhasm: reg256 out8

# qhasm: reg256 out8plus

# qhasm: reg256 out9plus2

# qhasm: int64 a8

# qhasm: int64 t8

# qhasm: reg256 mod8

# qhasm: stack256 stack_mod8

# qhasm: reg256 FVGS8

# qhasm: reg256 GSFV8

# qhasm: stack256 stack_FVGS8

# qhasm: reg256 out9

# qhasm: reg256 out9plus

# qhasm: reg256 out10plus2

# qhasm: int64 a9

# qhasm: int64 t9

# qhasm: reg256 mod9

# qhasm: stack256 stack_mod9

# qhasm: reg256 FVGS9

# qhasm: reg256 GSFV9

# qhasm: stack256 stack_FVGS9

# qhasm: reg256 out10

# qhasm: reg256 out10plus

# qhasm: reg256 out11plus2

# qhasm: int64 a10

# qhasm: int64 t10

# qhasm: reg256 mod10

# qhasm: stack256 stack_mod10

# qhasm: reg256 FVGS10

# qhasm: reg256 GSFV10

# qhasm: stack256 stack_FVGS10

# qhasm: reg256 out11

# qhasm: reg256 out11plus

# qhasm: reg256 out12plus2

# qhasm: int64 a11

# qhasm: int64 t11

# qhasm: reg256 mod11

# qhasm: stack256 stack_mod11

# qhasm: reg256 FVGS11

# qhasm: reg256 GSFV11

# qhasm: stack256 stack_FVGS11

# qhasm: reg256 out12

# qhasm: reg256 out12plus

# qhasm: reg256 out13plus2

# qhasm: int64 a12

# qhasm: int64 t12

# qhasm: reg256 mod12

# qhasm: stack256 stack_mod12

# qhasm: reg256 FVGS12

# qhasm: reg256 GSFV12

# qhasm: stack256 stack_FVGS12

# qhasm: reg256 out13

# qhasm: reg256 out13plus

# qhasm: reg256 out14plus2

# qhasm: int64 a13

# qhasm: int64 t13

# qhasm: reg256 mod13

# qhasm: stack256 stack_mod13

# qhasm: reg256 FVGS13

# qhasm: reg256 GSFV13

# qhasm: stack256 stack_FVGS13

# qhasm: reg256 out14

# qhasm: reg256 out14plus

# qhasm: reg256 out15plus2

# qhasm: int64 a14

# qhasm: int64 t14

# qhasm: reg256 mod14

# qhasm: stack256 stack_mod14

# qhasm: reg256 FVGS14

# qhasm: reg256 GSFV14

# qhasm: stack256 stack_FVGS14

# qhasm: reg256 out15

# qhasm: reg256 out15plus

# qhasm: reg256 out16plus2

# qhasm: int64 a15

# qhasm: int64 t15

# qhasm: reg256 mod15

# qhasm: stack256 stack_mod15

# qhasm: reg256 FVGS15

# qhasm: reg256 GSFV15

# qhasm: stack256 stack_FVGS15

# qhasm: reg256 out16

# qhasm: reg256 out16plus

# qhasm: reg256 out17plus2

# qhasm: int64 a16

# qhasm: int64 t16

# qhasm: reg256 mod16

# qhasm: stack256 stack_mod16

# qhasm: reg256 FVGS16

# qhasm: reg256 GSFV16

# qhasm: stack256 stack_FVGS16

# qhasm: reg256 out17

# qhasm: reg256 out17plus

# qhasm: int64 a17

# qhasm: int64 t17

# qhasm: reg256 mod17

# qhasm: stack256 stack_mod17

# qhasm: reg256 FVGS17

# qhasm: reg256 GSFV17

# qhasm: stack256 stack_FVGS17

# qhasm: reg256 out18

# qhasm: reg256 out18plus

# qhasm: reg256 out19

# qhasm: reg256 out19plus

# qhasm: reg256 out20

# qhasm: reg256 ta

# qhasm: reg256 tb

# qhasm: reg256 uuss

# qhasm: reg256 uuss0

# qhasm: reg256 uuss1

# qhasm: reg256 vvrr

# qhasm: reg256 vvrr0

# qhasm: reg256 vvrr1

# qhasm: int64            _m2p20

# qhasm: stack64     stack_m2p20

# qhasm: int64             _2p20

# qhasm: stack64      stack_2p20

# qhasm: int64            _m2p41

# qhasm: stack64     stack_m2p41

# qhasm: int64            _m2p62

# qhasm: stack64     stack_m2p62

# qhasm: int64        _2p20a2p41

# qhasm: stack64 stack_2p20a2p41

# qhasm: reg256 _2p30m1x4

# qhasm: reg256 _2p33x4

# qhasm: reg256 _2p63x4

# qhasm: reg256 _2p63m2p33x4

# qhasm: reg256 _2p29x4

# qhasm: reg256 _prime0x4

# qhasm: reg256 _prime1x4

# qhasm: stack256 stack_2p30m1x4

# qhasm: stack256 stack_2p33x4

# qhasm: stack256 stack_2p63x4

# qhasm: stack256 stack_2p63m2p33x4

# qhasm: stack256 stack_2p29x4

# qhasm: stack256 stack_prime0x4

# qhasm: stack256 stack_prime1x4

# qhasm: enter inverse_511
.p2align 5
.global _inverse_511
.global inverse_511
_inverse_511:
inverse_511:
mov %rsp,%r11
and $31,%r11
add $1536,%r11
sub %r11,%rsp

# qhasm: new stack_m1

# qhasm: stack_out = input_1
# asm 1: movq <input_1=int64#2,>stack_out=stack64#1
# asm 2: movq <input_1=%rsi,>stack_out=0(%rsp)
movq %rsi,0(%rsp)

# qhasm: table = input_2
# asm 1: mov  <input_2=int64#3,>table=int64#2
# asm 2: mov  <input_2=%rdx,>table=%rsi
mov  %rdx,%rsi

# qhasm: stack64 stack_r11

# qhasm: stack_r11 = caller_r11
# asm 1: movq <caller_r11=int64#9,>stack_r11=stack64#2
# asm 2: movq <caller_r11=%r11,>stack_r11=8(%rsp)
movq %r11,8(%rsp)

# qhasm: stack64 stack_r12

# qhasm: stack_r12 = caller_r12
# asm 1: movq <caller_r12=int64#10,>stack_r12=stack64#3
# asm 2: movq <caller_r12=%r12,>stack_r12=16(%rsp)
movq %r12,16(%rsp)

# qhasm: stack64 stack_r13

# qhasm: stack_r13 = caller_r13
# asm 1: movq <caller_r13=int64#11,>stack_r13=stack64#4
# asm 2: movq <caller_r13=%r13,>stack_r13=24(%rsp)
movq %r13,24(%rsp)

# qhasm: stack64 stack_r14

# qhasm: stack_r14 = caller_r14
# asm 1: movq <caller_r14=int64#12,>stack_r14=stack64#5
# asm 2: movq <caller_r14=%r14,>stack_r14=32(%rsp)
movq %r14,32(%rsp)

# qhasm: stack64 stack_r15

# qhasm: stack_r15 = caller_r15
# asm 1: movq <caller_r15=int64#13,>stack_r15=stack64#6
# asm 2: movq <caller_r15=%r15,>stack_r15=40(%rsp)
movq %r15,40(%rsp)

# qhasm: stack64 stack_rbx

# qhasm: stack_rbx = caller_rbx
# asm 1: movq <caller_rbx=int64#14,>stack_rbx=stack64#7
# asm 2: movq <caller_rbx=%rbx,>stack_rbx=48(%rsp)
movq %rbx,48(%rsp)

# qhasm: stack64 stack_rbp

# qhasm: stack_rbp = caller_rbp
# asm 1: movq <caller_rbp=int64#15,>stack_rbp=stack64#8
# asm 2: movq <caller_rbp=%rbp,>stack_rbp=56(%rsp)
movq %rbp,56(%rsp)

# qhasm: d1 = mem256[ table + 224 ]
# asm 1: vmovupd   224(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   224(<table=%rsi),>d1=%ymm0
vmovupd   224(%rsi),%ymm0

# qhasm: stack_FVGS0 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS0=stack256#2
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS0=160(%rsp)
vmovapd %ymm0,160(%rsp)

# qhasm: d1 = mem256[ table + 256 ]
# asm 1: vmovupd   256(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   256(<table=%rsi),>d1=%ymm0
vmovupd   256(%rsi),%ymm0

# qhasm: stack_FVGS1 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS1=stack256#3
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS1=192(%rsp)
vmovapd %ymm0,192(%rsp)

# qhasm: d1 = mem256[ table + 288 ]
# asm 1: vmovupd   288(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   288(<table=%rsi),>d1=%ymm0
vmovupd   288(%rsi),%ymm0

# qhasm: stack_FVGS2 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS2=stack256#4
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS2=224(%rsp)
vmovapd %ymm0,224(%rsp)

# qhasm: d1 = mem256[ table + 320 ]
# asm 1: vmovupd   320(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   320(<table=%rsi),>d1=%ymm0
vmovupd   320(%rsi),%ymm0

# qhasm: stack_FVGS3 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS3=stack256#5
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS3=256(%rsp)
vmovapd %ymm0,256(%rsp)

# qhasm: d1 = mem256[ table + 352 ]
# asm 1: vmovupd   352(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   352(<table=%rsi),>d1=%ymm0
vmovupd   352(%rsi),%ymm0

# qhasm: stack_FVGS4 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS4=stack256#6
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS4=288(%rsp)
vmovapd %ymm0,288(%rsp)

# qhasm: d1 = mem256[ table + 384 ]
# asm 1: vmovupd   384(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   384(<table=%rsi),>d1=%ymm0
vmovupd   384(%rsi),%ymm0

# qhasm: stack_FVGS5 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS5=stack256#7
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS5=320(%rsp)
vmovapd %ymm0,320(%rsp)

# qhasm: d1 = mem256[ table + 416 ]
# asm 1: vmovupd   416(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   416(<table=%rsi),>d1=%ymm0
vmovupd   416(%rsi),%ymm0

# qhasm: stack_FVGS6 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS6=stack256#8
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS6=352(%rsp)
vmovapd %ymm0,352(%rsp)

# qhasm: d1 = mem256[ table + 448 ]
# asm 1: vmovupd   448(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   448(<table=%rsi),>d1=%ymm0
vmovupd   448(%rsi),%ymm0

# qhasm: stack_FVGS7 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS7=stack256#9
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS7=384(%rsp)
vmovapd %ymm0,384(%rsp)

# qhasm: d1 = mem256[ table + 480 ]
# asm 1: vmovupd   480(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   480(<table=%rsi),>d1=%ymm0
vmovupd   480(%rsi),%ymm0

# qhasm: stack_FVGS8 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS8=stack256#10
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS8=416(%rsp)
vmovapd %ymm0,416(%rsp)

# qhasm: d1 = mem256[ table + 512 ]
# asm 1: vmovupd   512(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   512(<table=%rsi),>d1=%ymm0
vmovupd   512(%rsi),%ymm0

# qhasm: stack_FVGS9 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS9=stack256#11
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS9=448(%rsp)
vmovapd %ymm0,448(%rsp)

# qhasm: d1 = mem256[ table + 544 ]
# asm 1: vmovupd   544(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   544(<table=%rsi),>d1=%ymm0
vmovupd   544(%rsi),%ymm0

# qhasm: stack_FVGS10 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS10=stack256#12
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS10=480(%rsp)
vmovapd %ymm0,480(%rsp)

# qhasm: d1 = mem256[ table + 576 ]
# asm 1: vmovupd   576(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   576(<table=%rsi),>d1=%ymm0
vmovupd   576(%rsi),%ymm0

# qhasm: stack_FVGS11 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS11=stack256#13
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS11=512(%rsp)
vmovapd %ymm0,512(%rsp)

# qhasm: d1 = mem256[ table + 608 ]
# asm 1: vmovupd   608(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   608(<table=%rsi),>d1=%ymm0
vmovupd   608(%rsi),%ymm0

# qhasm: stack_FVGS12 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS12=stack256#14
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS12=544(%rsp)
vmovapd %ymm0,544(%rsp)

# qhasm: d1 = mem256[ table + 640 ]
# asm 1: vmovupd   640(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   640(<table=%rsi),>d1=%ymm0
vmovupd   640(%rsi),%ymm0

# qhasm: stack_FVGS13 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS13=stack256#15
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS13=576(%rsp)
vmovapd %ymm0,576(%rsp)

# qhasm: d1 = mem256[ table + 672 ]
# asm 1: vmovupd   672(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   672(<table=%rsi),>d1=%ymm0
vmovupd   672(%rsi),%ymm0

# qhasm: stack_FVGS14 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS14=stack256#16
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS14=608(%rsp)
vmovapd %ymm0,608(%rsp)

# qhasm: d1 = mem256[ table + 704 ]
# asm 1: vmovupd   704(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   704(<table=%rsi),>d1=%ymm0
vmovupd   704(%rsi),%ymm0

# qhasm: stack_FVGS15 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS15=stack256#17
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS15=640(%rsp)
vmovapd %ymm0,640(%rsp)

# qhasm: d1 = mem256[ table + 736 ]
# asm 1: vmovupd   736(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   736(<table=%rsi),>d1=%ymm0
vmovupd   736(%rsi),%ymm0

# qhasm: stack_FVGS16 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS16=stack256#18
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS16=672(%rsp)
vmovapd %ymm0,672(%rsp)

# qhasm: d1 = mem256[ table + 768 ]
# asm 1: vmovupd   768(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   768(<table=%rsi),>d1=%ymm0
vmovupd   768(%rsi),%ymm0

# qhasm: stack_FVGS17 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS17=stack256#19
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS17=704(%rsp)
vmovapd %ymm0,704(%rsp)

# qhasm: d1 = 4x stack_FVGS0[0]
# asm 1: vpbroadcastq <stack_FVGS0=stack256#2,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS0=160(%rsp),>d1=%ymm0
vpbroadcastq 160(%rsp),%ymm0

# qhasm: stack_mod0 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod0=stack256#20
# asm 2: vmovapd <d1=%ymm0,>stack_mod0=736(%rsp)
vmovapd %ymm0,736(%rsp)

# qhasm: d1 = 4x stack_FVGS1[0]
# asm 1: vpbroadcastq <stack_FVGS1=stack256#3,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS1=192(%rsp),>d1=%ymm0
vpbroadcastq 192(%rsp),%ymm0

# qhasm: stack_mod1 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod1=stack256#21
# asm 2: vmovapd <d1=%ymm0,>stack_mod1=768(%rsp)
vmovapd %ymm0,768(%rsp)

# qhasm: d1 = 4x stack_FVGS2[0]
# asm 1: vpbroadcastq <stack_FVGS2=stack256#4,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS2=224(%rsp),>d1=%ymm0
vpbroadcastq 224(%rsp),%ymm0

# qhasm: stack_mod2 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod2=stack256#22
# asm 2: vmovapd <d1=%ymm0,>stack_mod2=800(%rsp)
vmovapd %ymm0,800(%rsp)

# qhasm: d1 = 4x stack_FVGS3[0]
# asm 1: vpbroadcastq <stack_FVGS3=stack256#5,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS3=256(%rsp),>d1=%ymm0
vpbroadcastq 256(%rsp),%ymm0

# qhasm: stack_mod3 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod3=stack256#23
# asm 2: vmovapd <d1=%ymm0,>stack_mod3=832(%rsp)
vmovapd %ymm0,832(%rsp)

# qhasm: d1 = 4x stack_FVGS4[0]
# asm 1: vpbroadcastq <stack_FVGS4=stack256#6,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS4=288(%rsp),>d1=%ymm0
vpbroadcastq 288(%rsp),%ymm0

# qhasm: stack_mod4 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod4=stack256#24
# asm 2: vmovapd <d1=%ymm0,>stack_mod4=864(%rsp)
vmovapd %ymm0,864(%rsp)

# qhasm: d1 = 4x stack_FVGS5[0]
# asm 1: vpbroadcastq <stack_FVGS5=stack256#7,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS5=320(%rsp),>d1=%ymm0
vpbroadcastq 320(%rsp),%ymm0

# qhasm: stack_mod5 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod5=stack256#25
# asm 2: vmovapd <d1=%ymm0,>stack_mod5=896(%rsp)
vmovapd %ymm0,896(%rsp)

# qhasm: d1 = 4x stack_FVGS6[0]
# asm 1: vpbroadcastq <stack_FVGS6=stack256#8,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS6=352(%rsp),>d1=%ymm0
vpbroadcastq 352(%rsp),%ymm0

# qhasm: stack_mod6 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod6=stack256#26
# asm 2: vmovapd <d1=%ymm0,>stack_mod6=928(%rsp)
vmovapd %ymm0,928(%rsp)

# qhasm: d1 = 4x stack_FVGS7[0]
# asm 1: vpbroadcastq <stack_FVGS7=stack256#9,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS7=384(%rsp),>d1=%ymm0
vpbroadcastq 384(%rsp),%ymm0

# qhasm: stack_mod7 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod7=stack256#27
# asm 2: vmovapd <d1=%ymm0,>stack_mod7=960(%rsp)
vmovapd %ymm0,960(%rsp)

# qhasm: d1 = 4x stack_FVGS8[0]
# asm 1: vpbroadcastq <stack_FVGS8=stack256#10,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS8=416(%rsp),>d1=%ymm0
vpbroadcastq 416(%rsp),%ymm0

# qhasm: stack_mod8 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod8=stack256#28
# asm 2: vmovapd <d1=%ymm0,>stack_mod8=992(%rsp)
vmovapd %ymm0,992(%rsp)

# qhasm: d1 = 4x stack_FVGS9[0]
# asm 1: vpbroadcastq <stack_FVGS9=stack256#11,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS9=448(%rsp),>d1=%ymm0
vpbroadcastq 448(%rsp),%ymm0

# qhasm: stack_mod9 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod9=stack256#29
# asm 2: vmovapd <d1=%ymm0,>stack_mod9=1024(%rsp)
vmovapd %ymm0,1024(%rsp)

# qhasm: d1 = 4x stack_FVGS10[0]
# asm 1: vpbroadcastq <stack_FVGS10=stack256#12,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS10=480(%rsp),>d1=%ymm0
vpbroadcastq 480(%rsp),%ymm0

# qhasm: stack_mod10 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod10=stack256#30
# asm 2: vmovapd <d1=%ymm0,>stack_mod10=1056(%rsp)
vmovapd %ymm0,1056(%rsp)

# qhasm: d1 = 4x stack_FVGS11[0]
# asm 1: vpbroadcastq <stack_FVGS11=stack256#13,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS11=512(%rsp),>d1=%ymm0
vpbroadcastq 512(%rsp),%ymm0

# qhasm: stack_mod11 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod11=stack256#31
# asm 2: vmovapd <d1=%ymm0,>stack_mod11=1088(%rsp)
vmovapd %ymm0,1088(%rsp)

# qhasm: d1 = 4x stack_FVGS12[0]
# asm 1: vpbroadcastq <stack_FVGS12=stack256#14,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS12=544(%rsp),>d1=%ymm0
vpbroadcastq 544(%rsp),%ymm0

# qhasm: stack_mod12 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod12=stack256#32
# asm 2: vmovapd <d1=%ymm0,>stack_mod12=1120(%rsp)
vmovapd %ymm0,1120(%rsp)

# qhasm: d1 = 4x stack_FVGS13[0]
# asm 1: vpbroadcastq <stack_FVGS13=stack256#15,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS13=576(%rsp),>d1=%ymm0
vpbroadcastq 576(%rsp),%ymm0

# qhasm: stack_mod13 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod13=stack256#33
# asm 2: vmovapd <d1=%ymm0,>stack_mod13=1152(%rsp)
vmovapd %ymm0,1152(%rsp)

# qhasm: d1 = 4x stack_FVGS14[0]
# asm 1: vpbroadcastq <stack_FVGS14=stack256#16,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS14=608(%rsp),>d1=%ymm0
vpbroadcastq 608(%rsp),%ymm0

# qhasm: stack_mod14 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod14=stack256#34
# asm 2: vmovapd <d1=%ymm0,>stack_mod14=1184(%rsp)
vmovapd %ymm0,1184(%rsp)

# qhasm: d1 = 4x stack_FVGS15[0]
# asm 1: vpbroadcastq <stack_FVGS15=stack256#17,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS15=640(%rsp),>d1=%ymm0
vpbroadcastq 640(%rsp),%ymm0

# qhasm: stack_mod15 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod15=stack256#35
# asm 2: vmovapd <d1=%ymm0,>stack_mod15=1216(%rsp)
vmovapd %ymm0,1216(%rsp)

# qhasm: d1 = 4x stack_FVGS16[0]
# asm 1: vpbroadcastq <stack_FVGS16=stack256#18,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS16=672(%rsp),>d1=%ymm0
vpbroadcastq 672(%rsp),%ymm0

# qhasm: stack_mod16 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod16=stack256#36
# asm 2: vmovapd <d1=%ymm0,>stack_mod16=1248(%rsp)
vmovapd %ymm0,1248(%rsp)

# qhasm: d1 = 4x stack_FVGS17[0]
# asm 1: vpbroadcastq <stack_FVGS17=stack256#19,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS17=704(%rsp),>d1=%ymm0
vpbroadcastq 704(%rsp),%ymm0

# qhasm: stack_mod17 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod17=stack256#37
# asm 2: vmovapd <d1=%ymm0,>stack_mod17=1280(%rsp)
vmovapd %ymm0,1280(%rsp)

# qhasm: minv = mem64[ table + 800]
# asm 1: movq   800(<table=int64#2),>minv=int64#3
# asm 2: movq   800(<table=%rsi),>minv=%rdx
movq   800(%rsi),%rdx

# qhasm: stack_minv = minv
# asm 1: movq <minv=int64#3,>stack_minv=stack64#9
# asm 2: movq <minv=%rdx,>stack_minv=64(%rsp)
movq %rdx,64(%rsp)

# qhasm: a0 = mem64[input_0 +  0]
# asm 1: movq   0(<input_0=int64#1),>a0=int64#4
# asm 2: movq   0(<input_0=%rdi),>a0=%rcx
movq   0(%rdi),%rcx

# qhasm: minv *= a0
# asm 1: imul  <a0=int64#4,<minv=int64#3
# asm 2: imul  <a0=%rcx,<minv=%rdx
imul  %rcx,%rdx

# qhasm: (uint128) t1 t0 = minv * mem64[ table + 160 ]
# asm 1: mulx  160(<table=int64#2),>t0=int64#5,>t1=int64#6
# asm 2: mulx  160(<table=%rsi),>t0=%r8,>t1=%r9
mulx  160(%rsi),%r8,%r9

# qhasm: carry? t0 += a0
# asm 1: add  <a0=int64#4,<t0=int64#5
# asm 2: add  <a0=%rcx,<t0=%r8
add  %rcx,%r8

# qhasm: t1 += 0 + carry
# asm 1: adc $0,<t1=int64#6
# asm 2: adc $0,<t1=%r9
adc $0,%r9

# qhasm: a1 = mem64[input_0 +  8]
# asm 1: movq   8(<input_0=int64#1),>a1=int64#4
# asm 2: movq   8(<input_0=%rdi),>a1=%rcx
movq   8(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a1 += t1
# asm 1: add  <t1=int64#6,<a1=int64#4
# asm 2: add  <t1=%r9,<a1=%rcx
add  %r9,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t2 t1 = minv * mem64[ table + 168 ]
# asm 1: mulx  168(<table=int64#2),>t1=int64#6,>t2=int64#7
# asm 2: mulx  168(<table=%rsi),>t1=%r9,>t2=%rax
mulx  168(%rsi),%r9,%rax

# qhasm: carry? t1 += a1
# asm 1: add  <a1=int64#4,<t1=int64#6
# asm 2: add  <a1=%rcx,<t1=%r9
add  %rcx,%r9

# qhasm: t2 += h + carry
# asm 1: adc <h=int64#5,<t2=int64#7
# asm 2: adc <h=%r8,<t2=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS0[2] = t1
# asm 1: movq <t1=int64#6,<stack_FVGS0=stack256#2
# asm 2: movq <t1=%r9,<stack_FVGS0=176(%rsp)
movq %r9,176(%rsp)

# qhasm: a2 = mem64[input_0 + 16]
# asm 1: movq   16(<input_0=int64#1),>a2=int64#4
# asm 2: movq   16(<input_0=%rdi),>a2=%rcx
movq   16(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a2 += t2
# asm 1: add  <t2=int64#7,<a2=int64#4
# asm 2: add  <t2=%rax,<a2=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t3 t2 = minv * mem64[ table + 176 ]
# asm 1: mulx  176(<table=int64#2),>t2=int64#6,>t3=int64#7
# asm 2: mulx  176(<table=%rsi),>t2=%r9,>t3=%rax
mulx  176(%rsi),%r9,%rax

# qhasm: carry? t2 += a2
# asm 1: add  <a2=int64#4,<t2=int64#6
# asm 2: add  <a2=%rcx,<t2=%r9
add  %rcx,%r9

# qhasm: t3 += h + carry
# asm 1: adc <h=int64#5,<t3=int64#7
# asm 2: adc <h=%r8,<t3=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS1[2] = t2
# asm 1: movq <t2=int64#6,<stack_FVGS1=stack256#3
# asm 2: movq <t2=%r9,<stack_FVGS1=208(%rsp)
movq %r9,208(%rsp)

# qhasm: a3 = mem64[input_0 + 24]
# asm 1: movq   24(<input_0=int64#1),>a3=int64#4
# asm 2: movq   24(<input_0=%rdi),>a3=%rcx
movq   24(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a3 += t3
# asm 1: add  <t3=int64#7,<a3=int64#4
# asm 2: add  <t3=%rax,<a3=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t4 t3 = minv * mem64[ table + 184 ]
# asm 1: mulx  184(<table=int64#2),>t3=int64#6,>t4=int64#7
# asm 2: mulx  184(<table=%rsi),>t3=%r9,>t4=%rax
mulx  184(%rsi),%r9,%rax

# qhasm: carry? t3 += a3
# asm 1: add  <a3=int64#4,<t3=int64#6
# asm 2: add  <a3=%rcx,<t3=%r9
add  %rcx,%r9

# qhasm: t4 += h + carry
# asm 1: adc <h=int64#5,<t4=int64#7
# asm 2: adc <h=%r8,<t4=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS2[2] = t3
# asm 1: movq <t3=int64#6,<stack_FVGS2=stack256#4
# asm 2: movq <t3=%r9,<stack_FVGS2=240(%rsp)
movq %r9,240(%rsp)

# qhasm: a4 = mem64[input_0 + 32]
# asm 1: movq   32(<input_0=int64#1),>a4=int64#4
# asm 2: movq   32(<input_0=%rdi),>a4=%rcx
movq   32(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a4 += t4
# asm 1: add  <t4=int64#7,<a4=int64#4
# asm 2: add  <t4=%rax,<a4=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t5 t4 = minv * mem64[ table + 192 ]
# asm 1: mulx  192(<table=int64#2),>t4=int64#6,>t5=int64#7
# asm 2: mulx  192(<table=%rsi),>t4=%r9,>t5=%rax
mulx  192(%rsi),%r9,%rax

# qhasm: carry? t4 += a4
# asm 1: add  <a4=int64#4,<t4=int64#6
# asm 2: add  <a4=%rcx,<t4=%r9
add  %rcx,%r9

# qhasm: t5 += h + carry
# asm 1: adc <h=int64#5,<t5=int64#7
# asm 2: adc <h=%r8,<t5=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS3[2] = t4
# asm 1: movq <t4=int64#6,<stack_FVGS3=stack256#5
# asm 2: movq <t4=%r9,<stack_FVGS3=272(%rsp)
movq %r9,272(%rsp)

# qhasm: a5 = mem64[input_0 + 40]
# asm 1: movq   40(<input_0=int64#1),>a5=int64#4
# asm 2: movq   40(<input_0=%rdi),>a5=%rcx
movq   40(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a5 += t5
# asm 1: add  <t5=int64#7,<a5=int64#4
# asm 2: add  <t5=%rax,<a5=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t6 t5 = minv * mem64[ table + 200 ]
# asm 1: mulx  200(<table=int64#2),>t5=int64#6,>t6=int64#7
# asm 2: mulx  200(<table=%rsi),>t5=%r9,>t6=%rax
mulx  200(%rsi),%r9,%rax

# qhasm: carry? t5 += a5
# asm 1: add  <a5=int64#4,<t5=int64#6
# asm 2: add  <a5=%rcx,<t5=%r9
add  %rcx,%r9

# qhasm: t6 += h + carry
# asm 1: adc <h=int64#5,<t6=int64#7
# asm 2: adc <h=%r8,<t6=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS4[2] = t5
# asm 1: movq <t5=int64#6,<stack_FVGS4=stack256#6
# asm 2: movq <t5=%r9,<stack_FVGS4=304(%rsp)
movq %r9,304(%rsp)

# qhasm: a6 = mem64[input_0 + 48]
# asm 1: movq   48(<input_0=int64#1),>a6=int64#4
# asm 2: movq   48(<input_0=%rdi),>a6=%rcx
movq   48(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a6 += t6
# asm 1: add  <t6=int64#7,<a6=int64#4
# asm 2: add  <t6=%rax,<a6=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t7 t6 = minv * mem64[ table + 208 ]
# asm 1: mulx  208(<table=int64#2),>t6=int64#6,>t7=int64#7
# asm 2: mulx  208(<table=%rsi),>t6=%r9,>t7=%rax
mulx  208(%rsi),%r9,%rax

# qhasm: carry? t6 += a6
# asm 1: add  <a6=int64#4,<t6=int64#6
# asm 2: add  <a6=%rcx,<t6=%r9
add  %rcx,%r9

# qhasm: t7 += h + carry
# asm 1: adc <h=int64#5,<t7=int64#7
# asm 2: adc <h=%r8,<t7=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS5[2] = t6
# asm 1: movq <t6=int64#6,<stack_FVGS5=stack256#7
# asm 2: movq <t6=%r9,<stack_FVGS5=336(%rsp)
movq %r9,336(%rsp)

# qhasm: a7 = mem64[input_0 + 56]
# asm 1: movq   56(<input_0=int64#1),>a7=int64#1
# asm 2: movq   56(<input_0=%rdi),>a7=%rdi
movq   56(%rdi),%rdi

# qhasm: h = 0
# asm 1: xor  >h=int64#4,>h=int64#4
# asm 2: xor  >h=%rcx,>h=%rcx
xor  %rcx,%rcx

# qhasm: carry? a7 += t7
# asm 1: add  <t7=int64#7,<a7=int64#1
# asm 2: add  <t7=%rax,<a7=%rdi
add  %rax,%rdi

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#4
# asm 2: adc $0,<h=%rcx
adc $0,%rcx

# qhasm: (uint128) t8 t7 = minv * mem64[ table + 216 ]
# asm 1: mulx  216(<table=int64#2),>t7=int64#3,>t8=int64#5
# asm 2: mulx  216(<table=%rsi),>t7=%rdx,>t8=%r8
mulx  216(%rsi),%rdx,%r8

# qhasm: carry? t7 += a7
# asm 1: add  <a7=int64#1,<t7=int64#3
# asm 2: add  <a7=%rdi,<t7=%rdx
add  %rdi,%rdx

# qhasm: t8 += h + carry
# asm 1: adc <h=int64#4,<t8=int64#5
# asm 2: adc <h=%rcx,<t8=%r8
adc %rcx,%r8

# qhasm: inplace stack_FVGS6[2] = t7
# asm 1: movq <t7=int64#3,<stack_FVGS6=stack256#8
# asm 2: movq <t7=%rdx,<stack_FVGS6=368(%rsp)
movq %rdx,368(%rsp)

# qhasm: inplace stack_FVGS7[2] = t8
# asm 1: movq <t8=int64#5,<stack_FVGS7=stack256#9
# asm 2: movq <t8=%r8,<stack_FVGS7=400(%rsp)
movq %r8,400(%rsp)

# qhasm: a0 = stack_FVGS0[2]
# asm 1: movq <stack_FVGS0=stack256#2,>a0=int64#1
# asm 2: movq <stack_FVGS0=176(%rsp),>a0=%rdi
movq 176(%rsp),%rdi

# qhasm: carry? a0 -= mem64[ table + 160]
# asm 1: subq 160(<table=int64#2),<a0=int64#1
# asm 2: subq 160(<table=%rsi),<a0=%rdi
subq 160(%rsi),%rdi

# qhasm: inplace stack_FVGS10[2] = a0
# asm 1: movq <a0=int64#1,<stack_FVGS10=stack256#12
# asm 2: movq <a0=%rdi,<stack_FVGS10=496(%rsp)
movq %rdi,496(%rsp)

# qhasm: a1 = stack_FVGS1[2]
# asm 1: movq <stack_FVGS1=stack256#3,>a1=int64#1
# asm 2: movq <stack_FVGS1=208(%rsp),>a1=%rdi
movq 208(%rsp),%rdi

# qhasm: carry? a1 -= mem64[ table + 168] - carry
# asm 1: sbbq 168(<table=int64#2),<a1=int64#1
# asm 2: sbbq 168(<table=%rsi),<a1=%rdi
sbbq 168(%rsi),%rdi

# qhasm: inplace stack_FVGS11[2] = a1
# asm 1: movq <a1=int64#1,<stack_FVGS11=stack256#13
# asm 2: movq <a1=%rdi,<stack_FVGS11=528(%rsp)
movq %rdi,528(%rsp)

# qhasm: a2 = stack_FVGS2[2]
# asm 1: movq <stack_FVGS2=stack256#4,>a2=int64#1
# asm 2: movq <stack_FVGS2=240(%rsp),>a2=%rdi
movq 240(%rsp),%rdi

# qhasm: carry? a2 -= mem64[ table + 176] - carry
# asm 1: sbbq 176(<table=int64#2),<a2=int64#1
# asm 2: sbbq 176(<table=%rsi),<a2=%rdi
sbbq 176(%rsi),%rdi

# qhasm: inplace stack_FVGS12[2] = a2
# asm 1: movq <a2=int64#1,<stack_FVGS12=stack256#14
# asm 2: movq <a2=%rdi,<stack_FVGS12=560(%rsp)
movq %rdi,560(%rsp)

# qhasm: a3 = stack_FVGS3[2]
# asm 1: movq <stack_FVGS3=stack256#5,>a3=int64#1
# asm 2: movq <stack_FVGS3=272(%rsp),>a3=%rdi
movq 272(%rsp),%rdi

# qhasm: carry? a3 -= mem64[ table + 184] - carry
# asm 1: sbbq 184(<table=int64#2),<a3=int64#1
# asm 2: sbbq 184(<table=%rsi),<a3=%rdi
sbbq 184(%rsi),%rdi

# qhasm: inplace stack_FVGS13[2] = a3
# asm 1: movq <a3=int64#1,<stack_FVGS13=stack256#15
# asm 2: movq <a3=%rdi,<stack_FVGS13=592(%rsp)
movq %rdi,592(%rsp)

# qhasm: a4 = stack_FVGS4[2]
# asm 1: movq <stack_FVGS4=stack256#6,>a4=int64#1
# asm 2: movq <stack_FVGS4=304(%rsp),>a4=%rdi
movq 304(%rsp),%rdi

# qhasm: carry? a4 -= mem64[ table + 192] - carry
# asm 1: sbbq 192(<table=int64#2),<a4=int64#1
# asm 2: sbbq 192(<table=%rsi),<a4=%rdi
sbbq 192(%rsi),%rdi

# qhasm: inplace stack_FVGS14[2] = a4
# asm 1: movq <a4=int64#1,<stack_FVGS14=stack256#16
# asm 2: movq <a4=%rdi,<stack_FVGS14=624(%rsp)
movq %rdi,624(%rsp)

# qhasm: a5 = stack_FVGS5[2]
# asm 1: movq <stack_FVGS5=stack256#7,>a5=int64#1
# asm 2: movq <stack_FVGS5=336(%rsp),>a5=%rdi
movq 336(%rsp),%rdi

# qhasm: carry? a5 -= mem64[ table + 200] - carry
# asm 1: sbbq 200(<table=int64#2),<a5=int64#1
# asm 2: sbbq 200(<table=%rsi),<a5=%rdi
sbbq 200(%rsi),%rdi

# qhasm: inplace stack_FVGS15[2] = a5
# asm 1: movq <a5=int64#1,<stack_FVGS15=stack256#17
# asm 2: movq <a5=%rdi,<stack_FVGS15=656(%rsp)
movq %rdi,656(%rsp)

# qhasm: a6 = stack_FVGS6[2]
# asm 1: movq <stack_FVGS6=stack256#8,>a6=int64#1
# asm 2: movq <stack_FVGS6=368(%rsp),>a6=%rdi
movq 368(%rsp),%rdi

# qhasm: carry? a6 -= mem64[ table + 208] - carry
# asm 1: sbbq 208(<table=int64#2),<a6=int64#1
# asm 2: sbbq 208(<table=%rsi),<a6=%rdi
sbbq 208(%rsi),%rdi

# qhasm: inplace stack_FVGS16[2] = a6
# asm 1: movq <a6=int64#1,<stack_FVGS16=stack256#18
# asm 2: movq <a6=%rdi,<stack_FVGS16=688(%rsp)
movq %rdi,688(%rsp)

# qhasm: a7 = stack_FVGS7[2]
# asm 1: movq <stack_FVGS7=stack256#9,>a7=int64#1
# asm 2: movq <stack_FVGS7=400(%rsp),>a7=%rdi
movq 400(%rsp),%rdi

# qhasm: carry? a7 -= mem64[ table + 216] - carry
# asm 1: sbbq 216(<table=int64#2),<a7=int64#1
# asm 2: sbbq 216(<table=%rsi),<a7=%rdi
sbbq 216(%rsi),%rdi

# qhasm: inplace stack_FVGS17[2] = a7
# asm 1: movq <a7=int64#1,<stack_FVGS17=stack256#19
# asm 2: movq <a7=%rdi,<stack_FVGS17=720(%rsp)
movq %rdi,720(%rsp)

# qhasm: a7 = stack_FVGS17[2]
# asm 1: movq <stack_FVGS17=stack256#19,>a7=int64#1
# asm 2: movq <stack_FVGS17=720(%rsp),>a7=%rdi
movq 720(%rsp),%rdi

# qhasm: a7 = stack_FVGS7[2] if carry
# asm 1: cmovc <stack_FVGS7=stack256#9,<a7=int64#1
# asm 2: cmovc <stack_FVGS7=400(%rsp),<a7=%rdi
cmovc 400(%rsp),%rdi

# qhasm: inplace stack_FVGS17[2] = a7
# asm 1: movq <a7=int64#1,<stack_FVGS17=stack256#19
# asm 2: movq <a7=%rdi,<stack_FVGS17=720(%rsp)
movq %rdi,720(%rsp)

# qhasm: a6 = stack_FVGS16[2]
# asm 1: movq <stack_FVGS16=stack256#18,>a6=int64#1
# asm 2: movq <stack_FVGS16=688(%rsp),>a6=%rdi
movq 688(%rsp),%rdi

# qhasm: a6 = stack_FVGS6[2] if carry
# asm 1: cmovc <stack_FVGS6=stack256#8,<a6=int64#1
# asm 2: cmovc <stack_FVGS6=368(%rsp),<a6=%rdi
cmovc 368(%rsp),%rdi

# qhasm: inplace stack_FVGS16[2] = a6
# asm 1: movq <a6=int64#1,<stack_FVGS16=stack256#18
# asm 2: movq <a6=%rdi,<stack_FVGS16=688(%rsp)
movq %rdi,688(%rsp)

# qhasm: a5 = stack_FVGS15[2]
# asm 1: movq <stack_FVGS15=stack256#17,>a5=int64#1
# asm 2: movq <stack_FVGS15=656(%rsp),>a5=%rdi
movq 656(%rsp),%rdi

# qhasm: a5 = stack_FVGS5[2] if carry
# asm 1: cmovc <stack_FVGS5=stack256#7,<a5=int64#1
# asm 2: cmovc <stack_FVGS5=336(%rsp),<a5=%rdi
cmovc 336(%rsp),%rdi

# qhasm: inplace stack_FVGS15[2] = a5
# asm 1: movq <a5=int64#1,<stack_FVGS15=stack256#17
# asm 2: movq <a5=%rdi,<stack_FVGS15=656(%rsp)
movq %rdi,656(%rsp)

# qhasm: a4 = stack_FVGS14[2]
# asm 1: movq <stack_FVGS14=stack256#16,>a4=int64#1
# asm 2: movq <stack_FVGS14=624(%rsp),>a4=%rdi
movq 624(%rsp),%rdi

# qhasm: a4 = stack_FVGS4[2] if carry
# asm 1: cmovc <stack_FVGS4=stack256#6,<a4=int64#1
# asm 2: cmovc <stack_FVGS4=304(%rsp),<a4=%rdi
cmovc 304(%rsp),%rdi

# qhasm: inplace stack_FVGS14[2] = a4
# asm 1: movq <a4=int64#1,<stack_FVGS14=stack256#16
# asm 2: movq <a4=%rdi,<stack_FVGS14=624(%rsp)
movq %rdi,624(%rsp)

# qhasm: a3 = stack_FVGS13[2]
# asm 1: movq <stack_FVGS13=stack256#15,>a3=int64#1
# asm 2: movq <stack_FVGS13=592(%rsp),>a3=%rdi
movq 592(%rsp),%rdi

# qhasm: a3 = stack_FVGS3[2] if carry
# asm 1: cmovc <stack_FVGS3=stack256#5,<a3=int64#1
# asm 2: cmovc <stack_FVGS3=272(%rsp),<a3=%rdi
cmovc 272(%rsp),%rdi

# qhasm: inplace stack_FVGS13[2] = a3
# asm 1: movq <a3=int64#1,<stack_FVGS13=stack256#15
# asm 2: movq <a3=%rdi,<stack_FVGS13=592(%rsp)
movq %rdi,592(%rsp)

# qhasm: a2 = stack_FVGS12[2]
# asm 1: movq <stack_FVGS12=stack256#14,>a2=int64#1
# asm 2: movq <stack_FVGS12=560(%rsp),>a2=%rdi
movq 560(%rsp),%rdi

# qhasm: a2 = stack_FVGS2[2] if carry
# asm 1: cmovc <stack_FVGS2=stack256#4,<a2=int64#1
# asm 2: cmovc <stack_FVGS2=240(%rsp),<a2=%rdi
cmovc 240(%rsp),%rdi

# qhasm: inplace stack_FVGS12[2] = a2
# asm 1: movq <a2=int64#1,<stack_FVGS12=stack256#14
# asm 2: movq <a2=%rdi,<stack_FVGS12=560(%rsp)
movq %rdi,560(%rsp)

# qhasm: a1 = stack_FVGS11[2]
# asm 1: movq <stack_FVGS11=stack256#13,>a1=int64#1
# asm 2: movq <stack_FVGS11=528(%rsp),>a1=%rdi
movq 528(%rsp),%rdi

# qhasm: a1 = stack_FVGS1[2] if carry
# asm 1: cmovc <stack_FVGS1=stack256#3,<a1=int64#1
# asm 2: cmovc <stack_FVGS1=208(%rsp),<a1=%rdi
cmovc 208(%rsp),%rdi

# qhasm: inplace stack_FVGS11[2] = a1
# asm 1: movq <a1=int64#1,<stack_FVGS11=stack256#13
# asm 2: movq <a1=%rdi,<stack_FVGS11=528(%rsp)
movq %rdi,528(%rsp)

# qhasm: a0 = stack_FVGS10[2]
# asm 1: movq <stack_FVGS10=stack256#12,>a0=int64#1
# asm 2: movq <stack_FVGS10=496(%rsp),>a0=%rdi
movq 496(%rsp),%rdi

# qhasm: a0 = stack_FVGS0[2] if carry
# asm 1: cmovc <stack_FVGS0=stack256#2,<a0=int64#1
# asm 2: cmovc <stack_FVGS0=176(%rsp),<a0=%rdi
cmovc 176(%rsp),%rdi

# qhasm: inplace stack_FVGS10[2] = a0
# asm 1: movq <a0=int64#1,<stack_FVGS10=stack256#12
# asm 2: movq <a0=%rdi,<stack_FVGS10=496(%rsp)
movq %rdi,496(%rsp)

# qhasm: t0 = -1152921504606846976
# asm 1: mov  $-1152921504606846976,>t0=int64#3
# asm 2: mov  $-1152921504606846976,>t0=%rdx
mov  $-1152921504606846976,%rdx

# qhasm: g = a0 & ~ t0
# asm 1: andn  <a0=int64#1,<t0=int64#3,>g=int64#1
# asm 2: andn  <a0=%rdi,<t0=%rdx,>g=%rdi
andn  %rdi,%rdx,%rdi

# qhasm: a0 = stack_FVGS10[2]
# asm 1: movq <stack_FVGS10=stack256#12,>a0=int64#3
# asm 2: movq <stack_FVGS10=496(%rsp),>a0=%rdx
movq 496(%rsp),%rdx

# qhasm: t0 = a0
# asm 1: mov  <a0=int64#3,>t0=int64#4
# asm 2: mov  <a0=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS0[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS0=stack256#2
# asm 2: movq <t0=%rcx,<stack_FVGS0=176(%rsp)
movq %rcx,176(%rsp)

# qhasm: t0 = a0
# asm 1: mov  <a0=int64#3,>t0=int64#4
# asm 2: mov  <a0=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 30
# asm 1: shr  $30,<t0=int64#4
# asm 2: shr  $30,<t0=%rcx
shr  $30,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS1[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS1=stack256#3
# asm 2: movq <t0=%rcx,<stack_FVGS1=208(%rsp)
movq %rcx,208(%rsp)

# qhasm: a1 = stack_FVGS11[2]
# asm 1: movq <stack_FVGS11=stack256#13,>a1=int64#4
# asm 2: movq <stack_FVGS11=528(%rsp),>a1=%rcx
movq 528(%rsp),%rcx

# qhasm: a0 = (a1 a0) >> 60
# asm 1: shrd $60,<a1=int64#4,<a0=int64#3
# asm 2: shrd $60,<a1=%rcx,<a0=%rdx
shrd $60,%rcx,%rdx

# qhasm: a0 &= 1073741823
# asm 1: and  $1073741823,<a0=int64#3
# asm 2: and  $1073741823,<a0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS2[2] = a0
# asm 1: movq <a0=int64#3,<stack_FVGS2=stack256#4
# asm 2: movq <a0=%rdx,<stack_FVGS2=240(%rsp)
movq %rdx,240(%rsp)

# qhasm: t0 = a1
# asm 1: mov  <a1=int64#4,>t0=int64#3
# asm 2: mov  <a1=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 26
# asm 1: shr  $26,<t0=int64#3
# asm 2: shr  $26,<t0=%rdx
shr  $26,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS3[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS3=stack256#5
# asm 2: movq <t0=%rdx,<stack_FVGS3=272(%rsp)
movq %rdx,272(%rsp)

# qhasm: a2 = stack_FVGS12[2]
# asm 1: movq <stack_FVGS12=stack256#14,>a2=int64#3
# asm 2: movq <stack_FVGS12=560(%rsp),>a2=%rdx
movq 560(%rsp),%rdx

# qhasm: a1 = (a2 a1) >> 56
# asm 1: shrd $56,<a2=int64#3,<a1=int64#4
# asm 2: shrd $56,<a2=%rdx,<a1=%rcx
shrd $56,%rdx,%rcx

# qhasm: a1 &= 1073741823
# asm 1: and  $1073741823,<a1=int64#4
# asm 2: and  $1073741823,<a1=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS4[2] = a1
# asm 1: movq <a1=int64#4,<stack_FVGS4=stack256#6
# asm 2: movq <a1=%rcx,<stack_FVGS4=304(%rsp)
movq %rcx,304(%rsp)

# qhasm: t0 = a2
# asm 1: mov  <a2=int64#3,>t0=int64#4
# asm 2: mov  <a2=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 22
# asm 1: shr  $22,<t0=int64#4
# asm 2: shr  $22,<t0=%rcx
shr  $22,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS5[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS5=stack256#7
# asm 2: movq <t0=%rcx,<stack_FVGS5=336(%rsp)
movq %rcx,336(%rsp)

# qhasm: a3 = stack_FVGS13[2]
# asm 1: movq <stack_FVGS13=stack256#15,>a3=int64#4
# asm 2: movq <stack_FVGS13=592(%rsp),>a3=%rcx
movq 592(%rsp),%rcx

# qhasm: a2 = (a3 a2) >> 52
# asm 1: shrd $52,<a3=int64#4,<a2=int64#3
# asm 2: shrd $52,<a3=%rcx,<a2=%rdx
shrd $52,%rcx,%rdx

# qhasm: a2 &= 1073741823
# asm 1: and  $1073741823,<a2=int64#3
# asm 2: and  $1073741823,<a2=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS6[2] = a2
# asm 1: movq <a2=int64#3,<stack_FVGS6=stack256#8
# asm 2: movq <a2=%rdx,<stack_FVGS6=368(%rsp)
movq %rdx,368(%rsp)

# qhasm: t0 = a3
# asm 1: mov  <a3=int64#4,>t0=int64#3
# asm 2: mov  <a3=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 18
# asm 1: shr  $18,<t0=int64#3
# asm 2: shr  $18,<t0=%rdx
shr  $18,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS7[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS7=stack256#9
# asm 2: movq <t0=%rdx,<stack_FVGS7=400(%rsp)
movq %rdx,400(%rsp)

# qhasm: a4 = stack_FVGS14[2]
# asm 1: movq <stack_FVGS14=stack256#16,>a4=int64#3
# asm 2: movq <stack_FVGS14=624(%rsp),>a4=%rdx
movq 624(%rsp),%rdx

# qhasm: a3 = (a4 a3) >> 48
# asm 1: shrd $48,<a4=int64#3,<a3=int64#4
# asm 2: shrd $48,<a4=%rdx,<a3=%rcx
shrd $48,%rdx,%rcx

# qhasm: a3 &= 1073741823
# asm 1: and  $1073741823,<a3=int64#4
# asm 2: and  $1073741823,<a3=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS8[2] = a3
# asm 1: movq <a3=int64#4,<stack_FVGS8=stack256#10
# asm 2: movq <a3=%rcx,<stack_FVGS8=432(%rsp)
movq %rcx,432(%rsp)

# qhasm: t0 = a4
# asm 1: mov  <a4=int64#3,>t0=int64#4
# asm 2: mov  <a4=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 14
# asm 1: shr  $14,<t0=int64#4
# asm 2: shr  $14,<t0=%rcx
shr  $14,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS9[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS9=stack256#11
# asm 2: movq <t0=%rcx,<stack_FVGS9=464(%rsp)
movq %rcx,464(%rsp)

# qhasm: a5 = stack_FVGS15[2]
# asm 1: movq <stack_FVGS15=stack256#17,>a5=int64#4
# asm 2: movq <stack_FVGS15=656(%rsp),>a5=%rcx
movq 656(%rsp),%rcx

# qhasm: a4 = (a5 a4) >> 44
# asm 1: shrd $44,<a5=int64#4,<a4=int64#3
# asm 2: shrd $44,<a5=%rcx,<a4=%rdx
shrd $44,%rcx,%rdx

# qhasm: a4 &= 1073741823
# asm 1: and  $1073741823,<a4=int64#3
# asm 2: and  $1073741823,<a4=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS10[2] = a4
# asm 1: movq <a4=int64#3,<stack_FVGS10=stack256#12
# asm 2: movq <a4=%rdx,<stack_FVGS10=496(%rsp)
movq %rdx,496(%rsp)

# qhasm: t0 = a5
# asm 1: mov  <a5=int64#4,>t0=int64#3
# asm 2: mov  <a5=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 10
# asm 1: shr  $10,<t0=int64#3
# asm 2: shr  $10,<t0=%rdx
shr  $10,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS11[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS11=stack256#13
# asm 2: movq <t0=%rdx,<stack_FVGS11=528(%rsp)
movq %rdx,528(%rsp)

# qhasm: a6 = stack_FVGS16[2]
# asm 1: movq <stack_FVGS16=stack256#18,>a6=int64#3
# asm 2: movq <stack_FVGS16=688(%rsp),>a6=%rdx
movq 688(%rsp),%rdx

# qhasm: a5 = (a6 a5) >> 40
# asm 1: shrd $40,<a6=int64#3,<a5=int64#4
# asm 2: shrd $40,<a6=%rdx,<a5=%rcx
shrd $40,%rdx,%rcx

# qhasm: a5 &= 1073741823
# asm 1: and  $1073741823,<a5=int64#4
# asm 2: and  $1073741823,<a5=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS12[2] = a5
# asm 1: movq <a5=int64#4,<stack_FVGS12=stack256#14
# asm 2: movq <a5=%rcx,<stack_FVGS12=560(%rsp)
movq %rcx,560(%rsp)

# qhasm: t0 = a6
# asm 1: mov  <a6=int64#3,>t0=int64#4
# asm 2: mov  <a6=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 6
# asm 1: shr  $6,<t0=int64#4
# asm 2: shr  $6,<t0=%rcx
shr  $6,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS13[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS13=stack256#15
# asm 2: movq <t0=%rcx,<stack_FVGS13=592(%rsp)
movq %rcx,592(%rsp)

# qhasm: a7 = stack_FVGS17[2]
# asm 1: movq <stack_FVGS17=stack256#19,>a7=int64#4
# asm 2: movq <stack_FVGS17=720(%rsp),>a7=%rcx
movq 720(%rsp),%rcx

# qhasm: a6 = (a7 a6) >> 36
# asm 1: shrd $36,<a7=int64#4,<a6=int64#3
# asm 2: shrd $36,<a7=%rcx,<a6=%rdx
shrd $36,%rcx,%rdx

# qhasm: a6 &= 1073741823
# asm 1: and  $1073741823,<a6=int64#3
# asm 2: and  $1073741823,<a6=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS14[2] = a6
# asm 1: movq <a6=int64#3,<stack_FVGS14=stack256#16
# asm 2: movq <a6=%rdx,<stack_FVGS14=624(%rsp)
movq %rdx,624(%rsp)

# qhasm: t0 = a7
# asm 1: mov  <a7=int64#4,>t0=int64#3
# asm 2: mov  <a7=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 2
# asm 1: shr  $2,<t0=int64#3
# asm 2: shr  $2,<t0=%rdx
shr  $2,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS15[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS15=stack256#17
# asm 2: movq <t0=%rdx,<stack_FVGS15=656(%rsp)
movq %rdx,656(%rsp)

# qhasm: t0 = a7
# asm 1: mov  <a7=int64#4,>t0=int64#3
# asm 2: mov  <a7=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 32
# asm 1: shr  $32,<t0=int64#3
# asm 2: shr  $32,<t0=%rdx
shr  $32,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS16[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS16=stack256#18
# asm 2: movq <t0=%rdx,<stack_FVGS16=688(%rsp)
movq %rdx,688(%rsp)

# qhasm: (uint64) a7 >>= 62
# asm 1: shr  $62,<a7=int64#4
# asm 2: shr  $62,<a7=%rcx
shr  $62,%rcx

# qhasm: inplace stack_FVGS17[2] = a7
# asm 1: movq <a7=int64#4,<stack_FVGS17=stack256#19
# asm 2: movq <a7=%rcx,<stack_FVGS17=720(%rsp)
movq %rcx,720(%rsp)

# qhasm: f = stack_FVGS0[0]
# asm 1: movq <stack_FVGS0=stack256#2,>f=int64#4
# asm 2: movq <stack_FVGS0=160(%rsp),>f=%rcx
movq 160(%rsp),%rcx

# qhasm: f0 = stack_FVGS1[0]
# asm 1: movq <stack_FVGS1=stack256#3,>f0=int64#5
# asm 2: movq <stack_FVGS1=192(%rsp),>f0=%r8
movq 192(%rsp),%r8

# qhasm: f0 <<= 30
# asm 1: shl  $30,<f0=int64#5
# asm 2: shl  $30,<f0=%r8
shl  $30,%r8

# qhasm: f += f0 
# asm 1: add  <f0=int64#5,<f=int64#4
# asm 2: add  <f0=%r8,<f=%rcx
add  %r8,%rcx

# qhasm:                   m = 0
# asm 1: xor  >m=int64#6,>m=int64#6
# asm 2: xor  >m=%r9,>m=%r9
xor  %r9,%r9

# qhasm:                   z = -1
# asm 1: mov  $-1,>z=int64#3
# asm 2: mov  $-1,>z=%rdx
mov  $-1,%rdx

# qhasm: inplace stack_m1[0] = m
# asm 1: movq <m=int64#6,<stack_m1=stack256#1
# asm 2: movq <m=%r9,<stack_m1=128(%rsp)
movq %r9,128(%rsp)

# qhasm: inplace stack_m1[1] = z
# asm 1: movq <z=int64#3,<stack_m1=stack256#1
# asm 2: movq <z=%rdx,<stack_m1=136(%rsp)
movq %rdx,136(%rsp)

# qhasm:              _m2p20 = -1048576
# asm 1: mov  $-1048576,>_m2p20=int64#8
# asm 2: mov  $-1048576,>_m2p20=%r10
mov  $-1048576,%r10

# qhasm:         stack_m2p20 = _m2p20
# asm 1: movq <_m2p20=int64#8,>stack_m2p20=stack64#10
# asm 2: movq <_m2p20=%r10,>stack_m2p20=72(%rsp)
movq %r10,72(%rsp)

# qhasm:               _2p20 = 1048576
# asm 1: mov  $1048576,>_2p20=int64#3
# asm 2: mov  $1048576,>_2p20=%rdx
mov  $1048576,%rdx

# qhasm:          stack_2p20 = _2p20
# asm 1: movq <_2p20=int64#3,>stack_2p20=stack64#11
# asm 2: movq <_2p20=%rdx,>stack_2p20=80(%rsp)
movq %rdx,80(%rsp)

# qhasm:              _m2p41 = -2199023255552
# asm 1: mov  $-2199023255552,>_m2p41=int64#3
# asm 2: mov  $-2199023255552,>_m2p41=%rdx
mov  $-2199023255552,%rdx

# qhasm:         stack_m2p41 = _m2p41
# asm 1: movq <_m2p41=int64#3,>stack_m2p41=stack64#12
# asm 2: movq <_m2p41=%rdx,>stack_m2p41=88(%rsp)
movq %rdx,88(%rsp)

# qhasm:              _m2p62 = -4611686018427387904
# asm 1: mov  $-4611686018427387904,>_m2p62=int64#3
# asm 2: mov  $-4611686018427387904,>_m2p62=%rdx
mov  $-4611686018427387904,%rdx

# qhasm:         stack_m2p62 = _m2p62
# asm 1: movq <_m2p62=int64#3,>stack_m2p62=stack64#13
# asm 2: movq <_m2p62=%rdx,>stack_m2p62=96(%rsp)
movq %rdx,96(%rsp)

# qhasm:          _2p20a2p41 = 2199024304128
# asm 1: mov  $2199024304128,>_2p20a2p41=int64#3
# asm 2: mov  $2199024304128,>_2p20a2p41=%rdx
mov  $2199024304128,%rdx

# qhasm:     stack_2p20a2p41 = _2p20a2p41
# asm 1: movq <_2p20a2p41=int64#3,>stack_2p20a2p41=stack64#14
# asm 2: movq <_2p20a2p41=%rdx,>stack_2p20a2p41=104(%rsp)
movq %rdx,104(%rsp)

# qhasm:           _2p30m1x4 = mem256[ table +   0 ]
# asm 1: vmovupd   0(<table=int64#2),>_2p30m1x4=reg256#1
# asm 2: vmovupd   0(<table=%rsi),>_2p30m1x4=%ymm0
vmovupd   0(%rsi),%ymm0

# qhasm:      stack_2p30m1x4 = _2p30m1x4
# asm 1: vmovapd <_2p30m1x4=reg256#1,>stack_2p30m1x4=stack256#38
# asm 2: vmovapd <_2p30m1x4=%ymm0,>stack_2p30m1x4=1312(%rsp)
vmovapd %ymm0,1312(%rsp)

# qhasm:             _2p33x4 = mem256[ table +  32 ]
# asm 1: vmovupd   32(<table=int64#2),>_2p33x4=reg256#1
# asm 2: vmovupd   32(<table=%rsi),>_2p33x4=%ymm0
vmovupd   32(%rsi),%ymm0

# qhasm:        stack_2p33x4 = _2p33x4
# asm 1: vmovapd <_2p33x4=reg256#1,>stack_2p33x4=stack256#39
# asm 2: vmovapd <_2p33x4=%ymm0,>stack_2p33x4=1344(%rsp)
vmovapd %ymm0,1344(%rsp)

# qhasm:             _2p63x4 = mem256[ table +  64 ]
# asm 1: vmovupd   64(<table=int64#2),>_2p63x4=reg256#1
# asm 2: vmovupd   64(<table=%rsi),>_2p63x4=%ymm0
vmovupd   64(%rsi),%ymm0

# qhasm:        stack_2p63x4 = _2p63x4
# asm 1: vmovapd <_2p63x4=reg256#1,>stack_2p63x4=stack256#40
# asm 2: vmovapd <_2p63x4=%ymm0,>stack_2p63x4=1376(%rsp)
vmovapd %ymm0,1376(%rsp)

# qhasm:        _2p63m2p33x4 = mem256[ table +  96 ]
# asm 1: vmovupd   96(<table=int64#2),>_2p63m2p33x4=reg256#1
# asm 2: vmovupd   96(<table=%rsi),>_2p63m2p33x4=%ymm0
vmovupd   96(%rsi),%ymm0

# qhasm:   stack_2p63m2p33x4 = _2p63m2p33x4
# asm 1: vmovapd <_2p63m2p33x4=reg256#1,>stack_2p63m2p33x4=stack256#41
# asm 2: vmovapd <_2p63m2p33x4=%ymm0,>stack_2p63m2p33x4=1408(%rsp)
vmovapd %ymm0,1408(%rsp)

# qhasm:             _2p29x4 = mem256[ table + 128 ]
# asm 1: vmovupd   128(<table=int64#2),>_2p29x4=reg256#1
# asm 2: vmovupd   128(<table=%rsi),>_2p29x4=%ymm0
vmovupd   128(%rsi),%ymm0

# qhasm:        stack_2p29x4 = _2p29x4
# asm 1: vmovapd <_2p29x4=reg256#1,>stack_2p29x4=stack256#42
# asm 2: vmovapd <_2p29x4=%ymm0,>stack_2p29x4=1440(%rsp)
vmovapd %ymm0,1440(%rsp)

# qhasm:           _prime0x4 = mem256[ table + 160 ]
# asm 1: vmovupd   160(<table=int64#2),>_prime0x4=reg256#1
# asm 2: vmovupd   160(<table=%rsi),>_prime0x4=%ymm0
vmovupd   160(%rsi),%ymm0

# qhasm:      stack_prime0x4 = _prime0x4
# asm 1: vmovapd <_prime0x4=reg256#1,>stack_prime0x4=stack256#43
# asm 2: vmovapd <_prime0x4=%ymm0,>stack_prime0x4=1472(%rsp)
vmovapd %ymm0,1472(%rsp)

# qhasm: i = 20
# asm 1: mov  $20,>i=int64#2
# asm 2: mov  $20,>i=%rsi
mov  $20,%rsi

# qhasm: u = 1152921504606846976
# asm 1: mov  $1152921504606846976,>u=int64#9
# asm 2: mov  $1152921504606846976,>u=%r11
mov  $1152921504606846976,%r11

# qhasm: v = 0
# asm 1: xor  >v=int64#10,>v=int64#10
# asm 2: xor  >v=%r12,>v=%r12
xor  %r12,%r12

# qhasm: s = u
# asm 1: mov  <u=int64#9,>s=int64#11
# asm 2: mov  <u=%r11,>s=%r13
mov  %r11,%r13

# qhasm: r = 0
# asm 1: xor  >r=int64#12,>r=int64#12
# asm 2: xor  >r=%r14,>r=%r14
xor  %r14,%r14

# qhasm: nop
nop

# qhasm: nop
nop

# qhasm: nop
nop

# qhasm: nop
nop

# qhasm: nop
nop

# qhasm: nop
nop

# qhasm: nop
nop

# qhasm: bigloop:
._bigloop:

# qhasm:       rax = g
# asm 1: mov  <g=int64#1,>rax=int64#7
# asm 2: mov  <g=%rdi,>rax=%rax
mov  %rdi,%rax

# qhasm:       (int128) rdx rax = rax * s
# asm 1: imul <s=int64#11
# asm 2: imul <s=%r13
imul %r13

# qhasm:       t2 = rax
# asm 1: mov  <rax=int64#7,>t2=int64#14
# asm 2: mov  <rax=%rax,>t2=%rbx
mov  %rax,%rbx

# qhasm:       t1 = rdx
# asm 1: mov  <rdx=int64#3,>t1=int64#15
# asm 2: mov  <rdx=%rdx,>t1=%rbp
mov  %rdx,%rbp

# qhasm:       rax = f
# asm 1: mov  <f=int64#4,>rax=int64#7
# asm 2: mov  <f=%rcx,>rax=%rax
mov  %rcx,%rax

# qhasm:       (int128) rdx rax = rax * r
# asm 1: imul <r=int64#12
# asm 2: imul <r=%r14
imul %r14

# qhasm:       carry? t2 += rax
# asm 1: add  <rax=int64#7,<t2=int64#14
# asm 2: add  <rax=%rax,<t2=%rbx
add  %rax,%rbx

# qhasm:              t1 += rdx + carry
# asm 1: adc <rdx=int64#3,<t1=int64#15
# asm 2: adc <rdx=%rdx,<t1=%rbp
adc %rdx,%rbp

# qhasm:       t2 = (t1 t2) >> 60	 
# asm 1: shrd $60,<t1=int64#15,<t2=int64#14
# asm 2: shrd $60,<t1=%rbp,<t2=%rbx
shrd $60,%rbp,%rbx

# qhasm:       rax = f
# asm 1: mov  <f=int64#4,>rax=int64#7
# asm 2: mov  <f=%rcx,>rax=%rax
mov  %rcx,%rax

# qhasm:       (int128) rdx rax = rax * u
# asm 1: imul <u=int64#9
# asm 2: imul <u=%r11
imul %r11

# qhasm:       f = rax
# asm 1: mov  <rax=int64#7,>f=int64#4
# asm 2: mov  <rax=%rax,>f=%rcx
mov  %rax,%rcx

# qhasm:       t0 = rdx
# asm 1: mov  <rdx=int64#3,>t0=int64#15
# asm 2: mov  <rdx=%rdx,>t0=%rbp
mov  %rdx,%rbp

# qhasm:       rax = g
# asm 1: mov  <g=int64#1,>rax=int64#7
# asm 2: mov  <g=%rdi,>rax=%rax
mov  %rdi,%rax

# qhasm:       (int128) rdx rax = rax * v
# asm 1: imul <v=int64#10
# asm 2: imul <v=%r12
imul %r12

# qhasm:       carry? f += rax
# asm 1: add  <rax=int64#7,<f=int64#4
# asm 2: add  <rax=%rax,<f=%rcx
add  %rax,%rcx

# qhasm:              t0 += rdx + carry
# asm 1: adc <rdx=int64#3,<t0=int64#15
# asm 2: adc <rdx=%rdx,<t0=%rbp
adc %rdx,%rbp

# qhasm:       f = (t0 f) >> 60
# asm 1: shrd $60,<t0=int64#15,<f=int64#4
# asm 2: shrd $60,<t0=%rbp,<f=%rcx
shrd $60,%rbp,%rcx

# qhasm: new vvrr

# qhasm: vvrr = v,vvrr[1],0,0
# asm 1: vpinsrq $0x0,<v=int64#10,<vvrr=reg256#1%128,<vvrr=reg256#1%128
# asm 2: vpinsrq $0x0,<v=%r12,<vvrr=%xmm0,<vvrr=%xmm0
vpinsrq $0x0,%r12,%xmm0,%xmm0

# qhasm: vvrr = vvrr[0],r,0,0
# asm 1: vpinsrq $0x1,<r=int64#12,<vvrr=reg256#1%128,<vvrr=reg256#1%128
# asm 2: vpinsrq $0x1,<r=%r14,<vvrr=%xmm0,<vvrr=%xmm0
vpinsrq $0x1,%r14,%xmm0,%xmm0

# qhasm:       v *= g0
# asm 1: imul  <g0=int64#13,<v=int64#10
# asm 2: imul  <g0=%r15,<v=%r12
imul  %r15,%r12

# qhasm:       g0 *= s
# asm 1: imul  <s=int64#11,<g0=int64#13
# asm 2: imul  <s=%r13,<g0=%r15
imul  %r13,%r15

# qhasm:       r *= f0
# asm 1: imul  <f0=int64#5,<r=int64#12
# asm 2: imul  <f0=%r8,<r=%r14
imul  %r8,%r14

# qhasm:       f0 *= u
# asm 1: imul  <u=int64#9,<f0=int64#5
# asm 2: imul  <u=%r11,<f0=%r8
imul  %r11,%r8

# qhasm:       f0 += v
# asm 1: add  <v=int64#10,<f0=int64#5
# asm 2: add  <v=%r12,<f0=%r8
add  %r12,%r8

# qhasm:       g0 += r
# asm 1: add  <r=int64#12,<g0=int64#13
# asm 2: add  <r=%r14,<g0=%r15
add  %r14,%r15

# qhasm:       f += f0
# asm 1: add  <f0=int64#5,<f=int64#4
# asm 2: add  <f0=%r8,<f=%rcx
add  %r8,%rcx

# qhasm:       g = t2+g0
# asm 1: lea  (<t2=int64#14,<g0=int64#13),>g=int64#1
# asm 2: lea  (<t2=%rbx,<g0=%r15),>g=%rdi
lea  (%rbx,%r15),%rdi

# qhasm: loop20_init:
._loop20_init:

# qhasm:   fuv = f & ~ _m2p20
# asm 1: andn  <f=int64#4,<_m2p20=int64#8,>fuv=int64#3
# asm 2: andn  <f=%rcx,<_m2p20=%r10,>fuv=%rdx
andn  %rcx,%r10,%rdx

# qhasm: FVGS0 = stack_FVGS0
# asm 1: vmovapd <stack_FVGS0=stack256#2,>FVGS0=reg256#2
# asm 2: vmovapd <stack_FVGS0=160(%rsp),>FVGS0=%ymm1
vmovapd 160(%rsp),%ymm1

# qhasm: new uuss

# qhasm: uuss = u,uuss[1],0,0
# asm 1: vpinsrq $0x0,<u=int64#9,<uuss=reg256#3%128,<uuss=reg256#3%128
# asm 2: vpinsrq $0x0,<u=%r11,<uuss=%xmm2,<uuss=%xmm2
vpinsrq $0x0,%r11,%xmm2,%xmm2

# qhasm: uuss = uuss[0],s,0,0
# asm 1: vpinsrq $0x1,<s=int64#11,<uuss=reg256#3%128,<uuss=reg256#3%128
# asm 2: vpinsrq $0x1,<s=%r13,<uuss=%xmm2,<uuss=%xmm2
vpinsrq $0x1,%r13,%xmm2,%xmm2

# qhasm:   grs = g & ~ _m2p20
# asm 1: andn  <g=int64#1,<_m2p20=int64#8,>grs=int64#5
# asm 2: andn  <g=%rdi,<_m2p20=%r10,>grs=%r8
andn  %rdi,%r10,%r8

# qhasm:   fuv += stack_m2p41
# asm 1: addq <stack_m2p41=stack64#12,<fuv=int64#3
# asm 2: addq <stack_m2p41=88(%rsp),<fuv=%rdx
addq 88(%rsp),%rdx

# qhasm: GSFV0 = FVGS0[1,0]
# asm 1: vpermq $0x4e,<FVGS0=reg256#2,>GSFV0=reg256#4
# asm 2: vpermq $0x4e,<FVGS0=%ymm1,>GSFV0=%ymm3
vpermq $0x4e,%ymm1,%ymm3

# qhasm:   grs += stack_m2p62
# asm 1: addq <stack_m2p62=stack64#13,<grs=int64#5
# asm 2: addq <stack_m2p62=96(%rsp),<grs=%r8
addq 96(%rsp),%r8

# qhasm: uuss = uuss[0,0,1,1]
# asm 1: vpermq $0x50,<uuss=reg256#3,>uuss=reg256#3
# asm 2: vpermq $0x50,<uuss=%ymm2,>uuss=%ymm2
vpermq $0x50,%ymm2,%ymm2

# qhasm: vvrr = vvrr[0,0,1,1]
# asm 1: vpermq $0x50,<vvrr=reg256#1,>vvrr=reg256#1
# asm 2: vpermq $0x50,<vvrr=%ymm0,>vvrr=%ymm0
vpermq $0x50,%ymm0,%ymm0

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm4
vmovapd 1312(%rsp),%ymm4

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: uuss0 = uuss & _2p30m1x4
# asm 1: vpand <uuss=reg256#3,<_2p30m1x4=reg256#5,>uuss0=reg256#6
# asm 2: vpand <uuss=%ymm2,<_2p30m1x4=%ymm4,>uuss0=%ymm5
vpand %ymm2,%ymm4,%ymm5

# qhasm: vvrr0 = vvrr & _2p30m1x4 
# asm 1: vpand <vvrr=reg256#1,<_2p30m1x4=reg256#5,>vvrr0=reg256#7
# asm 2: vpand <vvrr=%ymm0,<_2p30m1x4=%ymm4,>vvrr0=%ymm6
vpand %ymm0,%ymm4,%ymm6

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: _2p63x4 = stack_2p63x4
# asm 1: vmovapd <stack_2p63x4=stack256#40,>_2p63x4=reg256#8
# asm 2: vmovapd <stack_2p63x4=1376(%rsp),>_2p63x4=%ymm7
vmovapd 1376(%rsp),%ymm7

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: uuss1 = uuss ^ _2p63x4
# asm 1: vpxor <uuss=reg256#3,<_2p63x4=reg256#8,>uuss1=reg256#3
# asm 2: vpxor <uuss=%ymm2,<_2p63x4=%ymm7,>uuss1=%ymm2
vpxor %ymm2,%ymm7,%ymm2

# qhasm: vvrr1 = vvrr ^ _2p63x4
# asm 1: vpxor <vvrr=reg256#1,<_2p63x4=reg256#8,>vvrr1=reg256#1
# asm 2: vpxor <vvrr=%ymm0,<_2p63x4=%ymm7,>vvrr1=%ymm0
vpxor %ymm0,%ymm7,%ymm0

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x uuss1 unsigned>>= 30
# asm 1: vpsrlq $30,<uuss1=reg256#3,<uuss1=reg256#3
# asm 2: vpsrlq $30,<uuss1=%ymm2,<uuss1=%ymm2
vpsrlq $30,%ymm2,%ymm2

# qhasm: 4x vvrr1 unsigned>>= 30
# asm 1: vpsrlq $30,<vvrr1=reg256#1,<vvrr1=reg256#1
# asm 2: vpsrlq $30,<vvrr1=%ymm0,<vvrr1=%ymm0
vpsrlq $30,%ymm0,%ymm0

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: _2p33x4 = stack_2p33x4
# asm 1: vmovapd <stack_2p33x4=stack256#39,>_2p33x4=reg256#9
# asm 2: vmovapd <stack_2p33x4=1344(%rsp),>_2p33x4=%ymm8
vmovapd 1344(%rsp),%ymm8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x uuss1 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#9,<uuss1=reg256#3,<uuss1=reg256#3
# asm 2: vpsubq <_2p33x4=%ymm8,<uuss1=%ymm2,<uuss1=%ymm2
vpsubq %ymm8,%ymm2,%ymm2

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x vvrr1 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#9,<vvrr1=reg256#1,<vvrr1=reg256#1
# asm 2: vpsubq <_2p33x4=%ymm8,<vvrr1=%ymm0,<vvrr1=%ymm0
vpsubq %ymm8,%ymm0,%ymm0

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x ta = int32 uuss0 * int32 FVGS0
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS0=reg256#2,>ta=reg256#9
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS0=%ymm1,>ta=%ymm8
vpmuldq %ymm5,%ymm1,%ymm8

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV0
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV0=reg256#4,>tb=reg256#10
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV0=%ymm3,>tb=%ymm9
vpmuldq %ymm6,%ymm3,%ymm9

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x out0 = ta + tb
# asm 1: vpaddq <tb=reg256#10,<ta=reg256#9,>out0=reg256#9
# asm 2: vpaddq <tb=%ymm9,<ta=%ymm8,>out0=%ymm8
vpaddq %ymm9,%ymm8,%ymm8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: minvx4 = 4x stack_minv
# asm 1: vpbroadcastq <stack_minv=stack64#9,>minvx4=reg256#10
# asm 2: vpbroadcastq <stack_minv=64(%rsp),>minvx4=%ymm9
vpbroadcastq 64(%rsp),%ymm9

# qhasm: mod0 = stack_mod0
# asm 1: vmovapd <stack_mod0=stack256#20,>mod0=reg256#11
# asm 2: vmovapd <stack_mod0=736(%rsp),>mod0=%ymm10
vmovapd 736(%rsp),%ymm10

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x d0 = int32 minvx4 * int32 out0
# asm 1: vpmuldq <minvx4=reg256#10,<out0=reg256#9,>d0=reg256#12
# asm 2: vpmuldq <minvx4=%ymm9,<out0=%ymm8,>d0=%ymm11
vpmuldq %ymm9,%ymm8,%ymm11

# qhasm: d0 &= _2p30m1x4
# asm 1: vpand <d0=reg256#12,<_2p30m1x4=reg256#5,<d0=reg256#12
# asm 2: vpand <d0=%ymm11,<_2p30m1x4=%ymm4,<d0=%ymm11
vpand %ymm11,%ymm4,%ymm11

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x ta = int32 mod0 * int32 d0
# asm 1: vpmuldq <mod0=reg256#11,<d0=reg256#12,>ta=reg256#13
# asm 2: vpmuldq <mod0=%ymm10,<d0=%ymm11,>ta=%ymm12
vpmuldq %ymm10,%ymm11,%ymm12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out0 += ta
# asm 1: vpaddq <out0=reg256#9,<ta=reg256#13,<out0=reg256#9
# asm 2: vpaddq <out0=%ymm8,<ta=%ymm12,<out0=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x carryy = out0 +_2p63x4
# asm 1: vpaddq <_2p63x4=reg256#8,<out0=reg256#9,>carryy=reg256#8
# asm 2: vpaddq <_2p63x4=%ymm7,<out0=%ymm8,>carryy=%ymm7
vpaddq %ymm7,%ymm8,%ymm7

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#8,<carryy=reg256#8
# asm 2: vpsrlq $30,<carryy=%ymm7,<carryy=%ymm7
vpsrlq $30,%ymm7,%ymm7

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: FVGS1 = stack_FVGS1
# asm 1: vmovapd <stack_FVGS1=stack256#3,>FVGS1=reg256#9
# asm 2: vmovapd <stack_FVGS1=192(%rsp),>FVGS1=%ymm8
vmovapd 192(%rsp),%ymm8

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: GSFV1 = FVGS1[1,0]
# asm 1: vpermq $0x4e,<FVGS1=reg256#9,>GSFV1=reg256#13
# asm 2: vpermq $0x4e,<FVGS1=%ymm8,>GSFV1=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod1 = stack_mod1
# asm 1: vmovapd <stack_mod1=stack256#21,>mod1=reg256#14
# asm 2: vmovapd <stack_mod1=768(%rsp),>mod1=%ymm13
vmovapd 768(%rsp),%ymm13

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS0
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS0=reg256#2,>ta=reg256#2
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS0=%ymm1,>ta=%ymm1
vpmuldq %ymm2,%ymm1,%ymm1

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV0
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV0=reg256#4,>tb=reg256#4
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV0=%ymm3,>tb=%ymm3
vpmuldq %ymm0,%ymm3,%ymm3

# qhasm: 4x out1plus = ta + tb
# asm 1: vpaddq <tb=reg256#4,<ta=reg256#2,>out1plus=reg256#2
# asm 2: vpaddq <tb=%ymm3,<ta=%ymm1,>out1plus=%ymm1
vpaddq %ymm3,%ymm1,%ymm1

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x ta = int32 uuss0 * int32 FVGS1
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS1=reg256#9,>ta=reg256#4
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS1=%ymm8,>ta=%ymm3
vpmuldq %ymm5,%ymm8,%ymm3

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV1
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV1=reg256#13,>tb=reg256#15
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV1=%ymm12,>tb=%ymm14
vpmuldq %ymm6,%ymm12,%ymm14

# qhasm: 4x out1 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#4,>out1=reg256#4
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm3,>out1=%ymm3
vpaddq %ymm14,%ymm3,%ymm3

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x out1 += out1plus
# asm 1: vpaddq <out1=reg256#4,<out1plus=reg256#2,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<out1plus=%ymm1,<out1=%ymm3
vpaddq %ymm3,%ymm1,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod1
# asm 1: vpmuldq <d0=reg256#12,<mod1=reg256#14,>ta=reg256#2
# asm 2: vpmuldq <d0=%ymm11,<mod1=%ymm13,>ta=%ymm1
vpmuldq %ymm11,%ymm13,%ymm1

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x ta += carryy
# asm 1: vpaddq <ta=reg256#2,<carryy=reg256#8,<ta=reg256#2
# asm 2: vpaddq <ta=%ymm1,<carryy=%ymm7,<ta=%ymm1
vpaddq %ymm1,%ymm7,%ymm1

# qhasm: 4x out1 += ta
# asm 1: vpaddq <out1=reg256#4,<ta=reg256#2,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<ta=%ymm1,<out1=%ymm3
vpaddq %ymm3,%ymm1,%ymm3

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x d1 = int32 minvx4 * int32 out1
# asm 1: vpmuldq <minvx4=reg256#10,<out1=reg256#4,>d1=reg256#2
# asm 2: vpmuldq <minvx4=%ymm9,<out1=%ymm3,>d1=%ymm1
vpmuldq %ymm9,%ymm3,%ymm1

# qhasm: d1 &= _2p30m1x4
# asm 1: vpand <d1=reg256#2,<_2p30m1x4=reg256#5,<d1=reg256#2
# asm 2: vpand <d1=%ymm1,<_2p30m1x4=%ymm4,<d1=%ymm1
vpand %ymm1,%ymm4,%ymm1

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x ta = int32 mod0 * int32 d1
# asm 1: vpmuldq <mod0=reg256#11,<d1=reg256#2,>ta=reg256#8
# asm 2: vpmuldq <mod0=%ymm10,<d1=%ymm1,>ta=%ymm7
vpmuldq %ymm10,%ymm1,%ymm7

# qhasm: 4x out1 += ta
# asm 1: vpaddq <out1=reg256#4,<ta=reg256#8,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<ta=%ymm7,<out1=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#8
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm7
vmovapd 1408(%rsp),%ymm7

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x carryy = out1 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out1=reg256#4,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out1=%ymm3,>carryy=%ymm3
vpaddq %ymm7,%ymm3,%ymm3

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: FVGS2 = stack_FVGS2
# asm 1: vmovapd <stack_FVGS2=stack256#4,>FVGS2=reg256#10
# asm 2: vmovapd <stack_FVGS2=224(%rsp),>FVGS2=%ymm9
vmovapd 224(%rsp),%ymm9

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: GSFV2 = FVGS2[1,0]
# asm 1: vpermq $0x4e,<FVGS2=reg256#10,>GSFV2=reg256#11
# asm 2: vpermq $0x4e,<FVGS2=%ymm9,>GSFV2=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: mod2 = stack_mod2
# asm 1: vmovapd <stack_mod2=stack256#22,>mod2=reg256#15
# asm 2: vmovapd <stack_mod2=800(%rsp),>mod2=%ymm14
vmovapd 800(%rsp),%ymm14

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x ta = int32 uuss1 * int32 FVGS1
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS1=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS1=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV1
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV1=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV1=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out2plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out2plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out2plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS2
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS2=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS2=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV2
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV2=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV2=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out2 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out2=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out2=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out2 += out2plus
# asm 1: vpaddq <out2=reg256#13,<out2plus=reg256#9,<out2=reg256#13
# asm 2: vpaddq <out2=%ymm12,<out2plus=%ymm8,<out2=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x ta = int32 d0 * int32 mod2
# asm 1: vpmuldq <d0=reg256#12,<mod2=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod2=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x tb = int32 d1 * int32 mod1
# asm 1: vpmuldq <d1=reg256#2,<mod1=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod1=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out2plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out2plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out2plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out2plus2 += carryy
# asm 1: vpaddq <out2plus2=reg256#9,<carryy=reg256#4,<out2plus2=reg256#9
# asm 2: vpaddq <out2plus2=%ymm8,<carryy=%ymm3,<out2plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out2 += out2plus2
# asm 1: vpaddq <out2=reg256#13,<out2plus2=reg256#9,<out2=reg256#13
# asm 2: vpaddq <out2=%ymm12,<out2plus2=%ymm8,<out2=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x carryy = out2 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out2=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out2=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: out2 &= _2p30m1x4
# asm 1: vpand <out2=reg256#13,<_2p30m1x4=reg256#5,<out2=reg256#13
# asm 2: vpand <out2=%ymm12,<_2p30m1x4=%ymm4,<out2=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS0 = out2
# asm 1: vmovapd <out2=reg256#13,>stack_FVGS0=stack256#2
# asm 2: vmovapd <out2=%ymm12,>stack_FVGS0=160(%rsp)
vmovapd %ymm12,160(%rsp)

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: FVGS3 = stack_FVGS3
# asm 1: vmovapd <stack_FVGS3=stack256#5,>FVGS3=reg256#9
# asm 2: vmovapd <stack_FVGS3=256(%rsp),>FVGS3=%ymm8
vmovapd 256(%rsp),%ymm8

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: GSFV3 = FVGS3[1,0]
# asm 1: vpermq $0x4e,<FVGS3=reg256#9,>GSFV3=reg256#13
# asm 2: vpermq $0x4e,<FVGS3=%ymm8,>GSFV3=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: mod3 = stack_mod3
# asm 1: vmovapd <stack_mod3=stack256#23,>mod3=reg256#14
# asm 2: vmovapd <stack_mod3=832(%rsp),>mod3=%ymm13
vmovapd 832(%rsp),%ymm13

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x ta = int32 uuss1 * int32 FVGS2
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS2=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS2=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV2
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV2=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV2=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out3plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out3plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out3plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x ta = int32 uuss0 * int32 FVGS3
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS3=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS3=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV3
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV3=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV3=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x out3 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out3=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out3=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out3 += out3plus
# asm 1: vpaddq <out3=reg256#11,<out3plus=reg256#10,<out3=reg256#11
# asm 2: vpaddq <out3=%ymm10,<out3plus=%ymm9,<out3=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod3
# asm 1: vpmuldq <d0=reg256#12,<mod3=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod3=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x tb = int32 d1 * int32 mod2
# asm 1: vpmuldq <d1=reg256#2,<mod2=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod2=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out3plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out3plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out3plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out3plus2 += carryy
# asm 1: vpaddq <out3plus2=reg256#10,<carryy=reg256#4,<out3plus2=reg256#10
# asm 2: vpaddq <out3plus2=%ymm9,<carryy=%ymm3,<out3plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out3 += out3plus2
# asm 1: vpaddq <out3=reg256#11,<out3plus2=reg256#10,<out3=reg256#11
# asm 2: vpaddq <out3=%ymm10,<out3plus2=%ymm9,<out3=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x carryy = out3 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out3=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out3=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out3 &= _2p30m1x4
# asm 1: vpand <out3=reg256#11,<_2p30m1x4=reg256#5,<out3=reg256#11
# asm 2: vpand <out3=%ymm10,<_2p30m1x4=%ymm4,<out3=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: stack_FVGS1 = out3
# asm 1: vmovapd <out3=reg256#11,>stack_FVGS1=stack256#3
# asm 2: vmovapd <out3=%ymm10,>stack_FVGS1=192(%rsp)
vmovapd %ymm10,192(%rsp)

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: FVGS4 = stack_FVGS4
# asm 1: vmovapd <stack_FVGS4=stack256#6,>FVGS4=reg256#10
# asm 2: vmovapd <stack_FVGS4=288(%rsp),>FVGS4=%ymm9
vmovapd 288(%rsp),%ymm9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: GSFV4 = FVGS4[1,0]
# asm 1: vpermq $0x4e,<FVGS4=reg256#10,>GSFV4=reg256#11
# asm 2: vpermq $0x4e,<FVGS4=%ymm9,>GSFV4=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod4 = stack_mod4
# asm 1: vmovapd <stack_mod4=stack256#24,>mod4=reg256#15
# asm 2: vmovapd <stack_mod4=864(%rsp),>mod4=%ymm14
vmovapd 864(%rsp),%ymm14

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x ta = int32 uuss1 * int32 FVGS3
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS3=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS3=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV3
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV3=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV3=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x out4plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out4plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out4plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS4
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS4=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS4=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV4
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV4=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV4=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out4 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out4=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out4=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out4 += out4plus
# asm 1: vpaddq <out4=reg256#13,<out4plus=reg256#9,<out4=reg256#13
# asm 2: vpaddq <out4=%ymm12,<out4plus=%ymm8,<out4=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x ta = int32 d0 * int32 mod4
# asm 1: vpmuldq <d0=reg256#12,<mod4=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod4=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x tb = int32 d1 * int32 mod3
# asm 1: vpmuldq <d1=reg256#2,<mod3=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod3=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x out4plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out4plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out4plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out4plus2 += carryy
# asm 1: vpaddq <out4plus2=reg256#9,<carryy=reg256#4,<out4plus2=reg256#9
# asm 2: vpaddq <out4plus2=%ymm8,<carryy=%ymm3,<out4plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out4 += out4plus2
# asm 1: vpaddq <out4=reg256#13,<out4plus2=reg256#9,<out4=reg256#13
# asm 2: vpaddq <out4=%ymm12,<out4plus2=%ymm8,<out4=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out4 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out4=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out4=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: out4 &= _2p30m1x4
# asm 1: vpand <out4=reg256#13,<_2p30m1x4=reg256#5,<out4=reg256#13
# asm 2: vpand <out4=%ymm12,<_2p30m1x4=%ymm4,<out4=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: stack_FVGS2 = out4
# asm 1: vmovapd <out4=reg256#13,>stack_FVGS2=stack256#4
# asm 2: vmovapd <out4=%ymm12,>stack_FVGS2=224(%rsp)
vmovapd %ymm12,224(%rsp)

# qhasm: FVGS5 = stack_FVGS5
# asm 1: vmovapd <stack_FVGS5=stack256#7,>FVGS5=reg256#9
# asm 2: vmovapd <stack_FVGS5=320(%rsp),>FVGS5=%ymm8
vmovapd 320(%rsp),%ymm8

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: GSFV5 = FVGS5[1,0]
# asm 1: vpermq $0x4e,<FVGS5=reg256#9,>GSFV5=reg256#13
# asm 2: vpermq $0x4e,<FVGS5=%ymm8,>GSFV5=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: mod5 = stack_mod5
# asm 1: vmovapd <stack_mod5=stack256#25,>mod5=reg256#14
# asm 2: vmovapd <stack_mod5=896(%rsp),>mod5=%ymm13
vmovapd 896(%rsp),%ymm13

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x ta = int32 uuss1 * int32 FVGS4
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS4=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS4=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV4
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV4=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV4=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out5plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out5plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out5plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x ta = int32 uuss0 * int32 FVGS5
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS5=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS5=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV5
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV5=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV5=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out5 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out5=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out5=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out5 += out5plus
# asm 1: vpaddq <out5=reg256#11,<out5plus=reg256#10,<out5=reg256#11
# asm 2: vpaddq <out5=%ymm10,<out5plus=%ymm9,<out5=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x ta = int32 d0 * int32 mod5
# asm 1: vpmuldq <d0=reg256#12,<mod5=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod5=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod4
# asm 1: vpmuldq <d1=reg256#2,<mod4=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod4=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x out5plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out5plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out5plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out5plus2 += carryy
# asm 1: vpaddq <out5plus2=reg256#10,<carryy=reg256#4,<out5plus2=reg256#10
# asm 2: vpaddq <out5plus2=%ymm9,<carryy=%ymm3,<out5plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out5 += out5plus2
# asm 1: vpaddq <out5=reg256#11,<out5plus2=reg256#10,<out5=reg256#11
# asm 2: vpaddq <out5=%ymm10,<out5plus2=%ymm9,<out5=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out5 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out5=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out5=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: out5 &= _2p30m1x4
# asm 1: vpand <out5=reg256#11,<_2p30m1x4=reg256#5,<out5=reg256#11
# asm 2: vpand <out5=%ymm10,<_2p30m1x4=%ymm4,<out5=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: stack_FVGS3 = out5
# asm 1: vmovapd <out5=reg256#11,>stack_FVGS3=stack256#5
# asm 2: vmovapd <out5=%ymm10,>stack_FVGS3=256(%rsp)
vmovapd %ymm10,256(%rsp)

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: FVGS6 = stack_FVGS6
# asm 1: vmovapd <stack_FVGS6=stack256#8,>FVGS6=reg256#10
# asm 2: vmovapd <stack_FVGS6=352(%rsp),>FVGS6=%ymm9
vmovapd 352(%rsp),%ymm9

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: GSFV6 = FVGS6[1,0]
# asm 1: vpermq $0x4e,<FVGS6=reg256#10,>GSFV6=reg256#11
# asm 2: vpermq $0x4e,<FVGS6=%ymm9,>GSFV6=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod6 = stack_mod6
# asm 1: vmovapd <stack_mod6=stack256#26,>mod6=reg256#15
# asm 2: vmovapd <stack_mod6=928(%rsp),>mod6=%ymm14
vmovapd 928(%rsp),%ymm14

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS5
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS5=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS5=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV5
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV5=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV5=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out6plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out6plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out6plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x ta = int32 uuss0 * int32 FVGS6
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS6=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS6=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV6
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV6=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV6=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out6 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out6=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out6=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out6 += out6plus
# asm 1: vpaddq <out6=reg256#13,<out6plus=reg256#9,<out6=reg256#13
# asm 2: vpaddq <out6=%ymm12,<out6plus=%ymm8,<out6=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x ta = int32 d0 * int32 mod6
# asm 1: vpmuldq <d0=reg256#12,<mod6=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod6=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod5
# asm 1: vpmuldq <d1=reg256#2,<mod5=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod5=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out6plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out6plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out6plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out6plus2 += carryy
# asm 1: vpaddq <out6plus2=reg256#9,<carryy=reg256#4,<out6plus2=reg256#9
# asm 2: vpaddq <out6plus2=%ymm8,<carryy=%ymm3,<out6plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out6 += out6plus2
# asm 1: vpaddq <out6=reg256#13,<out6plus2=reg256#9,<out6=reg256#13
# asm 2: vpaddq <out6=%ymm12,<out6plus2=%ymm8,<out6=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x carryy = out6 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out6=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out6=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out6 &= _2p30m1x4
# asm 1: vpand <out6=reg256#13,<_2p30m1x4=reg256#5,<out6=reg256#13
# asm 2: vpand <out6=%ymm12,<_2p30m1x4=%ymm4,<out6=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: stack_FVGS4 = out6
# asm 1: vmovapd <out6=reg256#13,>stack_FVGS4=stack256#6
# asm 2: vmovapd <out6=%ymm12,>stack_FVGS4=288(%rsp)
vmovapd %ymm12,288(%rsp)

# qhasm: FVGS7 = stack_FVGS7
# asm 1: vmovapd <stack_FVGS7=stack256#9,>FVGS7=reg256#9
# asm 2: vmovapd <stack_FVGS7=384(%rsp),>FVGS7=%ymm8
vmovapd 384(%rsp),%ymm8

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: GSFV7 = FVGS7[1,0]
# asm 1: vpermq $0x4e,<FVGS7=reg256#9,>GSFV7=reg256#13
# asm 2: vpermq $0x4e,<FVGS7=%ymm8,>GSFV7=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: mod7 = stack_mod7
# asm 1: vmovapd <stack_mod7=stack256#27,>mod7=reg256#14
# asm 2: vmovapd <stack_mod7=960(%rsp),>mod7=%ymm13
vmovapd 960(%rsp),%ymm13

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x ta = int32 uuss1 * int32 FVGS6
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS6=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS6=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV6
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV6=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV6=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x out7plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out7plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out7plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x ta = int32 uuss0 * int32 FVGS7
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS7=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS7=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV7
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV7=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV7=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x out7 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out7=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out7=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x out7 += out7plus
# asm 1: vpaddq <out7=reg256#11,<out7plus=reg256#10,<out7=reg256#11
# asm 2: vpaddq <out7=%ymm10,<out7plus=%ymm9,<out7=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod7
# asm 1: vpmuldq <d0=reg256#12,<mod7=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod7=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod6
# asm 1: vpmuldq <d1=reg256#2,<mod6=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod6=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out7plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out7plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out7plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out7plus2 += carryy
# asm 1: vpaddq <out7plus2=reg256#10,<carryy=reg256#4,<out7plus2=reg256#10
# asm 2: vpaddq <out7plus2=%ymm9,<carryy=%ymm3,<out7plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x out7 += out7plus2
# asm 1: vpaddq <out7=reg256#11,<out7plus2=reg256#10,<out7=reg256#11
# asm 2: vpaddq <out7=%ymm10,<out7plus2=%ymm9,<out7=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out7 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out7=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out7=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: out7 &= _2p30m1x4
# asm 1: vpand <out7=reg256#11,<_2p30m1x4=reg256#5,<out7=reg256#11
# asm 2: vpand <out7=%ymm10,<_2p30m1x4=%ymm4,<out7=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS5 = out7
# asm 1: vmovapd <out7=reg256#11,>stack_FVGS5=stack256#7
# asm 2: vmovapd <out7=%ymm10,>stack_FVGS5=320(%rsp)
vmovapd %ymm10,320(%rsp)

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: FVGS8 = stack_FVGS8
# asm 1: vmovapd <stack_FVGS8=stack256#10,>FVGS8=reg256#10
# asm 2: vmovapd <stack_FVGS8=416(%rsp),>FVGS8=%ymm9
vmovapd 416(%rsp),%ymm9

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: GSFV8 = FVGS8[1,0]
# asm 1: vpermq $0x4e,<FVGS8=reg256#10,>GSFV8=reg256#11
# asm 2: vpermq $0x4e,<FVGS8=%ymm9,>GSFV8=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: mod8 = stack_mod8
# asm 1: vmovapd <stack_mod8=stack256#28,>mod8=reg256#15
# asm 2: vmovapd <stack_mod8=992(%rsp),>mod8=%ymm14
vmovapd 992(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS7
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS7=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS7=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV7
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV7=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV7=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out8plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out8plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out8plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS8
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS8=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS8=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV8
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV8=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV8=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x out8 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out8=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out8=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out8 += out8plus
# asm 1: vpaddq <out8=reg256#13,<out8plus=reg256#9,<out8=reg256#13
# asm 2: vpaddq <out8=%ymm12,<out8plus=%ymm8,<out8=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod8
# asm 1: vpmuldq <d0=reg256#12,<mod8=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod8=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x tb = int32 d1 * int32 mod7
# asm 1: vpmuldq <d1=reg256#2,<mod7=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod7=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm: 4x out8plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out8plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out8plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out8plus2 += carryy
# asm 1: vpaddq <out8plus2=reg256#9,<carryy=reg256#4,<out8plus2=reg256#9
# asm 2: vpaddq <out8plus2=%ymm8,<carryy=%ymm3,<out8plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out8 += out8plus2
# asm 1: vpaddq <out8=reg256#13,<out8plus2=reg256#9,<out8=reg256#13
# asm 2: vpaddq <out8=%ymm12,<out8plus2=%ymm8,<out8=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x carryy = out8 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out8=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out8=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: out8 &= _2p30m1x4
# asm 1: vpand <out8=reg256#13,<_2p30m1x4=reg256#5,<out8=reg256#13
# asm 2: vpand <out8=%ymm12,<_2p30m1x4=%ymm4,<out8=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: stack_FVGS6 = out8
# asm 1: vmovapd <out8=reg256#13,>stack_FVGS6=stack256#8
# asm 2: vmovapd <out8=%ymm12,>stack_FVGS6=352(%rsp)
vmovapd %ymm12,352(%rsp)

# qhasm: FVGS9 = stack_FVGS9
# asm 1: vmovapd <stack_FVGS9=stack256#11,>FVGS9=reg256#9
# asm 2: vmovapd <stack_FVGS9=448(%rsp),>FVGS9=%ymm8
vmovapd 448(%rsp),%ymm8

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: GSFV9 = FVGS9[1,0]
# asm 1: vpermq $0x4e,<FVGS9=reg256#9,>GSFV9=reg256#13
# asm 2: vpermq $0x4e,<FVGS9=%ymm8,>GSFV9=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod9 = stack_mod9
# asm 1: vmovapd <stack_mod9=stack256#29,>mod9=reg256#14
# asm 2: vmovapd <stack_mod9=1024(%rsp),>mod9=%ymm13
vmovapd 1024(%rsp),%ymm13

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x ta = int32 uuss1 * int32 FVGS8
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS8=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS8=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV8
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV8=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV8=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x out9plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out9plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out9plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS9
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS9=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS9=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV9
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV9=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV9=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out9 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out9=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out9=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out9 += out9plus
# asm 1: vpaddq <out9=reg256#11,<out9plus=reg256#10,<out9=reg256#11
# asm 2: vpaddq <out9=%ymm10,<out9plus=%ymm9,<out9=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod9
# asm 1: vpmuldq <d0=reg256#12,<mod9=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod9=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x tb = int32 d1 * int32 mod8
# asm 1: vpmuldq <d1=reg256#2,<mod8=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod8=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out9plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out9plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out9plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out9plus2 += carryy
# asm 1: vpaddq <out9plus2=reg256#10,<carryy=reg256#4,<out9plus2=reg256#10
# asm 2: vpaddq <out9plus2=%ymm9,<carryy=%ymm3,<out9plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out9 += out9plus2
# asm 1: vpaddq <out9=reg256#11,<out9plus2=reg256#10,<out9=reg256#11
# asm 2: vpaddq <out9=%ymm10,<out9plus2=%ymm9,<out9=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out9 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out9=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out9=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out9 &= _2p30m1x4
# asm 1: vpand <out9=reg256#11,<_2p30m1x4=reg256#5,<out9=reg256#11
# asm 2: vpand <out9=%ymm10,<_2p30m1x4=%ymm4,<out9=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: stack_FVGS7 = out9
# asm 1: vmovapd <out9=reg256#11,>stack_FVGS7=stack256#9
# asm 2: vmovapd <out9=%ymm10,>stack_FVGS7=384(%rsp)
vmovapd %ymm10,384(%rsp)

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: FVGS10 = stack_FVGS10
# asm 1: vmovapd <stack_FVGS10=stack256#12,>FVGS10=reg256#10
# asm 2: vmovapd <stack_FVGS10=480(%rsp),>FVGS10=%ymm9
vmovapd 480(%rsp),%ymm9

# qhasm: GSFV10 = FVGS10[1,0]
# asm 1: vpermq $0x4e,<FVGS10=reg256#10,>GSFV10=reg256#11
# asm 2: vpermq $0x4e,<FVGS10=%ymm9,>GSFV10=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: mod10 = stack_mod10
# asm 1: vmovapd <stack_mod10=stack256#30,>mod10=reg256#15
# asm 2: vmovapd <stack_mod10=1056(%rsp),>mod10=%ymm14
vmovapd 1056(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS9
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS9=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS9=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV9
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV9=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV9=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out10plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out10plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out10plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS10
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS10=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS10=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV10
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV10=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV10=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out10 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out10=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out10=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm: 4x out10 += out10plus
# asm 1: vpaddq <out10=reg256#13,<out10plus=reg256#9,<out10=reg256#13
# asm 2: vpaddq <out10=%ymm12,<out10plus=%ymm8,<out10=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x ta = int32 d0 * int32 mod10
# asm 1: vpmuldq <d0=reg256#12,<mod10=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod10=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x tb = int32 d1 * int32 mod9
# asm 1: vpmuldq <d1=reg256#2,<mod9=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod9=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out10plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out10plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out10plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out10plus2 += carryy
# asm 1: vpaddq <out10plus2=reg256#9,<carryy=reg256#4,<out10plus2=reg256#9
# asm 2: vpaddq <out10plus2=%ymm8,<carryy=%ymm3,<out10plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x out10 += out10plus2
# asm 1: vpaddq <out10=reg256#13,<out10plus2=reg256#9,<out10=reg256#13
# asm 2: vpaddq <out10=%ymm12,<out10plus2=%ymm8,<out10=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x carryy = out10 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out10=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out10=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: out10 &= _2p30m1x4
# asm 1: vpand <out10=reg256#13,<_2p30m1x4=reg256#5,<out10=reg256#13
# asm 2: vpand <out10=%ymm12,<_2p30m1x4=%ymm4,<out10=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS8 = out10
# asm 1: vmovapd <out10=reg256#13,>stack_FVGS8=stack256#10
# asm 2: vmovapd <out10=%ymm12,>stack_FVGS8=416(%rsp)
vmovapd %ymm12,416(%rsp)

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: FVGS11 = stack_FVGS11
# asm 1: vmovapd <stack_FVGS11=stack256#13,>FVGS11=reg256#9
# asm 2: vmovapd <stack_FVGS11=512(%rsp),>FVGS11=%ymm8
vmovapd 512(%rsp),%ymm8

# qhasm: GSFV11 = FVGS11[1,0]
# asm 1: vpermq $0x4e,<FVGS11=reg256#9,>GSFV11=reg256#13
# asm 2: vpermq $0x4e,<FVGS11=%ymm8,>GSFV11=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: mod11 = stack_mod11
# asm 1: vmovapd <stack_mod11=stack256#31,>mod11=reg256#14
# asm 2: vmovapd <stack_mod11=1088(%rsp),>mod11=%ymm13
vmovapd 1088(%rsp),%ymm13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS10
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS10=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS10=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV10
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV10=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV10=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x out11plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out11plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out11plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS11
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS11=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS11=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV11
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV11=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV11=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out11 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out11=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out11=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm: 4x out11 += out11plus
# asm 1: vpaddq <out11=reg256#11,<out11plus=reg256#10,<out11=reg256#11
# asm 2: vpaddq <out11=%ymm10,<out11plus=%ymm9,<out11=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x ta = int32 d0 * int32 mod11
# asm 1: vpmuldq <d0=reg256#12,<mod11=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod11=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x tb = int32 d1 * int32 mod10
# asm 1: vpmuldq <d1=reg256#2,<mod10=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod10=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out11plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out11plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out11plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out11plus2 += carryy
# asm 1: vpaddq <out11plus2=reg256#10,<carryy=reg256#4,<out11plus2=reg256#10
# asm 2: vpaddq <out11plus2=%ymm9,<carryy=%ymm3,<out11plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out11 += out11plus2
# asm 1: vpaddq <out11=reg256#11,<out11plus2=reg256#10,<out11=reg256#11
# asm 2: vpaddq <out11=%ymm10,<out11plus2=%ymm9,<out11=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out11 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out11=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out11=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out11 &= _2p30m1x4
# asm 1: vpand <out11=reg256#11,<_2p30m1x4=reg256#5,<out11=reg256#11
# asm 2: vpand <out11=%ymm10,<_2p30m1x4=%ymm4,<out11=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: stack_FVGS9 = out11
# asm 1: vmovapd <out11=reg256#11,>stack_FVGS9=stack256#11
# asm 2: vmovapd <out11=%ymm10,>stack_FVGS9=448(%rsp)
vmovapd %ymm10,448(%rsp)

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: FVGS12 = stack_FVGS12
# asm 1: vmovapd <stack_FVGS12=stack256#14,>FVGS12=reg256#10
# asm 2: vmovapd <stack_FVGS12=544(%rsp),>FVGS12=%ymm9
vmovapd 544(%rsp),%ymm9

# qhasm: GSFV12 = FVGS12[1,0]
# asm 1: vpermq $0x4e,<FVGS12=reg256#10,>GSFV12=reg256#11
# asm 2: vpermq $0x4e,<FVGS12=%ymm9,>GSFV12=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: mod12 = stack_mod12
# asm 1: vmovapd <stack_mod12=stack256#32,>mod12=reg256#15
# asm 2: vmovapd <stack_mod12=1120(%rsp),>mod12=%ymm14
vmovapd 1120(%rsp),%ymm14

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS11
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS11=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS11=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV11
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV11=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV11=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out12plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out12plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out12plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS12
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS12=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS12=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV12
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV12=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV12=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out12 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out12=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out12=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out12 += out12plus
# asm 1: vpaddq <out12=reg256#13,<out12plus=reg256#9,<out12=reg256#13
# asm 2: vpaddq <out12=%ymm12,<out12plus=%ymm8,<out12=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod12
# asm 1: vpmuldq <d0=reg256#12,<mod12=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod12=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x tb = int32 d1 * int32 mod11
# asm 1: vpmuldq <d1=reg256#2,<mod11=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod11=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out12plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out12plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out12plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out12plus2 += carryy
# asm 1: vpaddq <out12plus2=reg256#9,<carryy=reg256#4,<out12plus2=reg256#9
# asm 2: vpaddq <out12plus2=%ymm8,<carryy=%ymm3,<out12plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x out12 += out12plus2
# asm 1: vpaddq <out12=reg256#13,<out12plus2=reg256#9,<out12=reg256#13
# asm 2: vpaddq <out12=%ymm12,<out12plus2=%ymm8,<out12=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out12 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out12=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out12=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: out12 &= _2p30m1x4
# asm 1: vpand <out12=reg256#13,<_2p30m1x4=reg256#5,<out12=reg256#13
# asm 2: vpand <out12=%ymm12,<_2p30m1x4=%ymm4,<out12=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS10 = out12
# asm 1: vmovapd <out12=reg256#13,>stack_FVGS10=stack256#12
# asm 2: vmovapd <out12=%ymm12,>stack_FVGS10=480(%rsp)
vmovapd %ymm12,480(%rsp)

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: FVGS13 = stack_FVGS13
# asm 1: vmovapd <stack_FVGS13=stack256#15,>FVGS13=reg256#9
# asm 2: vmovapd <stack_FVGS13=576(%rsp),>FVGS13=%ymm8
vmovapd 576(%rsp),%ymm8

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: GSFV13 = FVGS13[1,0]
# asm 1: vpermq $0x4e,<FVGS13=reg256#9,>GSFV13=reg256#13
# asm 2: vpermq $0x4e,<FVGS13=%ymm8,>GSFV13=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: mod13 = stack_mod13
# asm 1: vmovapd <stack_mod13=stack256#33,>mod13=reg256#14
# asm 2: vmovapd <stack_mod13=1152(%rsp),>mod13=%ymm13
vmovapd 1152(%rsp),%ymm13

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x ta = int32 uuss1 * int32 FVGS12
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS12=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS12=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV12
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV12=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV12=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out13plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out13plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out13plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS13
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS13=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS13=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV13
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV13=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV13=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out13 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out13=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out13=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm: 4x out13 += out13plus
# asm 1: vpaddq <out13=reg256#11,<out13plus=reg256#10,<out13=reg256#11
# asm 2: vpaddq <out13=%ymm10,<out13plus=%ymm9,<out13=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod13
# asm 1: vpmuldq <d0=reg256#12,<mod13=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod13=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x tb = int32 d1 * int32 mod12
# asm 1: vpmuldq <d1=reg256#2,<mod12=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod12=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out13plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out13plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out13plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out13plus2 += carryy
# asm 1: vpaddq <out13plus2=reg256#10,<carryy=reg256#4,<out13plus2=reg256#10
# asm 2: vpaddq <out13plus2=%ymm9,<carryy=%ymm3,<out13plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out13 += out13plus2
# asm 1: vpaddq <out13=reg256#11,<out13plus2=reg256#10,<out13=reg256#11
# asm 2: vpaddq <out13=%ymm10,<out13plus2=%ymm9,<out13=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x carryy = out13 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out13=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out13=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: out13 &= _2p30m1x4
# asm 1: vpand <out13=reg256#11,<_2p30m1x4=reg256#5,<out13=reg256#11
# asm 2: vpand <out13=%ymm10,<_2p30m1x4=%ymm4,<out13=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS11 = out13
# asm 1: vmovapd <out13=reg256#11,>stack_FVGS11=stack256#13
# asm 2: vmovapd <out13=%ymm10,>stack_FVGS11=512(%rsp)
vmovapd %ymm10,512(%rsp)

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: FVGS14 = stack_FVGS14
# asm 1: vmovapd <stack_FVGS14=stack256#16,>FVGS14=reg256#10
# asm 2: vmovapd <stack_FVGS14=608(%rsp),>FVGS14=%ymm9
vmovapd 608(%rsp),%ymm9

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: GSFV14 = FVGS14[1,0]
# asm 1: vpermq $0x4e,<FVGS14=reg256#10,>GSFV14=reg256#11
# asm 2: vpermq $0x4e,<FVGS14=%ymm9,>GSFV14=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: mod14 = stack_mod14
# asm 1: vmovapd <stack_mod14=stack256#34,>mod14=reg256#15
# asm 2: vmovapd <stack_mod14=1184(%rsp),>mod14=%ymm14
vmovapd 1184(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS13
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS13=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS13=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV13
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV13=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV13=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out14plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out14plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out14plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS14
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS14=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS14=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV14
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV14=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV14=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out14 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out14=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out14=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x out14 += out14plus
# asm 1: vpaddq <out14=reg256#13,<out14plus=reg256#9,<out14=reg256#13
# asm 2: vpaddq <out14=%ymm12,<out14plus=%ymm8,<out14=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod14
# asm 1: vpmuldq <d0=reg256#12,<mod14=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod14=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod13
# asm 1: vpmuldq <d1=reg256#2,<mod13=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod13=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out14plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out14plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out14plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out14plus2 += carryy
# asm 1: vpaddq <out14plus2=reg256#9,<carryy=reg256#4,<out14plus2=reg256#9
# asm 2: vpaddq <out14plus2=%ymm8,<carryy=%ymm3,<out14plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out14 += out14plus2
# asm 1: vpaddq <out14=reg256#13,<out14plus2=reg256#9,<out14=reg256#13
# asm 2: vpaddq <out14=%ymm12,<out14plus2=%ymm8,<out14=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x carryy = out14 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out14=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out14=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: out14 &= _2p30m1x4
# asm 1: vpand <out14=reg256#13,<_2p30m1x4=reg256#5,<out14=reg256#13
# asm 2: vpand <out14=%ymm12,<_2p30m1x4=%ymm4,<out14=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: stack_FVGS12 = out14
# asm 1: vmovapd <out14=reg256#13,>stack_FVGS12=stack256#14
# asm 2: vmovapd <out14=%ymm12,>stack_FVGS12=544(%rsp)
vmovapd %ymm12,544(%rsp)

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: FVGS15 = stack_FVGS15
# asm 1: vmovapd <stack_FVGS15=stack256#17,>FVGS15=reg256#9
# asm 2: vmovapd <stack_FVGS15=640(%rsp),>FVGS15=%ymm8
vmovapd 640(%rsp),%ymm8

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: GSFV15 = FVGS15[1,0]
# asm 1: vpermq $0x4e,<FVGS15=reg256#9,>GSFV15=reg256#13
# asm 2: vpermq $0x4e,<FVGS15=%ymm8,>GSFV15=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod15 = stack_mod15
# asm 1: vmovapd <stack_mod15=stack256#35,>mod15=reg256#14
# asm 2: vmovapd <stack_mod15=1216(%rsp),>mod15=%ymm13
vmovapd 1216(%rsp),%ymm13

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x ta = int32 uuss1 * int32 FVGS14
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS14=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS14=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV14
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV14=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV14=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out15plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out15plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out15plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS15
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS15=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS15=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV15
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV15=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV15=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out15 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out15=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out15=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out15 += out15plus
# asm 1: vpaddq <out15=reg256#11,<out15plus=reg256#10,<out15=reg256#11
# asm 2: vpaddq <out15=%ymm10,<out15plus=%ymm9,<out15=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x ta = int32 d0 * int32 mod15
# asm 1: vpmuldq <d0=reg256#12,<mod15=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod15=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x tb = int32 d1 * int32 mod14
# asm 1: vpmuldq <d1=reg256#2,<mod14=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod14=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out15plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out15plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out15plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out15plus2 += carryy
# asm 1: vpaddq <out15plus2=reg256#10,<carryy=reg256#4,<out15plus2=reg256#10
# asm 2: vpaddq <out15plus2=%ymm9,<carryy=%ymm3,<out15plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out15 += out15plus2
# asm 1: vpaddq <out15=reg256#11,<out15plus2=reg256#10,<out15=reg256#11
# asm 2: vpaddq <out15=%ymm10,<out15plus2=%ymm9,<out15=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out15 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out15=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out15=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out15 &= _2p30m1x4
# asm 1: vpand <out15=reg256#11,<_2p30m1x4=reg256#5,<out15=reg256#11
# asm 2: vpand <out15=%ymm10,<_2p30m1x4=%ymm4,<out15=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: stack_FVGS13 = out15
# asm 1: vmovapd <out15=reg256#11,>stack_FVGS13=stack256#15
# asm 2: vmovapd <out15=%ymm10,>stack_FVGS13=576(%rsp)
vmovapd %ymm10,576(%rsp)

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: FVGS16 = stack_FVGS16
# asm 1: vmovapd <stack_FVGS16=stack256#18,>FVGS16=reg256#10
# asm 2: vmovapd <stack_FVGS16=672(%rsp),>FVGS16=%ymm9
vmovapd 672(%rsp),%ymm9

# qhasm: GSFV16 = FVGS16[1,0]
# asm 1: vpermq $0x4e,<FVGS16=reg256#10,>GSFV16=reg256#11
# asm 2: vpermq $0x4e,<FVGS16=%ymm9,>GSFV16=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: mod16 = stack_mod16
# asm 1: vmovapd <stack_mod16=stack256#36,>mod16=reg256#15
# asm 2: vmovapd <stack_mod16=1248(%rsp),>mod16=%ymm14
vmovapd 1248(%rsp),%ymm14

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x ta = int32 uuss1 * int32 FVGS15
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS15=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS15=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV15
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV15=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV15=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out16plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out16plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out16plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x ta = int32 uuss0 * int32 FVGS16
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS16=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS16=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV16
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV16=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV16=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out16 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out16=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out16=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x out16 += out16plus
# asm 1: vpaddq <out16=reg256#13,<out16plus=reg256#9,<out16=reg256#13
# asm 2: vpaddq <out16=%ymm12,<out16plus=%ymm8,<out16=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x ta = int32 d0 * int32 mod16
# asm 1: vpmuldq <d0=reg256#12,<mod16=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod16=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod15
# asm 1: vpmuldq <d1=reg256#2,<mod15=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod15=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out16plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out16plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out16plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out16plus2 += carryy
# asm 1: vpaddq <out16plus2=reg256#9,<carryy=reg256#4,<out16plus2=reg256#9
# asm 2: vpaddq <out16plus2=%ymm8,<carryy=%ymm3,<out16plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out16 += out16plus2
# asm 1: vpaddq <out16=reg256#13,<out16plus2=reg256#9,<out16=reg256#13
# asm 2: vpaddq <out16=%ymm12,<out16plus2=%ymm8,<out16=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x carryy = out16 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out16=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out16=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: out16 &= _2p30m1x4
# asm 1: vpand <out16=reg256#13,<_2p30m1x4=reg256#5,<out16=reg256#13
# asm 2: vpand <out16=%ymm12,<_2p30m1x4=%ymm4,<out16=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: stack_FVGS14 = out16
# asm 1: vmovapd <out16=reg256#13,>stack_FVGS14=stack256#16
# asm 2: vmovapd <out16=%ymm12,>stack_FVGS14=608(%rsp)
vmovapd %ymm12,608(%rsp)

# qhasm: FVGS17 = stack_FVGS17
# asm 1: vmovapd <stack_FVGS17=stack256#19,>FVGS17=reg256#9
# asm 2: vmovapd <stack_FVGS17=704(%rsp),>FVGS17=%ymm8
vmovapd 704(%rsp),%ymm8

# qhasm: GSFV17 = FVGS17[1,0]
# asm 1: vpermq $0x4e,<FVGS17=reg256#9,>GSFV17=reg256#13
# asm 2: vpermq $0x4e,<FVGS17=%ymm8,>GSFV17=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm:   _2p20a2p41 = stack_2p20a2p41
# asm 1: movq <stack_2p20a2p41=stack64#14,>_2p20a2p41=int64#7
# asm 2: movq <stack_2p20a2p41=104(%rsp),>_2p20a2p41=%rax
movq 104(%rsp),%rax

# qhasm: extract_init:
._extract_init:

# qhasm: mod17 = stack_mod17
# asm 1: vmovapd <stack_mod17=stack256#37,>mod17=reg256#14
# asm 2: vmovapd <stack_mod17=1280(%rsp),>mod17=%ymm13
vmovapd 1280(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS16
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS16=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS16=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   s = grs + _2p20a2p41
# asm 1: lea  (<grs=int64#5,<_2p20a2p41=int64#7),>s=int64#9
# asm 2: lea  (<grs=%r8,<_2p20a2p41=%rax),>s=%r11
lea  (%r8,%rax),%r11

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV16
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV16=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV16=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   (int64) s >>= 42
# asm 1: sar  $42,<s=int64#9
# asm 2: sar  $42,<s=%r11
sar  $42,%r11

# qhasm: 4x out17plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out17plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out17plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   t2 = g
# asm 1: mov  <g=int64#1,>t2=int64#10
# asm 2: mov  <g=%rdi,>t2=%r12
mov  %rdi,%r12

# qhasm: 4x ta = int32 uuss0 * int32 FVGS17
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS17=reg256#9,>ta=reg256#6
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS17=%ymm8,>ta=%ymm5
vpmuldq %ymm5,%ymm8,%ymm5

# qhasm:   g *= s  
# asm 1: imul  <s=int64#9,<g=int64#1
# asm 2: imul  <s=%r11,<g=%rdi
imul  %r11,%rdi

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV17
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV17=reg256#13,>tb=reg256#7
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV17=%ymm12,>tb=%ymm6
vpmuldq %ymm6,%ymm12,%ymm6

# qhasm:   v = fuv + _2p20a2p41
# asm 1: lea  (<fuv=int64#3,<_2p20a2p41=int64#7),>v=int64#7
# asm 2: lea  (<fuv=%rdx,<_2p20a2p41=%rax),>v=%rax
lea  (%rdx,%rax),%rax

# qhasm: 4x out17 = ta + tb
# asm 1: vpaddq <tb=reg256#7,<ta=reg256#6,>out17=reg256#6
# asm 2: vpaddq <tb=%ymm6,<ta=%ymm5,>out17=%ymm5
vpaddq %ymm6,%ymm5,%ymm5

# qhasm: 4x out17 += out17plus
# asm 1: vpaddq <out17=reg256#6,<out17plus=reg256#10,<out17=reg256#6
# asm 2: vpaddq <out17=%ymm5,<out17plus=%ymm9,<out17=%ymm5
vpaddq %ymm5,%ymm9,%ymm5

# qhasm:   (int64) v >>= 42
# asm 1: sar  $42,<v=int64#7
# asm 2: sar  $42,<v=%rax
sar  $42,%rax

# qhasm: 4x ta = int32 d0 * int32 mod17
# asm 1: vpmuldq <d0=reg256#12,<mod17=reg256#14,>ta=reg256#7
# asm 2: vpmuldq <d0=%ymm11,<mod17=%ymm13,>ta=%ymm6
vpmuldq %ymm11,%ymm13,%ymm6

# qhasm:   t2 *= v
# asm 1: imul  <v=int64#7,<t2=int64#10
# asm 2: imul  <v=%rax,<t2=%r12
imul  %rax,%r12

# qhasm: 4x tb = int32 d1 * int32 mod16
# asm 1: vpmuldq <d1=reg256#2,<mod16=reg256#15,>tb=reg256#10
# asm 2: vpmuldq <d1=%ymm1,<mod16=%ymm14,>tb=%ymm9
vpmuldq %ymm1,%ymm14,%ymm9

# qhasm:   _2p20 = stack_2p20
# asm 1: movq <stack_2p20=stack64#11,>_2p20=int64#11
# asm 2: movq <stack_2p20=80(%rsp),>_2p20=%r13
movq 80(%rsp),%r13

# qhasm:   r = grs + _2p20
# asm 1: lea  (<grs=int64#5,<_2p20=int64#11),>r=int64#5
# asm 2: lea  (<grs=%r8,<_2p20=%r13),>r=%r8
lea  (%r8,%r13),%r8

# qhasm: 4x out17plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#10,<ta=reg256#7,>out17plus2=reg256#7
# asm 2: vpaddq <tb=%ymm9,<ta=%ymm6,>out17plus2=%ymm6
vpaddq %ymm9,%ymm6,%ymm6

# qhasm: 4x out17plus2 += carryy
# asm 1: vpaddq <out17plus2=reg256#7,<carryy=reg256#4,<out17plus2=reg256#7
# asm 2: vpaddq <out17plus2=%ymm6,<carryy=%ymm3,<out17plus2=%ymm6
vpaddq %ymm6,%ymm3,%ymm6

# qhasm:   r <<= 22
# asm 1: shl  $22,<r=int64#5
# asm 2: shl  $22,<r=%r8
shl  $22,%r8

# qhasm: 4x out17 += out17plus2
# asm 1: vpaddq <out17=reg256#6,<out17plus2=reg256#7,<out17=reg256#6
# asm 2: vpaddq <out17=%ymm5,<out17plus2=%ymm6,<out17=%ymm5
vpaddq %ymm5,%ymm6,%ymm5

# qhasm: 4x carryy = out17 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out17=reg256#6,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out17=%ymm5,>carryy=%ymm3
vpaddq %ymm7,%ymm5,%ymm3

# qhasm:   (int64) r >>= 43
# asm 1: sar  $43,<r=int64#5
# asm 2: sar  $43,<r=%r8
sar  $43,%r8

# qhasm:       rax = f
# asm 1: mov  <f=int64#4,>rax=int64#12
# asm 2: mov  <f=%rcx,>rax=%r14
mov  %rcx,%r14

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:       rax *= r
# asm 1: imul  <r=int64#5,<rax=int64#12
# asm 2: imul  <r=%r8,<rax=%r14
imul  %r8,%r14

# qhasm: out17 &= _2p30m1x4
# asm 1: vpand <out17=reg256#6,<_2p30m1x4=reg256#5,<out17=reg256#6
# asm 2: vpand <out17=%ymm5,<_2p30m1x4=%ymm4,<out17=%ymm5
vpand %ymm5,%ymm4,%ymm5

# qhasm: stack_FVGS15 = out17
# asm 1: vmovapd <out17=reg256#6,>stack_FVGS15=stack256#17
# asm 2: vmovapd <out17=%ymm5,>stack_FVGS15=640(%rsp)
vmovapd %ymm5,640(%rsp)

# qhasm:   u = fuv + _2p20
# asm 1: lea  (<fuv=int64#3,<_2p20=int64#11),>u=int64#3
# asm 2: lea  (<fuv=%rdx,<_2p20=%r13),>u=%rdx
lea  (%rdx,%r13),%rdx

# qhasm: _2p33x4 = stack_2p33x4
# asm 1: vmovapd <stack_2p33x4=stack256#39,>_2p33x4=reg256#6
# asm 2: vmovapd <stack_2p33x4=1344(%rsp),>_2p33x4=%ymm5
vmovapd 1344(%rsp),%ymm5

# qhasm:   u <<= 22
# asm 1: shl  $22,<u=int64#3
# asm 2: shl  $22,<u=%rdx
shl  $22,%rdx

# qhasm: 4x ta = int32 uuss1 * int32 FVGS17
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS17=reg256#9,>ta=reg256#3
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS17=%ymm8,>ta=%ymm2
vpmuldq %ymm2,%ymm8,%ymm2

# qhasm:   (int64) u >>= 43
# asm 1: sar  $43,<u=int64#3
# asm 2: sar  $43,<u=%rdx
sar  $43,%rdx

# qhasm:        f *= u
# asm 1: imul  <u=int64#3,<f=int64#4
# asm 2: imul  <u=%rdx,<f=%rcx
imul  %rdx,%rcx

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV17
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV17=reg256#13,>tb=reg256#1
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV17=%ymm12,>tb=%ymm0
vpmuldq %ymm0,%ymm12,%ymm0

# qhasm:        f += t2
# asm 1: add  <t2=int64#10,<f=int64#4
# asm 2: add  <t2=%r12,<f=%rcx
add  %r12,%rcx

# qhasm: 4x out18plus = ta + tb
# asm 1: vpaddq <tb=reg256#1,<ta=reg256#3,>out18plus=reg256#1
# asm 2: vpaddq <tb=%ymm0,<ta=%ymm2,>out18plus=%ymm0
vpaddq %ymm0,%ymm2,%ymm0

# qhasm: 4x ta = int32 mod17 * int32 d1
# asm 1: vpmuldq <mod17=reg256#14,<d1=reg256#2,>ta=reg256#2
# asm 2: vpmuldq <mod17=%ymm13,<d1=%ymm1,>ta=%ymm1
vpmuldq %ymm13,%ymm1,%ymm1

# qhasm:        g += rax
# asm 1: add  <rax=int64#12,<g=int64#1
# asm 2: add  <rax=%r14,<g=%rdi
add  %r14,%rdi

# qhasm: 4x out18 = ta + carryy
# asm 1: vpaddq <carryy=reg256#4,<ta=reg256#2,>out18=reg256#2
# asm 2: vpaddq <carryy=%ymm3,<ta=%ymm1,>out18=%ymm1
vpaddq %ymm3,%ymm1,%ymm1

# qhasm:   (int64) f >>= 20
# asm 1: sar  $20,<f=int64#4
# asm 2: sar  $20,<f=%rcx
sar  $20,%rcx

# qhasm: 4x out18 += out18plus
# asm 1: vpaddq <out18=reg256#2,<out18plus=reg256#1,<out18=reg256#2
# asm 2: vpaddq <out18=%ymm1,<out18plus=%ymm0,<out18=%ymm1
vpaddq %ymm1,%ymm0,%ymm1

# qhasm:   (int64) g >>= 20
# asm 1: sar  $20,<g=int64#1
# asm 2: sar  $20,<g=%rdi
sar  $20,%rdi

# qhasm: 4x out19 = out18 + _2p63m2p33x4
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out18=reg256#2,>out19=reg256#1
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out18=%ymm1,>out19=%ymm0
vpaddq %ymm7,%ymm1,%ymm0

# qhasm:   inplace stack_vvrr[0] = v
# asm 1: movq <v=int64#7,<stack_vvrr=stack256#44
# asm 2: movq <v=%rax,<stack_vvrr=1504(%rsp)
movq %rax,1504(%rsp)

# qhasm: 4x out19 unsigned >>= 30
# asm 1: vpsrlq $30,<out19=reg256#1,<out19=reg256#1
# asm 2: vpsrlq $30,<out19=%ymm0,<out19=%ymm0
vpsrlq $30,%ymm0,%ymm0

# qhasm: 4x out19 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#6,<out19=reg256#1,<out19=reg256#1
# asm 2: vpsubq <_2p33x4=%ymm5,<out19=%ymm0,<out19=%ymm0
vpsubq %ymm5,%ymm0,%ymm0

# qhasm:   inplace stack_uuss[0] = u
# asm 1: movq <u=int64#3,<stack_uuss=stack256#43
# asm 2: movq <u=%rdx,<stack_uuss=1472(%rsp)
movq %rdx,1472(%rsp)

# qhasm:   inplace stack_uuss[2] = s
# asm 1: movq <s=int64#9,<stack_uuss=stack256#43
# asm 2: movq <s=%r11,<stack_uuss=1488(%rsp)
movq %r11,1488(%rsp)

# qhasm: out18 &= _2p30m1x4
# asm 1: vpand <out18=reg256#2,<_2p30m1x4=reg256#5,<out18=reg256#2
# asm 2: vpand <out18=%ymm1,<_2p30m1x4=%ymm4,<out18=%ymm1
vpand %ymm1,%ymm4,%ymm1

# qhasm:   inplace stack_vvrr[2] = r
# asm 1: movq <r=int64#5,<stack_vvrr=stack256#44
# asm 2: movq <r=%r8,<stack_vvrr=1520(%rsp)
movq %r8,1520(%rsp)

# qhasm: stack_FVGS16 = out18
# asm 1: vmovapd <out18=reg256#2,>stack_FVGS16=stack256#18
# asm 2: vmovapd <out18=%ymm1,>stack_FVGS16=672(%rsp)
vmovapd %ymm1,672(%rsp)

# qhasm:   loop = 2
# asm 1: mov  $2,>loop=int64#3
# asm 2: mov  $2,>loop=%rdx
mov  $2,%rdx

# qhasm: stack_FVGS17 = out19
# asm 1: vmovapd <out19=reg256#1,>stack_FVGS17=stack256#19
# asm 2: vmovapd <out19=%ymm0,>stack_FVGS17=704(%rsp)
vmovapd %ymm0,704(%rsp)

# qhasm: loop20:
._loop20:

# qhasm:   fuv = f & ~ _m2p20
# asm 1: andn  <f=int64#4,<_m2p20=int64#8,>fuv=int64#7
# asm 2: andn  <f=%rcx,<_m2p20=%r10,>fuv=%rax
andn  %rcx,%r10,%rax

# qhasm:   grs = g & ~ _m2p20
# asm 1: andn  <g=int64#1,<_m2p20=int64#8,>grs=int64#5
# asm 2: andn  <g=%rdi,<_m2p20=%r10,>grs=%r8
andn  %rdi,%r10,%r8

# qhasm:   fuv += stack_m2p41
# asm 1: addq <stack_m2p41=stack64#12,<fuv=int64#7
# asm 2: addq <stack_m2p41=88(%rsp),<fuv=%rax
addq 88(%rsp),%rax

# qhasm:   grs += stack_m2p62
# asm 1: addq <stack_m2p62=stack64#13,<grs=int64#5
# asm 2: addq <stack_m2p62=96(%rsp),<grs=%r8
addq 96(%rsp),%r8

# qhasm: j = 4
# asm 1: mov  $4,>j=int64#9
# asm 2: mov  $4,>j=%r11
mov  $4,%r11

# qhasm: loop2:
._loop2:

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#10
# asm 2: movq <stack_m1=136(%rsp),>z=%r12
movq 136(%rsp),%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#10
# asm 2: movq <stack_m1=136(%rsp),>z=%r12
movq 136(%rsp),%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#10
# asm 2: movq <stack_m1=136(%rsp),>z=%r12
movq 136(%rsp),%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#10
# asm 2: movq <stack_m1=136(%rsp),>z=%r12
movq 136(%rsp),%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#10
# asm 2: movq <stack_m1=136(%rsp),>z=%r12
movq 136(%rsp),%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:  =? j -= 1
# asm 1: dec <j=int64#9
# asm 2: dec <j=%r11
dec %r11
# comment:fp stack unchanged by jump

# qhasm: goto loop2 if !=
jne ._loop2

# qhasm:   =? loop -= 1		
# asm 1: dec <loop=int64#3
# asm 2: dec <loop=%rdx
dec %rdx
# comment:fp stack unchanged by jump

# qhasm: goto lastloop if =
je ._lastloop

# qhasm: extract:
._extract:

# qhasm:   _2p20a2p41 = stack_2p20a2p41
# asm 1: movq <stack_2p20a2p41=stack64#14,>_2p20a2p41=int64#9
# asm 2: movq <stack_2p20a2p41=104(%rsp),>_2p20a2p41=%r11
movq 104(%rsp),%r11

# qhasm:   s = grs + _2p20a2p41
# asm 1: lea  (<grs=int64#5,<_2p20a2p41=int64#9),>s=int64#10
# asm 2: lea  (<grs=%r8,<_2p20a2p41=%r11),>s=%r12
lea  (%r8,%r11),%r12

# qhasm:   (int64) s >>= 42
# asm 1: sar  $42,<s=int64#10
# asm 2: sar  $42,<s=%r12
sar  $42,%r12

# qhasm:   t2 = g
# asm 1: mov  <g=int64#1,>t2=int64#11
# asm 2: mov  <g=%rdi,>t2=%r13
mov  %rdi,%r13

# qhasm:   g *= s  
# asm 1: imul  <s=int64#10,<g=int64#1
# asm 2: imul  <s=%r12,<g=%rdi
imul  %r12,%rdi

# qhasm:   v = fuv + _2p20a2p41
# asm 1: lea  (<fuv=int64#7,<_2p20a2p41=int64#9),>v=int64#9
# asm 2: lea  (<fuv=%rax,<_2p20a2p41=%r11),>v=%r11
lea  (%rax,%r11),%r11

# qhasm:   (int64) v >>= 42
# asm 1: sar  $42,<v=int64#9
# asm 2: sar  $42,<v=%r11
sar  $42,%r11

# qhasm:   t2 *= v
# asm 1: imul  <v=int64#9,<t2=int64#11
# asm 2: imul  <v=%r11,<t2=%r13
imul  %r11,%r13

# qhasm:   _2p20 = stack_2p20
# asm 1: movq <stack_2p20=stack64#11,>_2p20=int64#12
# asm 2: movq <stack_2p20=80(%rsp),>_2p20=%r14
movq 80(%rsp),%r14

# qhasm:   r = grs + _2p20
# asm 1: lea  (<grs=int64#5,<_2p20=int64#12),>r=int64#5
# asm 2: lea  (<grs=%r8,<_2p20=%r14),>r=%r8
lea  (%r8,%r14),%r8

# qhasm:   r <<= 22
# asm 1: shl  $22,<r=int64#5
# asm 2: shl  $22,<r=%r8
shl  $22,%r8

# qhasm:   (int64) r >>= 43
# asm 1: sar  $43,<r=int64#5
# asm 2: sar  $43,<r=%r8
sar  $43,%r8

# qhasm:       rax = f
# asm 1: mov  <f=int64#4,>rax=int64#13
# asm 2: mov  <f=%rcx,>rax=%r15
mov  %rcx,%r15

# qhasm:       rax *= r
# asm 1: imul  <r=int64#5,<rax=int64#13
# asm 2: imul  <r=%r8,<rax=%r15
imul  %r8,%r15

# qhasm:   u = fuv + _2p20
# asm 1: lea  (<fuv=int64#7,<_2p20=int64#12),>u=int64#7
# asm 2: lea  (<fuv=%rax,<_2p20=%r14),>u=%rax
lea  (%rax,%r14),%rax

# qhasm:   u <<= 22
# asm 1: shl  $22,<u=int64#7
# asm 2: shl  $22,<u=%rax
shl  $22,%rax

# qhasm:   (int64) u >>= 43
# asm 1: sar  $43,<u=int64#7
# asm 2: sar  $43,<u=%rax
sar  $43,%rax

# qhasm:        f *= u
# asm 1: imul  <u=int64#7,<f=int64#4
# asm 2: imul  <u=%rax,<f=%rcx
imul  %rax,%rcx

# qhasm:        f += t2
# asm 1: add  <t2=int64#11,<f=int64#4
# asm 2: add  <t2=%r13,<f=%rcx
add  %r13,%rcx

# qhasm:        g += rax
# asm 1: add  <rax=int64#13,<g=int64#1
# asm 2: add  <rax=%r15,<g=%rdi
add  %r15,%rdi

# qhasm:   (int64) f >>= 20
# asm 1: sar  $20,<f=int64#4
# asm 2: sar  $20,<f=%rcx
sar  $20,%rcx

# qhasm:   (int64) g >>= 20
# asm 1: sar  $20,<g=int64#1
# asm 2: sar  $20,<g=%rdi
sar  $20,%rdi

# qhasm:   t0 = stack_uuss[0]
# asm 1: movq <stack_uuss=stack256#43,>t0=int64#11
# asm 2: movq <stack_uuss=1472(%rsp),>t0=%r13
movq 1472(%rsp),%r13

# qhasm:   t0 *= u
# asm 1: imul  <u=int64#7,<t0=int64#11
# asm 2: imul  <u=%rax,<t0=%r13
imul  %rax,%r13

# qhasm:   t1 = stack_vvrr[2]
# asm 1: movq <stack_vvrr=stack256#44,>t1=int64#12
# asm 2: movq <stack_vvrr=1520(%rsp),>t1=%r14
movq 1520(%rsp),%r14

# qhasm:   t1 *= v
# asm 1: imul  <v=int64#9,<t1=int64#12
# asm 2: imul  <v=%r11,<t1=%r14
imul  %r11,%r14

# qhasm:   rtimesoldv = stack_vvrr[0]
# asm 1: movq <stack_vvrr=stack256#44,>rtimesoldv=int64#13
# asm 2: movq <stack_vvrr=1504(%rsp),>rtimesoldv=%r15
movq 1504(%rsp),%r15

# qhasm:   u *= rtimesoldv
# asm 1: imul  <rtimesoldv=int64#13,<u=int64#7
# asm 2: imul  <rtimesoldv=%r15,<u=%rax
imul  %r15,%rax

# qhasm:   stimesolds = stack_uuss[2]
# asm 1: movq <stack_uuss=stack256#43,>stimesolds=int64#14
# asm 2: movq <stack_uuss=1488(%rsp),>stimesolds=%rbx
movq 1488(%rsp),%rbx

# qhasm:   v *= stimesolds
# asm 1: imul  <stimesolds=int64#14,<v=int64#9
# asm 2: imul  <stimesolds=%rbx,<v=%r11
imul  %rbx,%r11

# qhasm:   rtimesoldv *= r
# asm 1: imul  <r=int64#5,<rtimesoldv=int64#13
# asm 2: imul  <r=%r8,<rtimesoldv=%r15
imul  %r8,%r15

# qhasm:   stimesolds *= s
# asm 1: imul  <s=int64#10,<stimesolds=int64#14
# asm 2: imul  <s=%r12,<stimesolds=%rbx
imul  %r12,%rbx

# qhasm:   r *= stack_uuss[0]
# asm 1: imulq <stack_uuss=stack256#43,<r=int64#5
# asm 2: imulq <stack_uuss=1472(%rsp),<r=%r8
imulq 1472(%rsp),%r8

# qhasm:   s *= stack_vvrr[2]
# asm 1: imulq <stack_vvrr=stack256#44,<s=int64#10
# asm 2: imulq <stack_vvrr=1520(%rsp),<s=%r12
imulq 1520(%rsp),%r12

# qhasm:   v += u
# asm 1: add  <u=int64#7,<v=int64#9
# asm 2: add  <u=%rax,<v=%r11
add  %rax,%r11

# qhasm:   u = t0 + t1
# asm 1: lea  (<t0=int64#11,<t1=int64#12),>u=int64#7
# asm 2: lea  (<t0=%r13,<t1=%r14),>u=%rax
lea  (%r13,%r14),%rax

# qhasm:   r += s
# asm 1: add  <s=int64#10,<r=int64#5
# asm 2: add  <s=%r12,<r=%r8
add  %r12,%r8

# qhasm:   s = rtimesoldv + stimesolds
# asm 1: lea  (<rtimesoldv=int64#13,<stimesolds=int64#14),>s=int64#10
# asm 2: lea  (<rtimesoldv=%r15,<stimesolds=%rbx),>s=%r12
lea  (%r15,%rbx),%r12

# qhasm: first_loop:
._first_loop:

# qhasm:   inplace stack_vvrr[0] = v
# asm 1: movq <v=int64#9,<stack_vvrr=stack256#44
# asm 2: movq <v=%r11,<stack_vvrr=1504(%rsp)
movq %r11,1504(%rsp)

# qhasm:   inplace stack_uuss[0] = u
# asm 1: movq <u=int64#7,<stack_uuss=stack256#43
# asm 2: movq <u=%rax,<stack_uuss=1472(%rsp)
movq %rax,1472(%rsp)

# qhasm:   inplace stack_uuss[2] = s
# asm 1: movq <s=int64#10,<stack_uuss=stack256#43
# asm 2: movq <s=%r12,<stack_uuss=1488(%rsp)
movq %r12,1488(%rsp)

# qhasm:   inplace stack_vvrr[2] = r
# asm 1: movq <r=int64#5,<stack_vvrr=stack256#44
# asm 2: movq <r=%r8,<stack_vvrr=1520(%rsp)
movq %r8,1520(%rsp)
# comment:fp stack unchanged by jump

# qhasm: goto loop20 
jmp ._loop20

# qhasm: lastloop:
._lastloop:

# qhasm:   _2p20a2p41 = stack_2p20a2p41
# asm 1: movq <stack_2p20a2p41=stack64#14,>_2p20a2p41=int64#1
# asm 2: movq <stack_2p20a2p41=104(%rsp),>_2p20a2p41=%rdi
movq 104(%rsp),%rdi

# qhasm:   s = grs + _2p20a2p41
# asm 1: lea  (<grs=int64#5,<_2p20a2p41=int64#1),>s=int64#3
# asm 2: lea  (<grs=%r8,<_2p20a2p41=%rdi),>s=%rdx
lea  (%r8,%rdi),%rdx

# qhasm:   (int64) s >>= 42
# asm 1: sar  $42,<s=int64#3
# asm 2: sar  $42,<s=%rdx
sar  $42,%rdx

# qhasm:   v = fuv + _2p20a2p41
# asm 1: lea  (<fuv=int64#7,<_2p20a2p41=int64#1),>v=int64#10
# asm 2: lea  (<fuv=%rax,<_2p20a2p41=%rdi),>v=%r12
lea  (%rax,%rdi),%r12

# qhasm:   (int64) v >>= 42
# asm 1: sar  $42,<v=int64#10
# asm 2: sar  $42,<v=%r12
sar  $42,%r12

# qhasm:   t1 = stack_vvrr[2]
# asm 1: movq <stack_vvrr=stack256#44,>t1=int64#1
# asm 2: movq <stack_vvrr=1520(%rsp),>t1=%rdi
movq 1520(%rsp),%rdi

# qhasm:   t1 *= v
# asm 1: imul  <v=int64#10,<t1=int64#1
# asm 2: imul  <v=%r12,<t1=%rdi
imul  %r12,%rdi

# qhasm:   stimesolds = stack_uuss[2]
# asm 1: movq <stack_uuss=stack256#43,>stimesolds=int64#4
# asm 2: movq <stack_uuss=1488(%rsp),>stimesolds=%rcx
movq 1488(%rsp),%rcx

# qhasm:   v *= stimesolds
# asm 1: imul  <stimesolds=int64#4,<v=int64#10
# asm 2: imul  <stimesolds=%rcx,<v=%r12
imul  %rcx,%r12

# qhasm:   stimesolds *= s
# asm 1: imul  <s=int64#3,<stimesolds=int64#4
# asm 2: imul  <s=%rdx,<stimesolds=%rcx
imul  %rdx,%rcx

# qhasm:   _2p20 = stack_2p20
# asm 1: movq <stack_2p20=stack64#11,>_2p20=int64#9
# asm 2: movq <stack_2p20=80(%rsp),>_2p20=%r11
movq 80(%rsp),%r11

# qhasm:   r = grs + _2p20
# asm 1: lea  (<grs=int64#5,<_2p20=int64#9),>r=int64#12
# asm 2: lea  (<grs=%r8,<_2p20=%r11),>r=%r14
lea  (%r8,%r11),%r14

# qhasm:   r <<= 22
# asm 1: shl  $22,<r=int64#12
# asm 2: shl  $22,<r=%r14
shl  $22,%r14

# qhasm:   (int64) r >>= 43
# asm 1: sar  $43,<r=int64#12
# asm 2: sar  $43,<r=%r14
sar  $43,%r14

# qhasm:   u = fuv + _2p20
# asm 1: lea  (<fuv=int64#7,<_2p20=int64#9),>u=int64#5
# asm 2: lea  (<fuv=%rax,<_2p20=%r11),>u=%r8
lea  (%rax,%r11),%r8

# qhasm:   u <<= 22
# asm 1: shl  $22,<u=int64#5
# asm 2: shl  $22,<u=%r8
shl  $22,%r8

# qhasm:   (int64) u >>= 43
# asm 1: sar  $43,<u=int64#5
# asm 2: sar  $43,<u=%r8
sar  $43,%r8

# qhasm:   t0 = stack_uuss[0]
# asm 1: movq <stack_uuss=stack256#43,>t0=int64#9
# asm 2: movq <stack_uuss=1472(%rsp),>t0=%r11
movq 1472(%rsp),%r11

# qhasm:   t0 *= u
# asm 1: imul  <u=int64#5,<t0=int64#9
# asm 2: imul  <u=%r8,<t0=%r11
imul  %r8,%r11

# qhasm:   rtimesoldv = stack_vvrr[0]
# asm 1: movq <stack_vvrr=stack256#44,>rtimesoldv=int64#11
# asm 2: movq <stack_vvrr=1504(%rsp),>rtimesoldv=%r13
movq 1504(%rsp),%r13

# qhasm:   u *= rtimesoldv
# asm 1: imul  <rtimesoldv=int64#11,<u=int64#5
# asm 2: imul  <rtimesoldv=%r13,<u=%r8
imul  %r13,%r8

# qhasm:   rtimesoldv *= r
# asm 1: imul  <r=int64#12,<rtimesoldv=int64#11
# asm 2: imul  <r=%r14,<rtimesoldv=%r13
imul  %r14,%r13

# qhasm:   s *= stack_vvrr[2]
# asm 1: imulq <stack_vvrr=stack256#44,<s=int64#3
# asm 2: imulq <stack_vvrr=1520(%rsp),<s=%rdx
imulq 1520(%rsp),%rdx

# qhasm:   r *= stack_uuss[0]
# asm 1: imulq <stack_uuss=stack256#43,<r=int64#12
# asm 2: imulq <stack_uuss=1472(%rsp),<r=%r14
imulq 1472(%rsp),%r14

# qhasm:   v += u
# asm 1: add  <u=int64#5,<v=int64#10
# asm 2: add  <u=%r8,<v=%r12
add  %r8,%r12

# qhasm:   u = t0 + t1
# asm 1: lea  (<t0=int64#9,<t1=int64#1),>u=int64#9
# asm 2: lea  (<t0=%r11,<t1=%rdi),>u=%r11
lea  (%r11,%rdi),%r11

# qhasm:   r += s
# asm 1: add  <s=int64#3,<r=int64#12
# asm 2: add  <s=%rdx,<r=%r14
add  %rdx,%r14

# qhasm:   s = rtimesoldv + stimesolds
# asm 1: lea  (<rtimesoldv=int64#11,<stimesolds=int64#4),>s=int64#11
# asm 2: lea  (<rtimesoldv=%r13,<stimesolds=%rcx),>s=%r13
lea  (%r13,%rcx),%r13

# qhasm:   t0 = stack_FVGS0[0]
# asm 1: movq <stack_FVGS0=stack256#2,>t0=int64#1
# asm 2: movq <stack_FVGS0=160(%rsp),>t0=%rdi
movq 160(%rsp),%rdi

# qhasm:   t1 = stack_FVGS1[0]
# asm 1: movq <stack_FVGS1=stack256#3,>t1=int64#3
# asm 2: movq <stack_FVGS1=192(%rsp),>t1=%rdx
movq 192(%rsp),%rdx

# qhasm:   t1 <<= 30
# asm 1: shl  $30,<t1=int64#3
# asm 2: shl  $30,<t1=%rdx
shl  $30,%rdx

# qhasm:   f = t0 + t1
# asm 1: lea  (<t0=int64#1,<t1=int64#3),>f=int64#4
# asm 2: lea  (<t0=%rdi,<t1=%rdx),>f=%rcx
lea  (%rdi,%rdx),%rcx

# qhasm:   t0 = stack_FVGS0[2]
# asm 1: movq <stack_FVGS0=stack256#2,>t0=int64#1
# asm 2: movq <stack_FVGS0=176(%rsp),>t0=%rdi
movq 176(%rsp),%rdi

# qhasm:   t1 = stack_FVGS1[2]
# asm 1: movq <stack_FVGS1=stack256#3,>t1=int64#3
# asm 2: movq <stack_FVGS1=208(%rsp),>t1=%rdx
movq 208(%rsp),%rdx

# qhasm:   t1 <<= 30
# asm 1: shl  $30,<t1=int64#3
# asm 2: shl  $30,<t1=%rdx
shl  $30,%rdx

# qhasm:   g = t0 + t1
# asm 1: lea  (<t0=int64#1,<t1=int64#3),>g=int64#1
# asm 2: lea  (<t0=%rdi,<t1=%rdx),>g=%rdi
lea  (%rdi,%rdx),%rdi

# qhasm:   t0 = stack_FVGS2[0]
# asm 1: movq <stack_FVGS2=stack256#4,>t0=int64#3
# asm 2: movq <stack_FVGS2=224(%rsp),>t0=%rdx
movq 224(%rsp),%rdx

# qhasm:   t1 = stack_FVGS3[0]
# asm 1: movq <stack_FVGS3=stack256#5,>t1=int64#5
# asm 2: movq <stack_FVGS3=256(%rsp),>t1=%r8
movq 256(%rsp),%r8

# qhasm:   t1 <<= 30
# asm 1: shl  $30,<t1=int64#5
# asm 2: shl  $30,<t1=%r8
shl  $30,%r8

# qhasm:   f0 = t0 + t1
# asm 1: lea  (<t0=int64#3,<t1=int64#5),>f0=int64#5
# asm 2: lea  (<t0=%rdx,<t1=%r8),>f0=%r8
lea  (%rdx,%r8),%r8

# qhasm:   t0 = stack_FVGS2[2]
# asm 1: movq <stack_FVGS2=stack256#4,>t0=int64#3
# asm 2: movq <stack_FVGS2=240(%rsp),>t0=%rdx
movq 240(%rsp),%rdx

# qhasm:   t1 = stack_FVGS3[2]
# asm 1: movq <stack_FVGS3=stack256#5,>t1=int64#13
# asm 2: movq <stack_FVGS3=272(%rsp),>t1=%r15
movq 272(%rsp),%r15

# qhasm:   t1 <<= 30
# asm 1: shl  $30,<t1=int64#13
# asm 2: shl  $30,<t1=%r15
shl  $30,%r15

# qhasm:   g0 = t0 + t1
# asm 1: lea  (<t0=int64#3,<t1=int64#13),>g0=int64#13
# asm 2: lea  (<t0=%rdx,<t1=%r15),>g0=%r15
lea  (%rdx,%r15),%r15

# qhasm: =? i -= 1
# asm 1: dec <i=int64#2
# asm 2: dec <i=%rsi
dec %rsi
# comment:fp stack unchanged by jump

# qhasm: goto bigloop if !=
jne ._bigloop

# qhasm: last_transition:
._last_transition:

# qhasm: fuv &= 2
# asm 1: and  $2,<fuv=int64#7
# asm 2: and  $2,<fuv=%rax
and  $2,%rax

# qhasm: t0 = fuv - 1
# asm 1: lea  -1(<fuv=int64#7),>t0=int64#1
# asm 2: lea  -1(<fuv=%rax),>t0=%rdi
lea  -1(%rax),%rdi

# qhasm: u *= t0
# asm 1: imul  <t0=int64#1,<u=int64#9
# asm 2: imul  <t0=%rdi,<u=%r11
imul  %rdi,%r11

# qhasm: v *= t0
# asm 1: imul  <t0=int64#1,<v=int64#10
# asm 2: imul  <t0=%rdi,<v=%r12
imul  %rdi,%r12

# qhasm: new vvrr

# qhasm: vvrr = v,vvrr[1],0,0
# asm 1: vpinsrq $0x0,<v=int64#10,<vvrr=reg256#1%128,<vvrr=reg256#1%128
# asm 2: vpinsrq $0x0,<v=%r12,<vvrr=%xmm0,<vvrr=%xmm0
vpinsrq $0x0,%r12,%xmm0,%xmm0

# qhasm: vvrr = vvrr[0],r,0,0
# asm 1: vpinsrq $0x1,<r=int64#12,<vvrr=reg256#1%128,<vvrr=reg256#1%128
# asm 2: vpinsrq $0x1,<r=%r14,<vvrr=%xmm0,<vvrr=%xmm0
vpinsrq $0x1,%r14,%xmm0,%xmm0

# qhasm: FVGS0 = stack_FVGS0
# asm 1: vmovapd <stack_FVGS0=stack256#2,>FVGS0=reg256#2
# asm 2: vmovapd <stack_FVGS0=160(%rsp),>FVGS0=%ymm1
vmovapd 160(%rsp),%ymm1

# qhasm: new uuss

# qhasm: uuss = u,uuss[1],0,0
# asm 1: vpinsrq $0x0,<u=int64#9,<uuss=reg256#3%128,<uuss=reg256#3%128
# asm 2: vpinsrq $0x0,<u=%r11,<uuss=%xmm2,<uuss=%xmm2
vpinsrq $0x0,%r11,%xmm2,%xmm2

# qhasm: uuss = uuss[0],s,0,0
# asm 1: vpinsrq $0x1,<s=int64#11,<uuss=reg256#3%128,<uuss=reg256#3%128
# asm 2: vpinsrq $0x1,<s=%r13,<uuss=%xmm2,<uuss=%xmm2
vpinsrq $0x1,%r13,%xmm2,%xmm2

# qhasm: GSFV0 = FVGS0[1,0]
# asm 1: vpermq $0x4e,<FVGS0=reg256#2,>GSFV0=reg256#4
# asm 2: vpermq $0x4e,<FVGS0=%ymm1,>GSFV0=%ymm3
vpermq $0x4e,%ymm1,%ymm3

# qhasm: uuss = uuss[0,0,1,1]
# asm 1: vpermq $0x50,<uuss=reg256#3,>uuss=reg256#3
# asm 2: vpermq $0x50,<uuss=%ymm2,>uuss=%ymm2
vpermq $0x50,%ymm2,%ymm2

# qhasm: vvrr = vvrr[0,0,1,1]
# asm 1: vpermq $0x50,<vvrr=reg256#1,>vvrr=reg256#1
# asm 2: vpermq $0x50,<vvrr=%ymm0,>vvrr=%ymm0
vpermq $0x50,%ymm0,%ymm0

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm4
vmovapd 1312(%rsp),%ymm4

# qhasm: uuss0 = uuss & _2p30m1x4
# asm 1: vpand <uuss=reg256#3,<_2p30m1x4=reg256#5,>uuss0=reg256#6
# asm 2: vpand <uuss=%ymm2,<_2p30m1x4=%ymm4,>uuss0=%ymm5
vpand %ymm2,%ymm4,%ymm5

# qhasm: vvrr0 = vvrr & _2p30m1x4 
# asm 1: vpand <vvrr=reg256#1,<_2p30m1x4=reg256#5,>vvrr0=reg256#7
# asm 2: vpand <vvrr=%ymm0,<_2p30m1x4=%ymm4,>vvrr0=%ymm6
vpand %ymm0,%ymm4,%ymm6

# qhasm: _2p63x4 = stack_2p63x4
# asm 1: vmovapd <stack_2p63x4=stack256#40,>_2p63x4=reg256#8
# asm 2: vmovapd <stack_2p63x4=1376(%rsp),>_2p63x4=%ymm7
vmovapd 1376(%rsp),%ymm7

# qhasm: uuss1 = uuss ^ _2p63x4
# asm 1: vpxor <uuss=reg256#3,<_2p63x4=reg256#8,>uuss1=reg256#3
# asm 2: vpxor <uuss=%ymm2,<_2p63x4=%ymm7,>uuss1=%ymm2
vpxor %ymm2,%ymm7,%ymm2

# qhasm: vvrr1 = vvrr ^ _2p63x4
# asm 1: vpxor <vvrr=reg256#1,<_2p63x4=reg256#8,>vvrr1=reg256#1
# asm 2: vpxor <vvrr=%ymm0,<_2p63x4=%ymm7,>vvrr1=%ymm0
vpxor %ymm0,%ymm7,%ymm0

# qhasm: 4x uuss1 unsigned>>= 30
# asm 1: vpsrlq $30,<uuss1=reg256#3,<uuss1=reg256#3
# asm 2: vpsrlq $30,<uuss1=%ymm2,<uuss1=%ymm2
vpsrlq $30,%ymm2,%ymm2

# qhasm: 4x vvrr1 unsigned>>= 30
# asm 1: vpsrlq $30,<vvrr1=reg256#1,<vvrr1=reg256#1
# asm 2: vpsrlq $30,<vvrr1=%ymm0,<vvrr1=%ymm0
vpsrlq $30,%ymm0,%ymm0

# qhasm: _2p33x4 = stack_2p33x4
# asm 1: vmovapd <stack_2p33x4=stack256#39,>_2p33x4=reg256#9
# asm 2: vmovapd <stack_2p33x4=1344(%rsp),>_2p33x4=%ymm8
vmovapd 1344(%rsp),%ymm8

# qhasm: 4x uuss1 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#9,<uuss1=reg256#3,<uuss1=reg256#3
# asm 2: vpsubq <_2p33x4=%ymm8,<uuss1=%ymm2,<uuss1=%ymm2
vpsubq %ymm8,%ymm2,%ymm2

# qhasm: 4x vvrr1 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#9,<vvrr1=reg256#1,<vvrr1=reg256#1
# asm 2: vpsubq <_2p33x4=%ymm8,<vvrr1=%ymm0,<vvrr1=%ymm0
vpsubq %ymm8,%ymm0,%ymm0

# qhasm: 4x ta = int32 uuss0 * int32 FVGS0
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS0=reg256#2,>ta=reg256#9
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS0=%ymm1,>ta=%ymm8
vpmuldq %ymm5,%ymm1,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV0
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV0=reg256#4,>tb=reg256#10
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV0=%ymm3,>tb=%ymm9
vpmuldq %ymm6,%ymm3,%ymm9

# qhasm: 4x out0 = ta + tb
# asm 1: vpaddq <tb=reg256#10,<ta=reg256#9,>out0=reg256#9
# asm 2: vpaddq <tb=%ymm9,<ta=%ymm8,>out0=%ymm8
vpaddq %ymm9,%ymm8,%ymm8

# qhasm: minvx4 = 4x stack_minv
# asm 1: vpbroadcastq <stack_minv=stack64#9,>minvx4=reg256#10
# asm 2: vpbroadcastq <stack_minv=64(%rsp),>minvx4=%ymm9
vpbroadcastq 64(%rsp),%ymm9

# qhasm: mod0 = stack_mod0
# asm 1: vmovapd <stack_mod0=stack256#20,>mod0=reg256#11
# asm 2: vmovapd <stack_mod0=736(%rsp),>mod0=%ymm10
vmovapd 736(%rsp),%ymm10

# qhasm: 4x d0 = int32 minvx4 * int32 out0
# asm 1: vpmuldq <minvx4=reg256#10,<out0=reg256#9,>d0=reg256#12
# asm 2: vpmuldq <minvx4=%ymm9,<out0=%ymm8,>d0=%ymm11
vpmuldq %ymm9,%ymm8,%ymm11

# qhasm: d0 &= _2p30m1x4
# asm 1: vpand <d0=reg256#12,<_2p30m1x4=reg256#5,<d0=reg256#12
# asm 2: vpand <d0=%ymm11,<_2p30m1x4=%ymm4,<d0=%ymm11
vpand %ymm11,%ymm4,%ymm11

# qhasm: 4x ta = int32 mod0 * int32 d0
# asm 1: vpmuldq <mod0=reg256#11,<d0=reg256#12,>ta=reg256#13
# asm 2: vpmuldq <mod0=%ymm10,<d0=%ymm11,>ta=%ymm12
vpmuldq %ymm10,%ymm11,%ymm12

# qhasm: 4x out0 += ta
# asm 1: vpaddq <out0=reg256#9,<ta=reg256#13,<out0=reg256#9
# asm 2: vpaddq <out0=%ymm8,<ta=%ymm12,<out0=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x carryy = out0 +_2p63x4
# asm 1: vpaddq <_2p63x4=reg256#8,<out0=reg256#9,>carryy=reg256#8
# asm 2: vpaddq <_2p63x4=%ymm7,<out0=%ymm8,>carryy=%ymm7
vpaddq %ymm7,%ymm8,%ymm7

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#8,<carryy=reg256#8
# asm 2: vpsrlq $30,<carryy=%ymm7,<carryy=%ymm7
vpsrlq $30,%ymm7,%ymm7

# qhasm: FVGS1 = stack_FVGS1
# asm 1: vmovapd <stack_FVGS1=stack256#3,>FVGS1=reg256#9
# asm 2: vmovapd <stack_FVGS1=192(%rsp),>FVGS1=%ymm8
vmovapd 192(%rsp),%ymm8

# qhasm: GSFV1 = FVGS1[1,0]
# asm 1: vpermq $0x4e,<FVGS1=reg256#9,>GSFV1=reg256#13
# asm 2: vpermq $0x4e,<FVGS1=%ymm8,>GSFV1=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod1 = stack_mod1
# asm 1: vmovapd <stack_mod1=stack256#21,>mod1=reg256#14
# asm 2: vmovapd <stack_mod1=768(%rsp),>mod1=%ymm13
vmovapd 768(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS0
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS0=reg256#2,>ta=reg256#2
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS0=%ymm1,>ta=%ymm1
vpmuldq %ymm2,%ymm1,%ymm1

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV0
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV0=reg256#4,>tb=reg256#4
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV0=%ymm3,>tb=%ymm3
vpmuldq %ymm0,%ymm3,%ymm3

# qhasm: 4x out1plus = ta + tb
# asm 1: vpaddq <tb=reg256#4,<ta=reg256#2,>out1plus=reg256#2
# asm 2: vpaddq <tb=%ymm3,<ta=%ymm1,>out1plus=%ymm1
vpaddq %ymm3,%ymm1,%ymm1

# qhasm: 4x ta = int32 uuss0 * int32 FVGS1
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS1=reg256#9,>ta=reg256#4
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS1=%ymm8,>ta=%ymm3
vpmuldq %ymm5,%ymm8,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV1
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV1=reg256#13,>tb=reg256#15
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV1=%ymm12,>tb=%ymm14
vpmuldq %ymm6,%ymm12,%ymm14

# qhasm: 4x out1 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#4,>out1=reg256#4
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm3,>out1=%ymm3
vpaddq %ymm14,%ymm3,%ymm3

# qhasm: 4x out1 += out1plus
# asm 1: vpaddq <out1=reg256#4,<out1plus=reg256#2,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<out1plus=%ymm1,<out1=%ymm3
vpaddq %ymm3,%ymm1,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod1
# asm 1: vpmuldq <d0=reg256#12,<mod1=reg256#14,>ta=reg256#2
# asm 2: vpmuldq <d0=%ymm11,<mod1=%ymm13,>ta=%ymm1
vpmuldq %ymm11,%ymm13,%ymm1

# qhasm: 4x ta += carryy
# asm 1: vpaddq <ta=reg256#2,<carryy=reg256#8,<ta=reg256#2
# asm 2: vpaddq <ta=%ymm1,<carryy=%ymm7,<ta=%ymm1
vpaddq %ymm1,%ymm7,%ymm1

# qhasm: 4x out1 += ta
# asm 1: vpaddq <out1=reg256#4,<ta=reg256#2,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<ta=%ymm1,<out1=%ymm3
vpaddq %ymm3,%ymm1,%ymm3

# qhasm: 4x d1 = int32 minvx4 * int32 out1
# asm 1: vpmuldq <minvx4=reg256#10,<out1=reg256#4,>d1=reg256#2
# asm 2: vpmuldq <minvx4=%ymm9,<out1=%ymm3,>d1=%ymm1
vpmuldq %ymm9,%ymm3,%ymm1

# qhasm: d1 &= _2p30m1x4
# asm 1: vpand <d1=reg256#2,<_2p30m1x4=reg256#5,<d1=reg256#2
# asm 2: vpand <d1=%ymm1,<_2p30m1x4=%ymm4,<d1=%ymm1
vpand %ymm1,%ymm4,%ymm1

# qhasm: 4x ta = int32 mod0 * int32 d1
# asm 1: vpmuldq <mod0=reg256#11,<d1=reg256#2,>ta=reg256#5
# asm 2: vpmuldq <mod0=%ymm10,<d1=%ymm1,>ta=%ymm4
vpmuldq %ymm10,%ymm1,%ymm4

# qhasm: 4x out1 += ta
# asm 1: vpaddq <out1=reg256#4,<ta=reg256#5,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<ta=%ymm4,<out1=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#5
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm4
vmovapd 1408(%rsp),%ymm4

# qhasm: 4x carryy = out1 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#5,<out1=reg256#4,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm4,<out1=%ymm3,>carryy=%ymm3
vpaddq %ymm4,%ymm3,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: FVGS2 = stack_FVGS2
# asm 1: vmovapd <stack_FVGS2=stack256#4,>FVGS2=reg256#5
# asm 2: vmovapd <stack_FVGS2=224(%rsp),>FVGS2=%ymm4
vmovapd 224(%rsp),%ymm4

# qhasm: GSFV2 = FVGS2[1,0]
# asm 1: vpermq $0x4e,<FVGS2=reg256#5,>GSFV2=reg256#8
# asm 2: vpermq $0x4e,<FVGS2=%ymm4,>GSFV2=%ymm7
vpermq $0x4e,%ymm4,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS1
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS1=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS1=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out2 = ta + carryy
# asm 1: vpaddq <carryy=reg256#4,<ta=reg256#9,>out2=reg256#4
# asm 2: vpaddq <carryy=%ymm3,<ta=%ymm8,>out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV1
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV1=reg256#13,>tb=reg256#9
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV1=%ymm12,>tb=%ymm8
vpmuldq %ymm0,%ymm12,%ymm8

# qhasm: 4x out2 += tb
# asm 1: vpaddq <out2=reg256#4,<tb=reg256#9,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<tb=%ymm8,<out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS2
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS2=reg256#5,>ta=reg256#9
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS2=%ymm4,>ta=%ymm8
vpmuldq %ymm5,%ymm4,%ymm8

# qhasm: 4x out2 += ta
# asm 1: vpaddq <out2=reg256#4,<ta=reg256#9,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<ta=%ymm8,<out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV2
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV2=reg256#8,>tb=reg256#9
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV2=%ymm7,>tb=%ymm8
vpmuldq %ymm6,%ymm7,%ymm8

# qhasm: 4x out2 += tb
# asm 1: vpaddq <out2=reg256#4,<tb=reg256#9,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<tb=%ymm8,<out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod1
# asm 1: vpmuldq <d1=reg256#2,<mod1=reg256#14,>tb=reg256#9
# asm 2: vpmuldq <d1=%ymm1,<mod1=%ymm13,>tb=%ymm8
vpmuldq %ymm1,%ymm13,%ymm8

# qhasm: 4x out2 += tb
# asm 1: vpaddq <out2=reg256#4,<tb=reg256#9,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<tb=%ymm8,<out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: mod2 = stack_mod2
# asm 1: vmovapd <stack_mod2=stack256#22,>mod2=reg256#9
# asm 2: vmovapd <stack_mod2=800(%rsp),>mod2=%ymm8
vmovapd 800(%rsp),%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod2
# asm 1: vpmuldq <d0=reg256#12,<mod2=reg256#9,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod2=%ymm8,>ta=%ymm12
vpmuldq %ymm11,%ymm8,%ymm12

# qhasm: 4x out2 += ta
# asm 1: vpaddq <out2=reg256#4,<ta=reg256#13,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<ta=%ymm12,<out2=%ymm3
vpaddq %ymm3,%ymm12,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm12
vmovapd 1312(%rsp),%ymm12

# qhasm: _2p29x4 = stack_2p29x4
# asm 1: vmovapd <stack_2p29x4=stack256#42,>_2p29x4=reg256#15
# asm 2: vmovapd <stack_2p29x4=1440(%rsp),>_2p29x4=%ymm14
vmovapd 1440(%rsp),%ymm14

# qhasm: 4x d2 = int32 minvx4 * int32 out2
# asm 1: vpmuldq <minvx4=reg256#10,<out2=reg256#4,>d2=reg256#10
# asm 2: vpmuldq <minvx4=%ymm9,<out2=%ymm3,>d2=%ymm9
vpmuldq %ymm9,%ymm3,%ymm9

# qhasm: d2 &= _2p30m1x4
# asm 1: vpand <d2=reg256#10,<_2p30m1x4=reg256#13,<d2=reg256#10
# asm 2: vpand <d2=%ymm9,<_2p30m1x4=%ymm12,<d2=%ymm9
vpand %ymm9,%ymm12,%ymm9

# qhasm: d2 ^= _2p29x4
# asm 1: vpxor <d2=reg256#10,<_2p29x4=reg256#15,<d2=reg256#10
# asm 2: vpxor <d2=%ymm9,<_2p29x4=%ymm14,<d2=%ymm9
vpxor %ymm9,%ymm14,%ymm9

# qhasm: 4x d2 -=  _2p29x4
# asm 1: vpsubq <_2p29x4=reg256#15,<d2=reg256#10,<d2=reg256#10
# asm 2: vpsubq <_2p29x4=%ymm14,<d2=%ymm9,<d2=%ymm9
vpsubq %ymm14,%ymm9,%ymm9

# qhasm: 4x ta = int32 mod0 * int32 d2
# asm 1: vpmuldq <mod0=reg256#11,<d2=reg256#10,>ta=reg256#11
# asm 2: vpmuldq <mod0=%ymm10,<d2=%ymm9,>ta=%ymm10
vpmuldq %ymm10,%ymm9,%ymm10

# qhasm: 4x out2 += ta
# asm 1: vpaddq <out2=reg256#4,<ta=reg256#11,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<ta=%ymm10,<out2=%ymm3
vpaddq %ymm3,%ymm10,%ymm3

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#11
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm10
vmovapd 1408(%rsp),%ymm10

# qhasm: 4x carryy = out2 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#11,<out2=reg256#4,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm10,<out2=%ymm3,>carryy=%ymm3
vpaddq %ymm10,%ymm3,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: FVGS3 = stack_FVGS3
# asm 1: vmovapd <stack_FVGS3=stack256#5,>FVGS3=reg256#11
# asm 2: vmovapd <stack_FVGS3=256(%rsp),>FVGS3=%ymm10
vmovapd 256(%rsp),%ymm10

# qhasm: GSFV3 = FVGS3[1,0]
# asm 1: vpermq $0x4e,<FVGS3=reg256#11,>GSFV3=reg256#13
# asm 2: vpermq $0x4e,<FVGS3=%ymm10,>GSFV3=%ymm12
vpermq $0x4e,%ymm10,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS2
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS2=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS2=%ymm4,>ta=%ymm4
vpmuldq %ymm2,%ymm4,%ymm4

# qhasm: 4x out3 = ta + carryy
# asm 1: vpaddq <carryy=reg256#4,<ta=reg256#5,>out3=reg256#4
# asm 2: vpaddq <carryy=%ymm3,<ta=%ymm4,>out3=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV2
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV2=reg256#8,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV2=%ymm7,>tb=%ymm4
vpmuldq %ymm0,%ymm7,%ymm4

# qhasm: 4x out3 += tb
# asm 1: vpaddq <out3=reg256#4,<tb=reg256#5,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<tb=%ymm4,<out3=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS3
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS3=reg256#11,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS3=%ymm10,>ta=%ymm4
vpmuldq %ymm5,%ymm10,%ymm4

# qhasm: 4x out3 += ta
# asm 1: vpaddq <out3=reg256#4,<ta=reg256#5,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<ta=%ymm4,<out3=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV3
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV3=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV3=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out3 += tb
# asm 1: vpaddq <out3=reg256#4,<tb=reg256#5,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<tb=%ymm4,<out3=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod3 = stack_mod3
# asm 1: vmovapd <stack_mod3=stack256#23,>mod3=reg256#5
# asm 2: vmovapd <stack_mod3=832(%rsp),>mod3=%ymm4
vmovapd 832(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod1
# asm 1: vpmuldq <d2=reg256#10,<mod1=reg256#14,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod1=%ymm13,>ta=%ymm7
vpmuldq %ymm9,%ymm13,%ymm7

# qhasm: 4x out3 += ta
# asm 1: vpaddq <out3=reg256#4,<ta=reg256#8,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<ta=%ymm7,<out3=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod2
# asm 1: vpmuldq <d1=reg256#2,<mod2=reg256#9,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod2=%ymm8,>tb=%ymm7
vpmuldq %ymm1,%ymm8,%ymm7

# qhasm: 4x out3 += tb
# asm 1: vpaddq <out3=reg256#4,<tb=reg256#8,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<tb=%ymm7,<out3=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod3
# asm 1: vpmuldq <d0=reg256#12,<mod3=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod3=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out3 += ta
# asm 1: vpaddq <out3=reg256#4,<ta=reg256#8,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<ta=%ymm7,<out3=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm7
vmovapd 1312(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out3 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out3=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out3=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out3 &= _2p30m1x4
# asm 1: vpand <out3=reg256#4,<_2p30m1x4=reg256#8,<out3=reg256#4
# asm 2: vpand <out3=%ymm3,<_2p30m1x4=%ymm7,<out3=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS0 = out3
# asm 1: vmovapd <out3=reg256#4,>stack_FVGS0=stack256#1
# asm 2: vmovapd <out3=%ymm3,>stack_FVGS0=128(%rsp)
vmovapd %ymm3,128(%rsp)

# qhasm: FVGS4 = stack_FVGS4
# asm 1: vmovapd <stack_FVGS4=stack256#6,>FVGS4=reg256#4
# asm 2: vmovapd <stack_FVGS4=288(%rsp),>FVGS4=%ymm3
vmovapd 288(%rsp),%ymm3

# qhasm: GSFV4 = FVGS4[1,0]
# asm 1: vpermq $0x4e,<FVGS4=reg256#4,>GSFV4=reg256#8
# asm 2: vpermq $0x4e,<FVGS4=%ymm3,>GSFV4=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS3
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS3=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS3=%ymm10,>ta=%ymm10
vpmuldq %ymm2,%ymm10,%ymm10

# qhasm: 4x out4 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#11,>out4=reg256#11
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm10,>out4=%ymm10
vpaddq %ymm13,%ymm10,%ymm10

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV3
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV3=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV3=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out4 += tb
# asm 1: vpaddq <out4=reg256#11,<tb=reg256#13,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<tb=%ymm12,<out4=%ymm10
vpaddq %ymm10,%ymm12,%ymm10

# qhasm: 4x ta = int32 uuss0 * int32 FVGS4
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS4=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS4=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out4 += ta
# asm 1: vpaddq <out4=reg256#11,<ta=reg256#13,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<ta=%ymm12,<out4=%ymm10
vpaddq %ymm10,%ymm12,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV4
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV4=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV4=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out4 += tb
# asm 1: vpaddq <out4=reg256#11,<tb=reg256#13,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<tb=%ymm12,<out4=%ymm10
vpaddq %ymm10,%ymm12,%ymm10

# qhasm: mod4 = stack_mod4
# asm 1: vmovapd <stack_mod4=stack256#24,>mod4=reg256#13
# asm 2: vmovapd <stack_mod4=864(%rsp),>mod4=%ymm12
vmovapd 864(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod2
# asm 1: vpmuldq <d2=reg256#10,<mod2=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <d2=%ymm9,<mod2=%ymm8,>ta=%ymm8
vpmuldq %ymm9,%ymm8,%ymm8

# qhasm: 4x out4 += ta
# asm 1: vpaddq <out4=reg256#11,<ta=reg256#9,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<ta=%ymm8,<out4=%ymm10
vpaddq %ymm10,%ymm8,%ymm10

# qhasm: 4x tb = int32 d1 * int32 mod3
# asm 1: vpmuldq <d1=reg256#2,<mod3=reg256#5,>tb=reg256#9
# asm 2: vpmuldq <d1=%ymm1,<mod3=%ymm4,>tb=%ymm8
vpmuldq %ymm1,%ymm4,%ymm8

# qhasm: 4x out4 += tb
# asm 1: vpaddq <out4=reg256#11,<tb=reg256#9,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<tb=%ymm8,<out4=%ymm10
vpaddq %ymm10,%ymm8,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod4
# asm 1: vpmuldq <d0=reg256#12,<mod4=reg256#13,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod4=%ymm12,>ta=%ymm8
vpmuldq %ymm11,%ymm12,%ymm8

# qhasm: 4x out4 += ta
# asm 1: vpaddq <out4=reg256#11,<ta=reg256#9,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<ta=%ymm8,<out4=%ymm10
vpaddq %ymm10,%ymm8,%ymm10

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#9
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm8
vmovapd 1312(%rsp),%ymm8

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out4 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out4=reg256#11,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out4=%ymm10,>carryy=%ymm13
vpaddq %ymm13,%ymm10,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out4 &= _2p30m1x4
# asm 1: vpand <out4=reg256#11,<_2p30m1x4=reg256#9,<out4=reg256#11
# asm 2: vpand <out4=%ymm10,<_2p30m1x4=%ymm8,<out4=%ymm10
vpand %ymm10,%ymm8,%ymm10

# qhasm: stack_FVGS1 = out4
# asm 1: vmovapd <out4=reg256#11,>stack_FVGS1=stack256#2
# asm 2: vmovapd <out4=%ymm10,>stack_FVGS1=160(%rsp)
vmovapd %ymm10,160(%rsp)

# qhasm: FVGS5 = stack_FVGS5
# asm 1: vmovapd <stack_FVGS5=stack256#7,>FVGS5=reg256#9
# asm 2: vmovapd <stack_FVGS5=320(%rsp),>FVGS5=%ymm8
vmovapd 320(%rsp),%ymm8

# qhasm: GSFV5 = FVGS5[1,0]
# asm 1: vpermq $0x4e,<FVGS5=reg256#9,>GSFV5=reg256#11
# asm 2: vpermq $0x4e,<FVGS5=%ymm8,>GSFV5=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS4
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS4=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS4=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out5 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out5=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out5=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV4
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV4=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV4=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out5 += tb
# asm 1: vpaddq <out5=reg256#4,<tb=reg256#8,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<tb=%ymm7,<out5=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS5
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS5=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS5=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out5 += ta
# asm 1: vpaddq <out5=reg256#4,<ta=reg256#8,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<ta=%ymm7,<out5=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV5
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV5=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV5=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out5 += tb
# asm 1: vpaddq <out5=reg256#4,<tb=reg256#8,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<tb=%ymm7,<out5=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod5 = stack_mod5
# asm 1: vmovapd <stack_mod5=stack256#25,>mod5=reg256#8
# asm 2: vmovapd <stack_mod5=896(%rsp),>mod5=%ymm7
vmovapd 896(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod3
# asm 1: vpmuldq <d2=reg256#10,<mod3=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod3=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out5 += ta
# asm 1: vpaddq <out5=reg256#4,<ta=reg256#5,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<ta=%ymm4,<out5=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod4
# asm 1: vpmuldq <d1=reg256#2,<mod4=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod4=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out5 += tb
# asm 1: vpaddq <out5=reg256#4,<tb=reg256#5,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<tb=%ymm4,<out5=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod5
# asm 1: vpmuldq <d0=reg256#12,<mod5=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod5=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out5 += ta
# asm 1: vpaddq <out5=reg256#4,<ta=reg256#5,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<ta=%ymm4,<out5=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm4
vmovapd 1312(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out5 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out5=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out5=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out5 &= _2p30m1x4
# asm 1: vpand <out5=reg256#4,<_2p30m1x4=reg256#5,<out5=reg256#4
# asm 2: vpand <out5=%ymm3,<_2p30m1x4=%ymm4,<out5=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS2 = out5
# asm 1: vmovapd <out5=reg256#4,>stack_FVGS2=stack256#3
# asm 2: vmovapd <out5=%ymm3,>stack_FVGS2=192(%rsp)
vmovapd %ymm3,192(%rsp)

# qhasm: FVGS6 = stack_FVGS6
# asm 1: vmovapd <stack_FVGS6=stack256#8,>FVGS6=reg256#4
# asm 2: vmovapd <stack_FVGS6=352(%rsp),>FVGS6=%ymm3
vmovapd 352(%rsp),%ymm3

# qhasm: GSFV6 = FVGS6[1,0]
# asm 1: vpermq $0x4e,<FVGS6=reg256#4,>GSFV6=reg256#5
# asm 2: vpermq $0x4e,<FVGS6=%ymm3,>GSFV6=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS5
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS5=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS5=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out6 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out6=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out6=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV5
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV5=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV5=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out6 += tb
# asm 1: vpaddq <out6=reg256#9,<tb=reg256#11,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<tb=%ymm10,<out6=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS6
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS6=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS6=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out6 += ta
# asm 1: vpaddq <out6=reg256#9,<ta=reg256#11,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<ta=%ymm10,<out6=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV6
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV6=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV6=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out6 += tb
# asm 1: vpaddq <out6=reg256#9,<tb=reg256#11,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<tb=%ymm10,<out6=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod6 = stack_mod6
# asm 1: vmovapd <stack_mod6=stack256#26,>mod6=reg256#11
# asm 2: vmovapd <stack_mod6=928(%rsp),>mod6=%ymm10
vmovapd 928(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod4
# asm 1: vpmuldq <d2=reg256#10,<mod4=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod4=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out6 += ta
# asm 1: vpaddq <out6=reg256#9,<ta=reg256#13,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<ta=%ymm12,<out6=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod5
# asm 1: vpmuldq <d1=reg256#2,<mod5=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod5=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out6 += tb
# asm 1: vpaddq <out6=reg256#9,<tb=reg256#13,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<tb=%ymm12,<out6=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod6
# asm 1: vpmuldq <d0=reg256#12,<mod6=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod6=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out6 += ta
# asm 1: vpaddq <out6=reg256#9,<ta=reg256#13,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<ta=%ymm12,<out6=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm12
vmovapd 1312(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out6 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out6=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out6=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out6 &= _2p30m1x4
# asm 1: vpand <out6=reg256#9,<_2p30m1x4=reg256#13,<out6=reg256#9
# asm 2: vpand <out6=%ymm8,<_2p30m1x4=%ymm12,<out6=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS3 = out6
# asm 1: vmovapd <out6=reg256#9,>stack_FVGS3=stack256#4
# asm 2: vmovapd <out6=%ymm8,>stack_FVGS3=224(%rsp)
vmovapd %ymm8,224(%rsp)

# qhasm: FVGS7 = stack_FVGS7
# asm 1: vmovapd <stack_FVGS7=stack256#9,>FVGS7=reg256#9
# asm 2: vmovapd <stack_FVGS7=384(%rsp),>FVGS7=%ymm8
vmovapd 384(%rsp),%ymm8

# qhasm: GSFV7 = FVGS7[1,0]
# asm 1: vpermq $0x4e,<FVGS7=reg256#9,>GSFV7=reg256#13
# asm 2: vpermq $0x4e,<FVGS7=%ymm8,>GSFV7=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS6
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS6=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS6=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out7 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out7=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out7=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV6
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV6=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV6=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out7 += tb
# asm 1: vpaddq <out7=reg256#4,<tb=reg256#5,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<tb=%ymm4,<out7=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS7
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS7=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS7=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out7 += ta
# asm 1: vpaddq <out7=reg256#4,<ta=reg256#5,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<ta=%ymm4,<out7=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV7
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV7=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV7=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out7 += tb
# asm 1: vpaddq <out7=reg256#4,<tb=reg256#5,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<tb=%ymm4,<out7=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod7 = stack_mod7
# asm 1: vmovapd <stack_mod7=stack256#27,>mod7=reg256#5
# asm 2: vmovapd <stack_mod7=960(%rsp),>mod7=%ymm4
vmovapd 960(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod5
# asm 1: vpmuldq <d2=reg256#10,<mod5=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod5=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out7 += ta
# asm 1: vpaddq <out7=reg256#4,<ta=reg256#8,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<ta=%ymm7,<out7=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod6
# asm 1: vpmuldq <d1=reg256#2,<mod6=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod6=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out7 += tb
# asm 1: vpaddq <out7=reg256#4,<tb=reg256#8,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<tb=%ymm7,<out7=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod7
# asm 1: vpmuldq <d0=reg256#12,<mod7=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod7=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out7 += ta
# asm 1: vpaddq <out7=reg256#4,<ta=reg256#8,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<ta=%ymm7,<out7=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm7
vmovapd 1312(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out7 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out7=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out7=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out7 &= _2p30m1x4
# asm 1: vpand <out7=reg256#4,<_2p30m1x4=reg256#8,<out7=reg256#4
# asm 2: vpand <out7=%ymm3,<_2p30m1x4=%ymm7,<out7=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS4 = out7
# asm 1: vmovapd <out7=reg256#4,>stack_FVGS4=stack256#5
# asm 2: vmovapd <out7=%ymm3,>stack_FVGS4=256(%rsp)
vmovapd %ymm3,256(%rsp)

# qhasm: FVGS8 = stack_FVGS8
# asm 1: vmovapd <stack_FVGS8=stack256#10,>FVGS8=reg256#4
# asm 2: vmovapd <stack_FVGS8=416(%rsp),>FVGS8=%ymm3
vmovapd 416(%rsp),%ymm3

# qhasm: GSFV8 = FVGS8[1,0]
# asm 1: vpermq $0x4e,<FVGS8=reg256#4,>GSFV8=reg256#8
# asm 2: vpermq $0x4e,<FVGS8=%ymm3,>GSFV8=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS7
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS7=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS7=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out8 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out8=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out8=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV7
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV7=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV7=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out8 += tb
# asm 1: vpaddq <out8=reg256#9,<tb=reg256#13,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<tb=%ymm12,<out8=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS8
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS8=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS8=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out8 += ta
# asm 1: vpaddq <out8=reg256#9,<ta=reg256#13,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<ta=%ymm12,<out8=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV8
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV8=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV8=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out8 += tb
# asm 1: vpaddq <out8=reg256#9,<tb=reg256#13,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<tb=%ymm12,<out8=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod8 = stack_mod8
# asm 1: vmovapd <stack_mod8=stack256#28,>mod8=reg256#13
# asm 2: vmovapd <stack_mod8=992(%rsp),>mod8=%ymm12
vmovapd 992(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod6
# asm 1: vpmuldq <d2=reg256#10,<mod6=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod6=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out8 += ta
# asm 1: vpaddq <out8=reg256#9,<ta=reg256#11,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<ta=%ymm10,<out8=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod7
# asm 1: vpmuldq <d1=reg256#2,<mod7=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod7=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out8 += tb
# asm 1: vpaddq <out8=reg256#9,<tb=reg256#11,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<tb=%ymm10,<out8=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod8
# asm 1: vpmuldq <d0=reg256#12,<mod8=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod8=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out8 += ta
# asm 1: vpaddq <out8=reg256#9,<ta=reg256#11,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<ta=%ymm10,<out8=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm10
vmovapd 1312(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out8 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out8=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out8=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out8 &= _2p30m1x4
# asm 1: vpand <out8=reg256#9,<_2p30m1x4=reg256#11,<out8=reg256#9
# asm 2: vpand <out8=%ymm8,<_2p30m1x4=%ymm10,<out8=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS5 = out8
# asm 1: vmovapd <out8=reg256#9,>stack_FVGS5=stack256#6
# asm 2: vmovapd <out8=%ymm8,>stack_FVGS5=288(%rsp)
vmovapd %ymm8,288(%rsp)

# qhasm: FVGS9 = stack_FVGS9
# asm 1: vmovapd <stack_FVGS9=stack256#11,>FVGS9=reg256#9
# asm 2: vmovapd <stack_FVGS9=448(%rsp),>FVGS9=%ymm8
vmovapd 448(%rsp),%ymm8

# qhasm: GSFV9 = FVGS9[1,0]
# asm 1: vpermq $0x4e,<FVGS9=reg256#9,>GSFV9=reg256#11
# asm 2: vpermq $0x4e,<FVGS9=%ymm8,>GSFV9=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS8
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS8=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS8=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out9 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out9=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out9=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV8
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV8=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV8=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out9 += tb
# asm 1: vpaddq <out9=reg256#4,<tb=reg256#8,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<tb=%ymm7,<out9=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS9
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS9=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS9=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out9 += ta
# asm 1: vpaddq <out9=reg256#4,<ta=reg256#8,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<ta=%ymm7,<out9=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV9
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV9=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV9=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out9 += tb
# asm 1: vpaddq <out9=reg256#4,<tb=reg256#8,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<tb=%ymm7,<out9=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod9 = stack_mod9
# asm 1: vmovapd <stack_mod9=stack256#29,>mod9=reg256#8
# asm 2: vmovapd <stack_mod9=1024(%rsp),>mod9=%ymm7
vmovapd 1024(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod7
# asm 1: vpmuldq <d2=reg256#10,<mod7=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod7=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out9 += ta
# asm 1: vpaddq <out9=reg256#4,<ta=reg256#5,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<ta=%ymm4,<out9=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod8
# asm 1: vpmuldq <d1=reg256#2,<mod8=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod8=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out9 += tb
# asm 1: vpaddq <out9=reg256#4,<tb=reg256#5,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<tb=%ymm4,<out9=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod9
# asm 1: vpmuldq <d0=reg256#12,<mod9=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod9=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out9 += ta
# asm 1: vpaddq <out9=reg256#4,<ta=reg256#5,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<ta=%ymm4,<out9=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm4
vmovapd 1312(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out9 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out9=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out9=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out9 &= _2p30m1x4
# asm 1: vpand <out9=reg256#4,<_2p30m1x4=reg256#5,<out9=reg256#4
# asm 2: vpand <out9=%ymm3,<_2p30m1x4=%ymm4,<out9=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS6 = out9
# asm 1: vmovapd <out9=reg256#4,>stack_FVGS6=stack256#7
# asm 2: vmovapd <out9=%ymm3,>stack_FVGS6=320(%rsp)
vmovapd %ymm3,320(%rsp)

# qhasm: FVGS10 = stack_FVGS10
# asm 1: vmovapd <stack_FVGS10=stack256#12,>FVGS10=reg256#4
# asm 2: vmovapd <stack_FVGS10=480(%rsp),>FVGS10=%ymm3
vmovapd 480(%rsp),%ymm3

# qhasm: GSFV10 = FVGS10[1,0]
# asm 1: vpermq $0x4e,<FVGS10=reg256#4,>GSFV10=reg256#5
# asm 2: vpermq $0x4e,<FVGS10=%ymm3,>GSFV10=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS9
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS9=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS9=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out10 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out10=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out10=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV9
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV9=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV9=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out10 += tb
# asm 1: vpaddq <out10=reg256#9,<tb=reg256#11,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<tb=%ymm10,<out10=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS10
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS10=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS10=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out10 += ta
# asm 1: vpaddq <out10=reg256#9,<ta=reg256#11,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<ta=%ymm10,<out10=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV10
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV10=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV10=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out10 += tb
# asm 1: vpaddq <out10=reg256#9,<tb=reg256#11,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<tb=%ymm10,<out10=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod10 = stack_mod10
# asm 1: vmovapd <stack_mod10=stack256#30,>mod10=reg256#11
# asm 2: vmovapd <stack_mod10=1056(%rsp),>mod10=%ymm10
vmovapd 1056(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod8
# asm 1: vpmuldq <d2=reg256#10,<mod8=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod8=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out10 += ta
# asm 1: vpaddq <out10=reg256#9,<ta=reg256#13,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<ta=%ymm12,<out10=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod9
# asm 1: vpmuldq <d1=reg256#2,<mod9=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod9=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out10 += tb
# asm 1: vpaddq <out10=reg256#9,<tb=reg256#13,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<tb=%ymm12,<out10=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod10
# asm 1: vpmuldq <d0=reg256#12,<mod10=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod10=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out10 += ta
# asm 1: vpaddq <out10=reg256#9,<ta=reg256#13,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<ta=%ymm12,<out10=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm12
vmovapd 1312(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out10 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out10=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out10=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out10 &= _2p30m1x4
# asm 1: vpand <out10=reg256#9,<_2p30m1x4=reg256#13,<out10=reg256#9
# asm 2: vpand <out10=%ymm8,<_2p30m1x4=%ymm12,<out10=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS7 = out10
# asm 1: vmovapd <out10=reg256#9,>stack_FVGS7=stack256#8
# asm 2: vmovapd <out10=%ymm8,>stack_FVGS7=352(%rsp)
vmovapd %ymm8,352(%rsp)

# qhasm: FVGS11 = stack_FVGS11
# asm 1: vmovapd <stack_FVGS11=stack256#13,>FVGS11=reg256#9
# asm 2: vmovapd <stack_FVGS11=512(%rsp),>FVGS11=%ymm8
vmovapd 512(%rsp),%ymm8

# qhasm: GSFV11 = FVGS11[1,0]
# asm 1: vpermq $0x4e,<FVGS11=reg256#9,>GSFV11=reg256#13
# asm 2: vpermq $0x4e,<FVGS11=%ymm8,>GSFV11=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS10
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS10=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS10=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out11 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out11=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out11=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV10
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV10=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV10=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out11 += tb
# asm 1: vpaddq <out11=reg256#4,<tb=reg256#5,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<tb=%ymm4,<out11=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS11
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS11=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS11=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out11 += ta
# asm 1: vpaddq <out11=reg256#4,<ta=reg256#5,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<ta=%ymm4,<out11=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV11
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV11=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV11=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out11 += tb
# asm 1: vpaddq <out11=reg256#4,<tb=reg256#5,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<tb=%ymm4,<out11=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod11 = stack_mod11
# asm 1: vmovapd <stack_mod11=stack256#31,>mod11=reg256#5
# asm 2: vmovapd <stack_mod11=1088(%rsp),>mod11=%ymm4
vmovapd 1088(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod9
# asm 1: vpmuldq <d2=reg256#10,<mod9=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod9=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out11 += ta
# asm 1: vpaddq <out11=reg256#4,<ta=reg256#8,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<ta=%ymm7,<out11=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod10
# asm 1: vpmuldq <d1=reg256#2,<mod10=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod10=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out11 += tb
# asm 1: vpaddq <out11=reg256#4,<tb=reg256#8,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<tb=%ymm7,<out11=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod11
# asm 1: vpmuldq <d0=reg256#12,<mod11=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod11=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out11 += ta
# asm 1: vpaddq <out11=reg256#4,<ta=reg256#8,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<ta=%ymm7,<out11=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm7
vmovapd 1312(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out11 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out11=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out11=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out11 &= _2p30m1x4
# asm 1: vpand <out11=reg256#4,<_2p30m1x4=reg256#8,<out11=reg256#4
# asm 2: vpand <out11=%ymm3,<_2p30m1x4=%ymm7,<out11=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS8 = out11
# asm 1: vmovapd <out11=reg256#4,>stack_FVGS8=stack256#9
# asm 2: vmovapd <out11=%ymm3,>stack_FVGS8=384(%rsp)
vmovapd %ymm3,384(%rsp)

# qhasm: FVGS12 = stack_FVGS12
# asm 1: vmovapd <stack_FVGS12=stack256#14,>FVGS12=reg256#4
# asm 2: vmovapd <stack_FVGS12=544(%rsp),>FVGS12=%ymm3
vmovapd 544(%rsp),%ymm3

# qhasm: GSFV12 = FVGS12[1,0]
# asm 1: vpermq $0x4e,<FVGS12=reg256#4,>GSFV12=reg256#8
# asm 2: vpermq $0x4e,<FVGS12=%ymm3,>GSFV12=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS11
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS11=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS11=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out12 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out12=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out12=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV11
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV11=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV11=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out12 += tb
# asm 1: vpaddq <out12=reg256#9,<tb=reg256#13,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<tb=%ymm12,<out12=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS12
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS12=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS12=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out12 += ta
# asm 1: vpaddq <out12=reg256#9,<ta=reg256#13,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<ta=%ymm12,<out12=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV12
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV12=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV12=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out12 += tb
# asm 1: vpaddq <out12=reg256#9,<tb=reg256#13,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<tb=%ymm12,<out12=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod12 = stack_mod12
# asm 1: vmovapd <stack_mod12=stack256#32,>mod12=reg256#13
# asm 2: vmovapd <stack_mod12=1120(%rsp),>mod12=%ymm12
vmovapd 1120(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod10
# asm 1: vpmuldq <d2=reg256#10,<mod10=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod10=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out12 += ta
# asm 1: vpaddq <out12=reg256#9,<ta=reg256#11,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<ta=%ymm10,<out12=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod11
# asm 1: vpmuldq <d1=reg256#2,<mod11=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod11=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out12 += tb
# asm 1: vpaddq <out12=reg256#9,<tb=reg256#11,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<tb=%ymm10,<out12=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod12
# asm 1: vpmuldq <d0=reg256#12,<mod12=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod12=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out12 += ta
# asm 1: vpaddq <out12=reg256#9,<ta=reg256#11,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<ta=%ymm10,<out12=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm10
vmovapd 1312(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out12 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out12=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out12=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out12 &= _2p30m1x4
# asm 1: vpand <out12=reg256#9,<_2p30m1x4=reg256#11,<out12=reg256#9
# asm 2: vpand <out12=%ymm8,<_2p30m1x4=%ymm10,<out12=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS9 = out12
# asm 1: vmovapd <out12=reg256#9,>stack_FVGS9=stack256#10
# asm 2: vmovapd <out12=%ymm8,>stack_FVGS9=416(%rsp)
vmovapd %ymm8,416(%rsp)

# qhasm: FVGS13 = stack_FVGS13
# asm 1: vmovapd <stack_FVGS13=stack256#15,>FVGS13=reg256#9
# asm 2: vmovapd <stack_FVGS13=576(%rsp),>FVGS13=%ymm8
vmovapd 576(%rsp),%ymm8

# qhasm: GSFV13 = FVGS13[1,0]
# asm 1: vpermq $0x4e,<FVGS13=reg256#9,>GSFV13=reg256#11
# asm 2: vpermq $0x4e,<FVGS13=%ymm8,>GSFV13=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS12
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS12=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS12=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out13 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out13=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out13=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV12
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV12=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV12=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out13 += tb
# asm 1: vpaddq <out13=reg256#4,<tb=reg256#8,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<tb=%ymm7,<out13=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS13
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS13=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS13=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out13 += ta
# asm 1: vpaddq <out13=reg256#4,<ta=reg256#8,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<ta=%ymm7,<out13=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV13
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV13=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV13=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out13 += tb
# asm 1: vpaddq <out13=reg256#4,<tb=reg256#8,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<tb=%ymm7,<out13=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod13 = stack_mod13
# asm 1: vmovapd <stack_mod13=stack256#33,>mod13=reg256#8
# asm 2: vmovapd <stack_mod13=1152(%rsp),>mod13=%ymm7
vmovapd 1152(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod11
# asm 1: vpmuldq <d2=reg256#10,<mod11=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod11=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out13 += ta
# asm 1: vpaddq <out13=reg256#4,<ta=reg256#5,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<ta=%ymm4,<out13=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod12
# asm 1: vpmuldq <d1=reg256#2,<mod12=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod12=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out13 += tb
# asm 1: vpaddq <out13=reg256#4,<tb=reg256#5,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<tb=%ymm4,<out13=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod13
# asm 1: vpmuldq <d0=reg256#12,<mod13=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod13=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out13 += ta
# asm 1: vpaddq <out13=reg256#4,<ta=reg256#5,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<ta=%ymm4,<out13=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm4
vmovapd 1312(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out13 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out13=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out13=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out13 &= _2p30m1x4
# asm 1: vpand <out13=reg256#4,<_2p30m1x4=reg256#5,<out13=reg256#4
# asm 2: vpand <out13=%ymm3,<_2p30m1x4=%ymm4,<out13=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS10 = out13
# asm 1: vmovapd <out13=reg256#4,>stack_FVGS10=stack256#11
# asm 2: vmovapd <out13=%ymm3,>stack_FVGS10=448(%rsp)
vmovapd %ymm3,448(%rsp)

# qhasm: FVGS14 = stack_FVGS14
# asm 1: vmovapd <stack_FVGS14=stack256#16,>FVGS14=reg256#4
# asm 2: vmovapd <stack_FVGS14=608(%rsp),>FVGS14=%ymm3
vmovapd 608(%rsp),%ymm3

# qhasm: GSFV14 = FVGS14[1,0]
# asm 1: vpermq $0x4e,<FVGS14=reg256#4,>GSFV14=reg256#5
# asm 2: vpermq $0x4e,<FVGS14=%ymm3,>GSFV14=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS13
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS13=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS13=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out14 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out14=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out14=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV13
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV13=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV13=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out14 += tb
# asm 1: vpaddq <out14=reg256#9,<tb=reg256#11,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<tb=%ymm10,<out14=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS14
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS14=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS14=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out14 += ta
# asm 1: vpaddq <out14=reg256#9,<ta=reg256#11,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<ta=%ymm10,<out14=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV14
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV14=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV14=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out14 += tb
# asm 1: vpaddq <out14=reg256#9,<tb=reg256#11,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<tb=%ymm10,<out14=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod14 = stack_mod14
# asm 1: vmovapd <stack_mod14=stack256#34,>mod14=reg256#11
# asm 2: vmovapd <stack_mod14=1184(%rsp),>mod14=%ymm10
vmovapd 1184(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod12
# asm 1: vpmuldq <d2=reg256#10,<mod12=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod12=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out14 += ta
# asm 1: vpaddq <out14=reg256#9,<ta=reg256#13,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<ta=%ymm12,<out14=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod13
# asm 1: vpmuldq <d1=reg256#2,<mod13=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod13=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out14 += tb
# asm 1: vpaddq <out14=reg256#9,<tb=reg256#13,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<tb=%ymm12,<out14=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod14
# asm 1: vpmuldq <d0=reg256#12,<mod14=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod14=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out14 += ta
# asm 1: vpaddq <out14=reg256#9,<ta=reg256#13,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<ta=%ymm12,<out14=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm12
vmovapd 1312(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out14 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out14=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out14=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out14 &= _2p30m1x4
# asm 1: vpand <out14=reg256#9,<_2p30m1x4=reg256#13,<out14=reg256#9
# asm 2: vpand <out14=%ymm8,<_2p30m1x4=%ymm12,<out14=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS11 = out14
# asm 1: vmovapd <out14=reg256#9,>stack_FVGS11=stack256#12
# asm 2: vmovapd <out14=%ymm8,>stack_FVGS11=480(%rsp)
vmovapd %ymm8,480(%rsp)

# qhasm: FVGS15 = stack_FVGS15
# asm 1: vmovapd <stack_FVGS15=stack256#17,>FVGS15=reg256#9
# asm 2: vmovapd <stack_FVGS15=640(%rsp),>FVGS15=%ymm8
vmovapd 640(%rsp),%ymm8

# qhasm: GSFV15 = FVGS15[1,0]
# asm 1: vpermq $0x4e,<FVGS15=reg256#9,>GSFV15=reg256#13
# asm 2: vpermq $0x4e,<FVGS15=%ymm8,>GSFV15=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS14
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS14=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS14=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out15 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out15=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out15=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV14
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV14=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV14=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out15 += tb
# asm 1: vpaddq <out15=reg256#4,<tb=reg256#5,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<tb=%ymm4,<out15=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS15
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS15=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS15=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out15 += ta
# asm 1: vpaddq <out15=reg256#4,<ta=reg256#5,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<ta=%ymm4,<out15=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV15
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV15=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV15=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out15 += tb
# asm 1: vpaddq <out15=reg256#4,<tb=reg256#5,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<tb=%ymm4,<out15=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod15 = stack_mod15
# asm 1: vmovapd <stack_mod15=stack256#35,>mod15=reg256#5
# asm 2: vmovapd <stack_mod15=1216(%rsp),>mod15=%ymm4
vmovapd 1216(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod13
# asm 1: vpmuldq <d2=reg256#10,<mod13=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod13=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out15 += ta
# asm 1: vpaddq <out15=reg256#4,<ta=reg256#8,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<ta=%ymm7,<out15=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod14
# asm 1: vpmuldq <d1=reg256#2,<mod14=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod14=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out15 += tb
# asm 1: vpaddq <out15=reg256#4,<tb=reg256#8,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<tb=%ymm7,<out15=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod15
# asm 1: vpmuldq <d0=reg256#12,<mod15=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod15=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out15 += ta
# asm 1: vpaddq <out15=reg256#4,<ta=reg256#8,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<ta=%ymm7,<out15=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm7
vmovapd 1312(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out15 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out15=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out15=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out15 &= _2p30m1x4
# asm 1: vpand <out15=reg256#4,<_2p30m1x4=reg256#8,<out15=reg256#4
# asm 2: vpand <out15=%ymm3,<_2p30m1x4=%ymm7,<out15=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS12 = out15
# asm 1: vmovapd <out15=reg256#4,>stack_FVGS12=stack256#13
# asm 2: vmovapd <out15=%ymm3,>stack_FVGS12=512(%rsp)
vmovapd %ymm3,512(%rsp)

# qhasm: FVGS16 = stack_FVGS16
# asm 1: vmovapd <stack_FVGS16=stack256#18,>FVGS16=reg256#4
# asm 2: vmovapd <stack_FVGS16=672(%rsp),>FVGS16=%ymm3
vmovapd 672(%rsp),%ymm3

# qhasm: GSFV16 = FVGS16[1,0]
# asm 1: vpermq $0x4e,<FVGS16=reg256#4,>GSFV16=reg256#8
# asm 2: vpermq $0x4e,<FVGS16=%ymm3,>GSFV16=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS15
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS15=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS15=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out16 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out16=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out16=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV15
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV15=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV15=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out16 += tb
# asm 1: vpaddq <out16=reg256#9,<tb=reg256#13,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<tb=%ymm12,<out16=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS16
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS16=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS16=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out16 += ta
# asm 1: vpaddq <out16=reg256#9,<ta=reg256#13,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<ta=%ymm12,<out16=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV16
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV16=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV16=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out16 += tb
# asm 1: vpaddq <out16=reg256#9,<tb=reg256#13,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<tb=%ymm12,<out16=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod16 = stack_mod16
# asm 1: vmovapd <stack_mod16=stack256#36,>mod16=reg256#13
# asm 2: vmovapd <stack_mod16=1248(%rsp),>mod16=%ymm12
vmovapd 1248(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod14
# asm 1: vpmuldq <d2=reg256#10,<mod14=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod14=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out16 += ta
# asm 1: vpaddq <out16=reg256#9,<ta=reg256#11,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<ta=%ymm10,<out16=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod15
# asm 1: vpmuldq <d1=reg256#2,<mod15=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod15=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out16 += tb
# asm 1: vpaddq <out16=reg256#9,<tb=reg256#11,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<tb=%ymm10,<out16=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod16
# asm 1: vpmuldq <d0=reg256#12,<mod16=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod16=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out16 += ta
# asm 1: vpaddq <out16=reg256#9,<ta=reg256#11,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<ta=%ymm10,<out16=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm10
vmovapd 1312(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 1408(%rsp),%ymm13

# qhasm: 4x carryy = out16 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out16=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out16=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out16 &= _2p30m1x4
# asm 1: vpand <out16=reg256#9,<_2p30m1x4=reg256#11,<out16=reg256#9
# asm 2: vpand <out16=%ymm8,<_2p30m1x4=%ymm10,<out16=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS13 = out16
# asm 1: vmovapd <out16=reg256#9,>stack_FVGS13=stack256#14
# asm 2: vmovapd <out16=%ymm8,>stack_FVGS13=544(%rsp)
vmovapd %ymm8,544(%rsp)

# qhasm: FVGS17 = stack_FVGS17
# asm 1: vmovapd <stack_FVGS17=stack256#19,>FVGS17=reg256#9
# asm 2: vmovapd <stack_FVGS17=704(%rsp),>FVGS17=%ymm8
vmovapd 704(%rsp),%ymm8

# qhasm: GSFV17 = FVGS17[1,0]
# asm 1: vpermq $0x4e,<FVGS17=reg256#9,>GSFV17=reg256#11
# asm 2: vpermq $0x4e,<FVGS17=%ymm8,>GSFV17=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS16
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS16=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS16=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out17 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out17=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out17=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV16
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV16=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV16=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out17 += tb
# asm 1: vpaddq <out17=reg256#4,<tb=reg256#8,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<tb=%ymm7,<out17=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS17
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS17=reg256#9,>ta=reg256#6
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS17=%ymm8,>ta=%ymm5
vpmuldq %ymm5,%ymm8,%ymm5

# qhasm: 4x out17 += ta
# asm 1: vpaddq <out17=reg256#4,<ta=reg256#6,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<ta=%ymm5,<out17=%ymm3
vpaddq %ymm3,%ymm5,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV17
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV17=reg256#11,>tb=reg256#6
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV17=%ymm10,>tb=%ymm5
vpmuldq %ymm6,%ymm10,%ymm5

# qhasm: 4x out17 += tb
# asm 1: vpaddq <out17=reg256#4,<tb=reg256#6,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<tb=%ymm5,<out17=%ymm3
vpaddq %ymm3,%ymm5,%ymm3

# qhasm: mod17 = stack_mod17
# asm 1: vmovapd <stack_mod17=stack256#37,>mod17=reg256#6
# asm 2: vmovapd <stack_mod17=1280(%rsp),>mod17=%ymm5
vmovapd 1280(%rsp),%ymm5

# qhasm: 4x ta = int32 d2 * int32 mod15
# asm 1: vpmuldq <d2=reg256#10,<mod15=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod15=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out17 += ta
# asm 1: vpaddq <out17=reg256#4,<ta=reg256#5,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<ta=%ymm4,<out17=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod16
# asm 1: vpmuldq <d1=reg256#2,<mod16=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod16=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out17 += tb
# asm 1: vpaddq <out17=reg256#4,<tb=reg256#5,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<tb=%ymm4,<out17=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod17
# asm 1: vpmuldq <d0=reg256#12,<mod17=reg256#6,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod17=%ymm5,>ta=%ymm4
vpmuldq %ymm11,%ymm5,%ymm4

# qhasm: 4x out17 += ta
# asm 1: vpaddq <out17=reg256#4,<ta=reg256#5,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<ta=%ymm4,<out17=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#38,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=1312(%rsp),>_2p30m1x4=%ymm4
vmovapd 1312(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#41,>_2p63m2p33x4=reg256#7
# asm 2: vmovapd <stack_2p63m2p33x4=1408(%rsp),>_2p63m2p33x4=%ymm6
vmovapd 1408(%rsp),%ymm6

# qhasm: 4x carryy = out17 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#7,<out17=reg256#4,>carryy=reg256#8
# asm 2: vpaddq <_2p63m2p33x4=%ymm6,<out17=%ymm3,>carryy=%ymm7
vpaddq %ymm6,%ymm3,%ymm7

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#8,<carryy=reg256#8
# asm 2: vpsrlq $30,<carryy=%ymm7,<carryy=%ymm7
vpsrlq $30,%ymm7,%ymm7

# qhasm: out17 &= _2p30m1x4
# asm 1: vpand <out17=reg256#4,<_2p30m1x4=reg256#5,<out17=reg256#4
# asm 2: vpand <out17=%ymm3,<_2p30m1x4=%ymm4,<out17=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS14 = out17
# asm 1: vmovapd <out17=reg256#4,>stack_FVGS14=stack256#15
# asm 2: vmovapd <out17=%ymm3,>stack_FVGS14=576(%rsp)
vmovapd %ymm3,576(%rsp)

# qhasm: 4x ta = int32 uuss1 * int32 FVGS17
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS17=reg256#9,>ta=reg256#3
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS17=%ymm8,>ta=%ymm2
vpmuldq %ymm2,%ymm8,%ymm2

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV17
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV17=reg256#11,>tb=reg256#1
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV17=%ymm10,>tb=%ymm0
vpmuldq %ymm0,%ymm10,%ymm0

# qhasm: 4x out18plus = ta + tb
# asm 1: vpaddq <tb=reg256#1,<ta=reg256#3,>out18plus=reg256#1
# asm 2: vpaddq <tb=%ymm0,<ta=%ymm2,>out18plus=%ymm0
vpaddq %ymm0,%ymm2,%ymm0

# qhasm: 4x ta = int32 mod17 * int32 d1
# asm 1: vpmuldq <mod17=reg256#6,<d1=reg256#2,>ta=reg256#2
# asm 2: vpmuldq <mod17=%ymm5,<d1=%ymm1,>ta=%ymm1
vpmuldq %ymm5,%ymm1,%ymm1

# qhasm: 4x tb = int32 mod16 * int32 d2
# asm 1: vpmuldq <mod16=reg256#13,<d2=reg256#10,>tb=reg256#3
# asm 2: vpmuldq <mod16=%ymm12,<d2=%ymm9,>tb=%ymm2
vpmuldq %ymm12,%ymm9,%ymm2

# qhasm: 4x tb += carryy
# asm 1: vpaddq <tb=reg256#3,<carryy=reg256#8,<tb=reg256#3
# asm 2: vpaddq <tb=%ymm2,<carryy=%ymm7,<tb=%ymm2
vpaddq %ymm2,%ymm7,%ymm2

# qhasm: 4x out18 = ta + tb
# asm 1: vpaddq <tb=reg256#3,<ta=reg256#2,>out18=reg256#2
# asm 2: vpaddq <tb=%ymm2,<ta=%ymm1,>out18=%ymm1
vpaddq %ymm2,%ymm1,%ymm1

# qhasm: 4x out18 += out18plus
# asm 1: vpaddq <out18=reg256#2,<out18plus=reg256#1,<out18=reg256#2
# asm 2: vpaddq <out18=%ymm1,<out18plus=%ymm0,<out18=%ymm1
vpaddq %ymm1,%ymm0,%ymm1

# qhasm: 4x carryy = out18 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#7,<out18=reg256#2,>carryy=reg256#1
# asm 2: vpaddq <_2p63m2p33x4=%ymm6,<out18=%ymm1,>carryy=%ymm0
vpaddq %ymm6,%ymm1,%ymm0

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#1,<carryy=reg256#1
# asm 2: vpsrlq $30,<carryy=%ymm0,<carryy=%ymm0
vpsrlq $30,%ymm0,%ymm0

# qhasm: out18 &= _2p30m1x4
# asm 1: vpand <out18=reg256#2,<_2p30m1x4=reg256#5,<out18=reg256#2
# asm 2: vpand <out18=%ymm1,<_2p30m1x4=%ymm4,<out18=%ymm1
vpand %ymm1,%ymm4,%ymm1

# qhasm: stack_FVGS15 = out18
# asm 1: vmovapd <out18=reg256#2,>stack_FVGS15=stack256#16
# asm 2: vmovapd <out18=%ymm1,>stack_FVGS15=608(%rsp)
vmovapd %ymm1,608(%rsp)

# qhasm: _2p33x4 = stack_2p33x4
# asm 1: vmovapd <stack_2p33x4=stack256#39,>_2p33x4=reg256#2
# asm 2: vmovapd <stack_2p33x4=1344(%rsp),>_2p33x4=%ymm1
vmovapd 1344(%rsp),%ymm1

# qhasm: 4x tb = int32 mod17 * int32 d2
# asm 1: vpmuldq <mod17=reg256#6,<d2=reg256#10,>tb=reg256#3
# asm 2: vpmuldq <mod17=%ymm5,<d2=%ymm9,>tb=%ymm2
vpmuldq %ymm5,%ymm9,%ymm2

# qhasm: 4x out19 = tb + carryy
# asm 1: vpaddq <carryy=reg256#1,<tb=reg256#3,>out19=reg256#1
# asm 2: vpaddq <carryy=%ymm0,<tb=%ymm2,>out19=%ymm0
vpaddq %ymm0,%ymm2,%ymm0

# qhasm: 4x out20 = out19 + _2p63m2p33x4
# asm 1: vpaddq <_2p63m2p33x4=reg256#7,<out19=reg256#1,>out20=reg256#3
# asm 2: vpaddq <_2p63m2p33x4=%ymm6,<out19=%ymm0,>out20=%ymm2
vpaddq %ymm6,%ymm0,%ymm2

# qhasm: 4x out20 unsigned >>= 30
# asm 1: vpsrlq $30,<out20=reg256#3,<out20=reg256#3
# asm 2: vpsrlq $30,<out20=%ymm2,<out20=%ymm2
vpsrlq $30,%ymm2,%ymm2

# qhasm: 4x out20 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#2,<out20=reg256#3,<out20=reg256#3
# asm 2: vpsubq <_2p33x4=%ymm1,<out20=%ymm2,<out20=%ymm2
vpsubq %ymm1,%ymm2,%ymm2

# qhasm: out19 &= _2p30m1x4
# asm 1: vpand <out19=reg256#1,<_2p30m1x4=reg256#5,<out19=reg256#1
# asm 2: vpand <out19=%ymm0,<_2p30m1x4=%ymm4,<out19=%ymm0
vpand %ymm0,%ymm4,%ymm0

# qhasm: stack_FVGS17 = out20
# asm 1: vmovapd <out20=reg256#3,>stack_FVGS17=stack256#17
# asm 2: vmovapd <out20=%ymm2,>stack_FVGS17=640(%rsp)
vmovapd %ymm2,640(%rsp)

# qhasm: z = stack_FVGS17[1]
# asm 1: movq <stack_FVGS17=stack256#17,>z=int64#1
# asm 2: movq <stack_FVGS17=648(%rsp),>z=%rdi
movq 648(%rsp),%rdi

# qhasm: (int64) z >>= 63
# asm 1: sar  $63,<z=int64#1
# asm 2: sar  $63,<z=%rdi
sar  $63,%rdi

# qhasm: stack_FVGS16 = out19
# asm 1: vmovapd <out19=reg256#1,>stack_FVGS16=stack256#18
# asm 2: vmovapd <out19=%ymm0,>stack_FVGS16=672(%rsp)
vmovapd %ymm0,672(%rsp)

# qhasm: table = stack_out
# asm 1: movq <stack_out=stack64#1,>table=int64#2
# asm 2: movq <stack_out=0(%rsp),>table=%rsi
movq 0(%rsp),%rsi

# qhasm: a0 = stack_FVGS0[1]
# asm 1: movq <stack_FVGS0=stack256#1,>a0=int64#3
# asm 2: movq <stack_FVGS0=136(%rsp),>a0=%rdx
movq 136(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod0[0]
# asm 1: andq <stack_mod0=stack256#20,<h=int64#4
# asm 2: andq <stack_mod0=736(%rsp),<h=%rcx
andq 736(%rsp),%rcx

# qhasm: a0 += h
# asm 1: add  <h=int64#4,<a0=int64#3
# asm 2: add  <h=%rcx,<a0=%rdx
add  %rcx,%rdx

# qhasm: t1 = stack_FVGS1[1]
# asm 1: movq <stack_FVGS1=stack256#2,>t1=int64#4
# asm 2: movq <stack_FVGS1=168(%rsp),>t1=%rcx
movq 168(%rsp),%rcx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod1[0]
# asm 1: andq <stack_mod1=stack256#21,<h=int64#5
# asm 2: andq <stack_mod1=768(%rsp),<h=%r8
andq 768(%rsp),%r8

# qhasm: t1 += h
# asm 1: add  <h=int64#5,<t1=int64#4
# asm 2: add  <h=%r8,<t1=%rcx
add  %r8,%rcx

# qhasm: t1 <<= 30
# asm 1: shl  $30,<t1=int64#4
# asm 2: shl  $30,<t1=%rcx
shl  $30,%rcx

# qhasm: a0 += t1
# asm 1: add  <t1=int64#4,<a0=int64#3
# asm 2: add  <t1=%rcx,<a0=%rdx
add  %rcx,%rdx

# qhasm: t2 = stack_FVGS2[1]
# asm 1: movq <stack_FVGS2=stack256#3,>t2=int64#4
# asm 2: movq <stack_FVGS2=200(%rsp),>t2=%rcx
movq 200(%rsp),%rcx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod2[0]
# asm 1: andq <stack_mod2=stack256#22,<h=int64#5
# asm 2: andq <stack_mod2=800(%rsp),<h=%r8
andq 800(%rsp),%r8

# qhasm: t2 += h
# asm 1: add  <h=int64#5,<t2=int64#4
# asm 2: add  <h=%r8,<t2=%rcx
add  %r8,%rcx

# qhasm: a1 = t2
# asm 1: mov  <t2=int64#4,>a1=int64#5
# asm 2: mov  <t2=%rcx,>a1=%r8
mov  %rcx,%r8

# qhasm: t2 <<= 60
# asm 1: shl  $60,<t2=int64#4
# asm 2: shl  $60,<t2=%rcx
shl  $60,%rcx

# qhasm: (int64) a1 >>= 4
# asm 1: sar  $4,<a1=int64#5
# asm 2: sar  $4,<a1=%r8
sar  $4,%r8

# qhasm: carry? a0 += t2
# asm 1: add  <t2=int64#4,<a0=int64#3
# asm 2: add  <t2=%rcx,<a0=%rdx
add  %rcx,%rdx

# qhasm: a1 += 0 + carry
# asm 1: adc $0,<a1=int64#5
# asm 2: adc $0,<a1=%r8
adc $0,%r8

# qhasm: mem64[table +  0] = a0
# asm 1: movq   <a0=int64#3,0(<table=int64#2)
# asm 2: movq   <a0=%rdx,0(<table=%rsi)
movq   %rdx,0(%rsi)

# qhasm: t3 = stack_FVGS3[1]
# asm 1: movq <stack_FVGS3=stack256#4,>t3=int64#3
# asm 2: movq <stack_FVGS3=232(%rsp),>t3=%rdx
movq 232(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod3[0]
# asm 1: andq <stack_mod3=stack256#23,<h=int64#4
# asm 2: andq <stack_mod3=832(%rsp),<h=%rcx
andq 832(%rsp),%rcx

# qhasm: t3 += h
# asm 1: add  <h=int64#4,<t3=int64#3
# asm 2: add  <h=%rcx,<t3=%rdx
add  %rcx,%rdx

# qhasm: t3 <<= 26
# asm 1: shl  $26,<t3=int64#3
# asm 2: shl  $26,<t3=%rdx
shl  $26,%rdx

# qhasm: a1 += t3
# asm 1: add  <t3=int64#3,<a1=int64#5
# asm 2: add  <t3=%rdx,<a1=%r8
add  %rdx,%r8

# qhasm: t4 = stack_FVGS4[1]
# asm 1: movq <stack_FVGS4=stack256#5,>t4=int64#3
# asm 2: movq <stack_FVGS4=264(%rsp),>t4=%rdx
movq 264(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod4[0]
# asm 1: andq <stack_mod4=stack256#24,<h=int64#4
# asm 2: andq <stack_mod4=864(%rsp),<h=%rcx
andq 864(%rsp),%rcx

# qhasm: t4 += h
# asm 1: add  <h=int64#4,<t4=int64#3
# asm 2: add  <h=%rcx,<t4=%rdx
add  %rcx,%rdx

# qhasm: a2 = t4
# asm 1: mov  <t4=int64#3,>a2=int64#4
# asm 2: mov  <t4=%rdx,>a2=%rcx
mov  %rdx,%rcx

# qhasm: t4 <<= 56
# asm 1: shl  $56,<t4=int64#3
# asm 2: shl  $56,<t4=%rdx
shl  $56,%rdx

# qhasm: (int64) a2 >>= 8
# asm 1: sar  $8,<a2=int64#4
# asm 2: sar  $8,<a2=%rcx
sar  $8,%rcx

# qhasm: carry? a1 += t4
# asm 1: add  <t4=int64#3,<a1=int64#5
# asm 2: add  <t4=%rdx,<a1=%r8
add  %rdx,%r8

# qhasm: a2 += 0 + carry
# asm 1: adc $0,<a2=int64#4
# asm 2: adc $0,<a2=%rcx
adc $0,%rcx

# qhasm: mem64[table +  8] = a1
# asm 1: movq   <a1=int64#5,8(<table=int64#2)
# asm 2: movq   <a1=%r8,8(<table=%rsi)
movq   %r8,8(%rsi)

# qhasm: t5 = stack_FVGS5[1]
# asm 1: movq <stack_FVGS5=stack256#6,>t5=int64#3
# asm 2: movq <stack_FVGS5=296(%rsp),>t5=%rdx
movq 296(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod5[0]
# asm 1: andq <stack_mod5=stack256#25,<h=int64#5
# asm 2: andq <stack_mod5=896(%rsp),<h=%r8
andq 896(%rsp),%r8

# qhasm: t5 += h
# asm 1: add  <h=int64#5,<t5=int64#3
# asm 2: add  <h=%r8,<t5=%rdx
add  %r8,%rdx

# qhasm: t5 <<= 22
# asm 1: shl  $22,<t5=int64#3
# asm 2: shl  $22,<t5=%rdx
shl  $22,%rdx

# qhasm: a2 += t5
# asm 1: add  <t5=int64#3,<a2=int64#4
# asm 2: add  <t5=%rdx,<a2=%rcx
add  %rdx,%rcx

# qhasm: t6 = stack_FVGS6[1]
# asm 1: movq <stack_FVGS6=stack256#7,>t6=int64#3
# asm 2: movq <stack_FVGS6=328(%rsp),>t6=%rdx
movq 328(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod6[0]
# asm 1: andq <stack_mod6=stack256#26,<h=int64#5
# asm 2: andq <stack_mod6=928(%rsp),<h=%r8
andq 928(%rsp),%r8

# qhasm: t6 += h
# asm 1: add  <h=int64#5,<t6=int64#3
# asm 2: add  <h=%r8,<t6=%rdx
add  %r8,%rdx

# qhasm: a3 = t6
# asm 1: mov  <t6=int64#3,>a3=int64#5
# asm 2: mov  <t6=%rdx,>a3=%r8
mov  %rdx,%r8

# qhasm: t6 <<= 52
# asm 1: shl  $52,<t6=int64#3
# asm 2: shl  $52,<t6=%rdx
shl  $52,%rdx

# qhasm: (int64) a3 >>= 12
# asm 1: sar  $12,<a3=int64#5
# asm 2: sar  $12,<a3=%r8
sar  $12,%r8

# qhasm: carry? a2 += t6
# asm 1: add  <t6=int64#3,<a2=int64#4
# asm 2: add  <t6=%rdx,<a2=%rcx
add  %rdx,%rcx

# qhasm: a3 += 0 + carry
# asm 1: adc $0,<a3=int64#5
# asm 2: adc $0,<a3=%r8
adc $0,%r8

# qhasm: mem64[table + 16] = a2
# asm 1: movq   <a2=int64#4,16(<table=int64#2)
# asm 2: movq   <a2=%rcx,16(<table=%rsi)
movq   %rcx,16(%rsi)

# qhasm: t7 = stack_FVGS7[1]
# asm 1: movq <stack_FVGS7=stack256#8,>t7=int64#3
# asm 2: movq <stack_FVGS7=360(%rsp),>t7=%rdx
movq 360(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod7[0]
# asm 1: andq <stack_mod7=stack256#27,<h=int64#4
# asm 2: andq <stack_mod7=960(%rsp),<h=%rcx
andq 960(%rsp),%rcx

# qhasm: t7 += h
# asm 1: add  <h=int64#4,<t7=int64#3
# asm 2: add  <h=%rcx,<t7=%rdx
add  %rcx,%rdx

# qhasm: t7 <<= 18
# asm 1: shl  $18,<t7=int64#3
# asm 2: shl  $18,<t7=%rdx
shl  $18,%rdx

# qhasm: a3 += t7
# asm 1: add  <t7=int64#3,<a3=int64#5
# asm 2: add  <t7=%rdx,<a3=%r8
add  %rdx,%r8

# qhasm: t8 = stack_FVGS8[1]
# asm 1: movq <stack_FVGS8=stack256#9,>t8=int64#3
# asm 2: movq <stack_FVGS8=392(%rsp),>t8=%rdx
movq 392(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod8[0]
# asm 1: andq <stack_mod8=stack256#28,<h=int64#4
# asm 2: andq <stack_mod8=992(%rsp),<h=%rcx
andq 992(%rsp),%rcx

# qhasm: t8 += h
# asm 1: add  <h=int64#4,<t8=int64#3
# asm 2: add  <h=%rcx,<t8=%rdx
add  %rcx,%rdx

# qhasm: a4 = t8
# asm 1: mov  <t8=int64#3,>a4=int64#4
# asm 2: mov  <t8=%rdx,>a4=%rcx
mov  %rdx,%rcx

# qhasm: t8 <<= 48
# asm 1: shl  $48,<t8=int64#3
# asm 2: shl  $48,<t8=%rdx
shl  $48,%rdx

# qhasm: (int64) a4 >>= 16
# asm 1: sar  $16,<a4=int64#4
# asm 2: sar  $16,<a4=%rcx
sar  $16,%rcx

# qhasm: carry? a3 += t8
# asm 1: add  <t8=int64#3,<a3=int64#5
# asm 2: add  <t8=%rdx,<a3=%r8
add  %rdx,%r8

# qhasm: a4 += 0 + carry
# asm 1: adc $0,<a4=int64#4
# asm 2: adc $0,<a4=%rcx
adc $0,%rcx

# qhasm: mem64[table + 24] = a3
# asm 1: movq   <a3=int64#5,24(<table=int64#2)
# asm 2: movq   <a3=%r8,24(<table=%rsi)
movq   %r8,24(%rsi)

# qhasm: t9 = stack_FVGS9[1]
# asm 1: movq <stack_FVGS9=stack256#10,>t9=int64#3
# asm 2: movq <stack_FVGS9=424(%rsp),>t9=%rdx
movq 424(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod9[0]
# asm 1: andq <stack_mod9=stack256#29,<h=int64#5
# asm 2: andq <stack_mod9=1024(%rsp),<h=%r8
andq 1024(%rsp),%r8

# qhasm: t9 += h
# asm 1: add  <h=int64#5,<t9=int64#3
# asm 2: add  <h=%r8,<t9=%rdx
add  %r8,%rdx

# qhasm: t9 <<= 14
# asm 1: shl  $14,<t9=int64#3
# asm 2: shl  $14,<t9=%rdx
shl  $14,%rdx

# qhasm: a4 += t9
# asm 1: add  <t9=int64#3,<a4=int64#4
# asm 2: add  <t9=%rdx,<a4=%rcx
add  %rdx,%rcx

# qhasm: t10 = stack_FVGS10[1]
# asm 1: movq <stack_FVGS10=stack256#11,>t10=int64#3
# asm 2: movq <stack_FVGS10=456(%rsp),>t10=%rdx
movq 456(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod10[0]
# asm 1: andq <stack_mod10=stack256#30,<h=int64#5
# asm 2: andq <stack_mod10=1056(%rsp),<h=%r8
andq 1056(%rsp),%r8

# qhasm: t10 += h
# asm 1: add  <h=int64#5,<t10=int64#3
# asm 2: add  <h=%r8,<t10=%rdx
add  %r8,%rdx

# qhasm: a5 = t10
# asm 1: mov  <t10=int64#3,>a5=int64#5
# asm 2: mov  <t10=%rdx,>a5=%r8
mov  %rdx,%r8

# qhasm: t10 <<= 44
# asm 1: shl  $44,<t10=int64#3
# asm 2: shl  $44,<t10=%rdx
shl  $44,%rdx

# qhasm: (int64) a5 >>= 20
# asm 1: sar  $20,<a5=int64#5
# asm 2: sar  $20,<a5=%r8
sar  $20,%r8

# qhasm: carry? a4 += t10
# asm 1: add  <t10=int64#3,<a4=int64#4
# asm 2: add  <t10=%rdx,<a4=%rcx
add  %rdx,%rcx

# qhasm: a5 += 0 + carry
# asm 1: adc $0,<a5=int64#5
# asm 2: adc $0,<a5=%r8
adc $0,%r8

# qhasm: mem64[table + 32] = a4
# asm 1: movq   <a4=int64#4,32(<table=int64#2)
# asm 2: movq   <a4=%rcx,32(<table=%rsi)
movq   %rcx,32(%rsi)

# qhasm: t11 = stack_FVGS11[1]
# asm 1: movq <stack_FVGS11=stack256#12,>t11=int64#3
# asm 2: movq <stack_FVGS11=488(%rsp),>t11=%rdx
movq 488(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod11[0]
# asm 1: andq <stack_mod11=stack256#31,<h=int64#4
# asm 2: andq <stack_mod11=1088(%rsp),<h=%rcx
andq 1088(%rsp),%rcx

# qhasm: t11 += h
# asm 1: add  <h=int64#4,<t11=int64#3
# asm 2: add  <h=%rcx,<t11=%rdx
add  %rcx,%rdx

# qhasm: t11 <<= 10
# asm 1: shl  $10,<t11=int64#3
# asm 2: shl  $10,<t11=%rdx
shl  $10,%rdx

# qhasm: a5 += t11
# asm 1: add  <t11=int64#3,<a5=int64#5
# asm 2: add  <t11=%rdx,<a5=%r8
add  %rdx,%r8

# qhasm: t12 = stack_FVGS12[1]
# asm 1: movq <stack_FVGS12=stack256#13,>t12=int64#3
# asm 2: movq <stack_FVGS12=520(%rsp),>t12=%rdx
movq 520(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod12[0]
# asm 1: andq <stack_mod12=stack256#32,<h=int64#4
# asm 2: andq <stack_mod12=1120(%rsp),<h=%rcx
andq 1120(%rsp),%rcx

# qhasm: t12 += h
# asm 1: add  <h=int64#4,<t12=int64#3
# asm 2: add  <h=%rcx,<t12=%rdx
add  %rcx,%rdx

# qhasm: a6 = t12
# asm 1: mov  <t12=int64#3,>a6=int64#4
# asm 2: mov  <t12=%rdx,>a6=%rcx
mov  %rdx,%rcx

# qhasm: t12 <<= 40
# asm 1: shl  $40,<t12=int64#3
# asm 2: shl  $40,<t12=%rdx
shl  $40,%rdx

# qhasm: (int64) a6 >>= 24
# asm 1: sar  $24,<a6=int64#4
# asm 2: sar  $24,<a6=%rcx
sar  $24,%rcx

# qhasm: carry? a5 += t12
# asm 1: add  <t12=int64#3,<a5=int64#5
# asm 2: add  <t12=%rdx,<a5=%r8
add  %rdx,%r8

# qhasm: a6 += 0 + carry
# asm 1: adc $0,<a6=int64#4
# asm 2: adc $0,<a6=%rcx
adc $0,%rcx

# qhasm: mem64[table + 40] = a5
# asm 1: movq   <a5=int64#5,40(<table=int64#2)
# asm 2: movq   <a5=%r8,40(<table=%rsi)
movq   %r8,40(%rsi)

# qhasm: t13 = stack_FVGS13[1]
# asm 1: movq <stack_FVGS13=stack256#14,>t13=int64#3
# asm 2: movq <stack_FVGS13=552(%rsp),>t13=%rdx
movq 552(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod13[0]
# asm 1: andq <stack_mod13=stack256#33,<h=int64#5
# asm 2: andq <stack_mod13=1152(%rsp),<h=%r8
andq 1152(%rsp),%r8

# qhasm: t13 += h
# asm 1: add  <h=int64#5,<t13=int64#3
# asm 2: add  <h=%r8,<t13=%rdx
add  %r8,%rdx

# qhasm: t13 <<= 6
# asm 1: shl  $6,<t13=int64#3
# asm 2: shl  $6,<t13=%rdx
shl  $6,%rdx

# qhasm: a6 += t13
# asm 1: add  <t13=int64#3,<a6=int64#4
# asm 2: add  <t13=%rdx,<a6=%rcx
add  %rdx,%rcx

# qhasm: t14 = stack_FVGS14[1]
# asm 1: movq <stack_FVGS14=stack256#15,>t14=int64#3
# asm 2: movq <stack_FVGS14=584(%rsp),>t14=%rdx
movq 584(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod14[0]
# asm 1: andq <stack_mod14=stack256#34,<h=int64#5
# asm 2: andq <stack_mod14=1184(%rsp),<h=%r8
andq 1184(%rsp),%r8

# qhasm: t14 += h
# asm 1: add  <h=int64#5,<t14=int64#3
# asm 2: add  <h=%r8,<t14=%rdx
add  %r8,%rdx

# qhasm: a7 = t14
# asm 1: mov  <t14=int64#3,>a7=int64#5
# asm 2: mov  <t14=%rdx,>a7=%r8
mov  %rdx,%r8

# qhasm: t14 <<= 36
# asm 1: shl  $36,<t14=int64#3
# asm 2: shl  $36,<t14=%rdx
shl  $36,%rdx

# qhasm: (int64) a7 >>= 28
# asm 1: sar  $28,<a7=int64#5
# asm 2: sar  $28,<a7=%r8
sar  $28,%r8

# qhasm: carry? a6 += t14
# asm 1: add  <t14=int64#3,<a6=int64#4
# asm 2: add  <t14=%rdx,<a6=%rcx
add  %rdx,%rcx

# qhasm: a7 += 0 + carry
# asm 1: adc $0,<a7=int64#5
# asm 2: adc $0,<a7=%r8
adc $0,%r8

# qhasm: mem64[table + 48] = a6
# asm 1: movq   <a6=int64#4,48(<table=int64#2)
# asm 2: movq   <a6=%rcx,48(<table=%rsi)
movq   %rcx,48(%rsi)

# qhasm: t15 = stack_FVGS15[1]
# asm 1: movq <stack_FVGS15=stack256#16,>t15=int64#3
# asm 2: movq <stack_FVGS15=616(%rsp),>t15=%rdx
movq 616(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod15[0]
# asm 1: andq <stack_mod15=stack256#35,<h=int64#4
# asm 2: andq <stack_mod15=1216(%rsp),<h=%rcx
andq 1216(%rsp),%rcx

# qhasm: t15 += h
# asm 1: add  <h=int64#4,<t15=int64#3
# asm 2: add  <h=%rcx,<t15=%rdx
add  %rcx,%rdx

# qhasm: t15 <<= 2
# asm 1: shl  $2,<t15=int64#3
# asm 2: shl  $2,<t15=%rdx
shl  $2,%rdx

# qhasm: a7 += t15
# asm 1: add  <t15=int64#3,<a7=int64#5
# asm 2: add  <t15=%rdx,<a7=%r8
add  %rdx,%r8

# qhasm: t16 = stack_FVGS16[1]
# asm 1: movq <stack_FVGS16=stack256#18,>t16=int64#3
# asm 2: movq <stack_FVGS16=680(%rsp),>t16=%rdx
movq 680(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod16[0]
# asm 1: andq <stack_mod16=stack256#36,<h=int64#4
# asm 2: andq <stack_mod16=1248(%rsp),<h=%rcx
andq 1248(%rsp),%rcx

# qhasm: t16 += h
# asm 1: add  <h=int64#4,<t16=int64#3
# asm 2: add  <h=%rcx,<t16=%rdx
add  %rcx,%rdx

# qhasm: t16 <<= 32
# asm 1: shl  $32,<t16=int64#3
# asm 2: shl  $32,<t16=%rdx
shl  $32,%rdx

# qhasm: a7 += t16
# asm 1: add  <t16=int64#3,<a7=int64#5
# asm 2: add  <t16=%rdx,<a7=%r8
add  %rdx,%r8

# qhasm: t17 = stack_FVGS17[1]
# asm 1: movq <stack_FVGS17=stack256#17,>t17=int64#3
# asm 2: movq <stack_FVGS17=648(%rsp),>t17=%rdx
movq 648(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#1
# asm 2: mov  <z=%rdi,>h=%rdi
mov  %rdi,%rdi

# qhasm: h &= stack_mod17[0]
# asm 1: andq <stack_mod17=stack256#37,<h=int64#1
# asm 2: andq <stack_mod17=1280(%rsp),<h=%rdi
andq 1280(%rsp),%rdi

# qhasm: t17 += h
# asm 1: add  <h=int64#1,<t17=int64#3
# asm 2: add  <h=%rdi,<t17=%rdx
add  %rdi,%rdx

# qhasm: t17 <<= 62
# asm 1: shl  $62,<t17=int64#3
# asm 2: shl  $62,<t17=%rdx
shl  $62,%rdx

# qhasm: a7 += t17
# asm 1: add  <t17=int64#3,<a7=int64#5
# asm 2: add  <t17=%rdx,<a7=%r8
add  %rdx,%r8

# qhasm: mem64[table + 56] = a7
# asm 1: movq   <a7=int64#5,56(<table=int64#2)
# asm 2: movq   <a7=%r8,56(<table=%rsi)
movq   %r8,56(%rsi)

# qhasm: caller_r11 = stack_r11
# asm 1: movq <stack_r11=stack64#2,>caller_r11=int64#9
# asm 2: movq <stack_r11=8(%rsp),>caller_r11=%r11
movq 8(%rsp),%r11

# qhasm: caller_r12 = stack_r12
# asm 1: movq <stack_r12=stack64#3,>caller_r12=int64#10
# asm 2: movq <stack_r12=16(%rsp),>caller_r12=%r12
movq 16(%rsp),%r12

# qhasm: caller_r13 = stack_r13
# asm 1: movq <stack_r13=stack64#4,>caller_r13=int64#11
# asm 2: movq <stack_r13=24(%rsp),>caller_r13=%r13
movq 24(%rsp),%r13

# qhasm: caller_r14 = stack_r14
# asm 1: movq <stack_r14=stack64#5,>caller_r14=int64#12
# asm 2: movq <stack_r14=32(%rsp),>caller_r14=%r14
movq 32(%rsp),%r14

# qhasm: caller_r15 = stack_r15
# asm 1: movq <stack_r15=stack64#6,>caller_r15=int64#13
# asm 2: movq <stack_r15=40(%rsp),>caller_r15=%r15
movq 40(%rsp),%r15

# qhasm: caller_rbx = stack_rbx
# asm 1: movq <stack_rbx=stack64#7,>caller_rbx=int64#14
# asm 2: movq <stack_rbx=48(%rsp),>caller_rbx=%rbx
movq 48(%rsp),%rbx

# qhasm: caller_rbp = stack_rbp
# asm 1: movq <stack_rbp=stack64#8,>caller_rbp=int64#15
# asm 2: movq <stack_rbp=56(%rsp),>caller_rbp=%rbp
movq 56(%rsp),%rbp

# qhasm: return
add %r11,%rsp
ret

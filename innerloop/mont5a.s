
# qhasm: int64 input_0

# qhasm: int64 input_1

# qhasm: int64 input_2

# qhasm: int64 input_3

# qhasm: int64 input_4

# qhasm: int64 input_5

# qhasm: stack64 input_6

# qhasm: stack64 input_7

# qhasm: int64 caller_r11

# qhasm: int64 caller_r12

# qhasm: int64 caller_r13

# qhasm: int64 caller_r14

# qhasm: int64 caller_r15

# qhasm: int64 caller_rbx

# qhasm: int64 caller_rbp

# qhasm: int64 m

# qhasm: int64 f

# qhasm: int64 g

# qhasm: int64 u

# qhasm: int64 v

# qhasm: int64 r

# qhasm: int64 s

# qhasm: int64 uvrs

# qhasm: int64 fuv

# qhasm: int64 grs

# qhasm: int64 mnew

# qhasm: int64 z

# qhasm: int64 loop

# qhasm: int64 rax

# qhasm: int64 rdx

# qhasm: int64 h

# qhasm: int64 oldg

# qhasm: int64 i

# qhasm: int64 j

# qhasm: int64 f0

# qhasm: int64 g0

# qhasm: int64 table

# qhasm: int64 minv

# qhasm: stack64 stack_minv

# qhasm: int64 rtimesoldv

# qhasm: int64 stimesolds

# qhasm: stack64 stack_out

# qhasm: stack256 stack_m1

# qhasm: stack64 stack_m

# qhasm: stack256 stack_fxgx

# qhasm: stack256 stack_uuss

# qhasm: stack256 stack_vvrr

# qhasm: stack256 stack_fygy

# qhasm: stack64 stack_fuv

# qhasm: stack64 stack_f

# qhasm: reg256 carryy

# qhasm: reg256 minvx4

# qhasm: reg256 d0

# qhasm: reg256 d1

# qhasm: reg256 d2

# qhasm: reg256 out0

# qhasm: int64 a0

# qhasm: int64 t0

# qhasm: reg256 mod0

# qhasm: stack256 stack_mod0

# qhasm: reg256 FVGS0

# qhasm: reg256 GSFV0

# qhasm: stack256 stack_FVGS0

# qhasm: reg256 out1

# qhasm: reg256 out1plus

# qhasm: reg256 out2plus2

# qhasm: int64 a1

# qhasm: int64 t1

# qhasm: reg256 mod1

# qhasm: stack256 stack_mod1

# qhasm: reg256 FVGS1

# qhasm: reg256 GSFV1

# qhasm: stack256 stack_FVGS1

# qhasm: reg256 out2

# qhasm: reg256 out2plus

# qhasm: reg256 out3plus2

# qhasm: int64 a2

# qhasm: int64 t2

# qhasm: reg256 mod2

# qhasm: stack256 stack_mod2

# qhasm: reg256 FVGS2

# qhasm: reg256 GSFV2

# qhasm: stack256 stack_FVGS2

# qhasm: reg256 out3

# qhasm: reg256 out3plus

# qhasm: reg256 out4plus2

# qhasm: int64 a3

# qhasm: int64 t3

# qhasm: reg256 mod3

# qhasm: stack256 stack_mod3

# qhasm: reg256 FVGS3

# qhasm: reg256 GSFV3

# qhasm: stack256 stack_FVGS3

# qhasm: reg256 out4

# qhasm: reg256 out4plus

# qhasm: reg256 out5plus2

# qhasm: int64 a4

# qhasm: int64 t4

# qhasm: reg256 mod4

# qhasm: stack256 stack_mod4

# qhasm: reg256 FVGS4

# qhasm: reg256 GSFV4

# qhasm: stack256 stack_FVGS4

# qhasm: reg256 out5

# qhasm: reg256 out5plus

# qhasm: reg256 out6plus2

# qhasm: int64 a5

# qhasm: int64 t5

# qhasm: reg256 mod5

# qhasm: stack256 stack_mod5

# qhasm: reg256 FVGS5

# qhasm: reg256 GSFV5

# qhasm: stack256 stack_FVGS5

# qhasm: reg256 out6

# qhasm: reg256 out6plus

# qhasm: reg256 out7plus2

# qhasm: int64 a6

# qhasm: int64 t6

# qhasm: reg256 mod6

# qhasm: stack256 stack_mod6

# qhasm: reg256 FVGS6

# qhasm: reg256 GSFV6

# qhasm: stack256 stack_FVGS6

# qhasm: reg256 out7

# qhasm: reg256 out7plus

# qhasm: reg256 out8plus2

# qhasm: int64 a7

# qhasm: int64 t7

# qhasm: reg256 mod7

# qhasm: stack256 stack_mod7

# qhasm: reg256 FVGS7

# qhasm: reg256 GSFV7

# qhasm: stack256 stack_FVGS7

# qhasm: reg256 out8

# qhasm: reg256 out8plus

# qhasm: reg256 out9plus2

# qhasm: int64 a8

# qhasm: int64 t8

# qhasm: reg256 mod8

# qhasm: stack256 stack_mod8

# qhasm: reg256 FVGS8

# qhasm: reg256 GSFV8

# qhasm: stack256 stack_FVGS8

# qhasm: reg256 out9

# qhasm: reg256 out9plus

# qhasm: reg256 out10plus2

# qhasm: int64 a9

# qhasm: int64 t9

# qhasm: reg256 mod9

# qhasm: stack256 stack_mod9

# qhasm: reg256 FVGS9

# qhasm: reg256 GSFV9

# qhasm: stack256 stack_FVGS9

# qhasm: reg256 out10

# qhasm: reg256 out10plus

# qhasm: reg256 out11plus2

# qhasm: int64 a10

# qhasm: int64 t10

# qhasm: reg256 mod10

# qhasm: stack256 stack_mod10

# qhasm: reg256 FVGS10

# qhasm: reg256 GSFV10

# qhasm: stack256 stack_FVGS10

# qhasm: reg256 out11

# qhasm: reg256 out11plus

# qhasm: reg256 out12plus2

# qhasm: int64 a11

# qhasm: int64 t11

# qhasm: reg256 mod11

# qhasm: stack256 stack_mod11

# qhasm: reg256 FVGS11

# qhasm: reg256 GSFV11

# qhasm: stack256 stack_FVGS11

# qhasm: reg256 out12

# qhasm: reg256 out12plus

# qhasm: reg256 out13plus2

# qhasm: int64 a12

# qhasm: int64 t12

# qhasm: reg256 mod12

# qhasm: stack256 stack_mod12

# qhasm: reg256 FVGS12

# qhasm: reg256 GSFV12

# qhasm: stack256 stack_FVGS12

# qhasm: reg256 out13

# qhasm: reg256 out13plus

# qhasm: reg256 out14plus2

# qhasm: int64 a13

# qhasm: int64 t13

# qhasm: reg256 mod13

# qhasm: stack256 stack_mod13

# qhasm: reg256 FVGS13

# qhasm: reg256 GSFV13

# qhasm: stack256 stack_FVGS13

# qhasm: reg256 out14

# qhasm: reg256 out14plus

# qhasm: reg256 out15plus2

# qhasm: int64 a14

# qhasm: int64 t14

# qhasm: reg256 mod14

# qhasm: stack256 stack_mod14

# qhasm: reg256 FVGS14

# qhasm: reg256 GSFV14

# qhasm: stack256 stack_FVGS14

# qhasm: reg256 out15

# qhasm: reg256 out15plus

# qhasm: reg256 out16plus2

# qhasm: int64 a15

# qhasm: int64 t15

# qhasm: reg256 mod15

# qhasm: stack256 stack_mod15

# qhasm: reg256 FVGS15

# qhasm: reg256 GSFV15

# qhasm: stack256 stack_FVGS15

# qhasm: reg256 out16

# qhasm: reg256 out16plus

# qhasm: reg256 out17plus2

# qhasm: int64 a16

# qhasm: int64 t16

# qhasm: reg256 mod16

# qhasm: stack256 stack_mod16

# qhasm: reg256 FVGS16

# qhasm: reg256 GSFV16

# qhasm: stack256 stack_FVGS16

# qhasm: reg256 out17

# qhasm: reg256 out17plus

# qhasm: reg256 out18plus2

# qhasm: int64 a17

# qhasm: int64 t17

# qhasm: reg256 mod17

# qhasm: stack256 stack_mod17

# qhasm: reg256 FVGS17

# qhasm: reg256 GSFV17

# qhasm: stack256 stack_FVGS17

# qhasm: reg256 out18

# qhasm: reg256 out18plus

# qhasm: reg256 out19plus2

# qhasm: int64 a18

# qhasm: int64 t18

# qhasm: reg256 mod18

# qhasm: stack256 stack_mod18

# qhasm: reg256 FVGS18

# qhasm: reg256 GSFV18

# qhasm: stack256 stack_FVGS18

# qhasm: reg256 out19

# qhasm: reg256 out19plus

# qhasm: reg256 out20plus2

# qhasm: int64 a19

# qhasm: int64 t19

# qhasm: reg256 mod19

# qhasm: stack256 stack_mod19

# qhasm: reg256 FVGS19

# qhasm: reg256 GSFV19

# qhasm: stack256 stack_FVGS19

# qhasm: reg256 out20

# qhasm: reg256 out20plus

# qhasm: reg256 out21plus2

# qhasm: int64 a20

# qhasm: int64 t20

# qhasm: reg256 mod20

# qhasm: stack256 stack_mod20

# qhasm: reg256 FVGS20

# qhasm: reg256 GSFV20

# qhasm: stack256 stack_FVGS20

# qhasm: reg256 out21

# qhasm: reg256 out21plus

# qhasm: reg256 out22plus2

# qhasm: int64 a21

# qhasm: int64 t21

# qhasm: reg256 mod21

# qhasm: stack256 stack_mod21

# qhasm: reg256 FVGS21

# qhasm: reg256 GSFV21

# qhasm: stack256 stack_FVGS21

# qhasm: reg256 out22

# qhasm: reg256 out22plus

# qhasm: reg256 out23plus2

# qhasm: int64 a22

# qhasm: int64 t22

# qhasm: reg256 mod22

# qhasm: stack256 stack_mod22

# qhasm: reg256 FVGS22

# qhasm: reg256 GSFV22

# qhasm: stack256 stack_FVGS22

# qhasm: reg256 out23

# qhasm: reg256 out23plus

# qhasm: reg256 out24plus2

# qhasm: int64 a23

# qhasm: int64 t23

# qhasm: reg256 mod23

# qhasm: stack256 stack_mod23

# qhasm: reg256 FVGS23

# qhasm: reg256 GSFV23

# qhasm: stack256 stack_FVGS23

# qhasm: reg256 out24

# qhasm: reg256 out24plus

# qhasm: reg256 out25plus2

# qhasm: int64 a24

# qhasm: int64 t24

# qhasm: reg256 mod24

# qhasm: stack256 stack_mod24

# qhasm: reg256 FVGS24

# qhasm: reg256 GSFV24

# qhasm: stack256 stack_FVGS24

# qhasm: reg256 out25

# qhasm: reg256 out25plus

# qhasm: reg256 out26plus2

# qhasm: int64 a25

# qhasm: int64 t25

# qhasm: reg256 mod25

# qhasm: stack256 stack_mod25

# qhasm: reg256 FVGS25

# qhasm: reg256 GSFV25

# qhasm: stack256 stack_FVGS25

# qhasm: reg256 out26

# qhasm: reg256 out26plus

# qhasm: reg256 out27plus2

# qhasm: int64 a26

# qhasm: int64 t26

# qhasm: reg256 mod26

# qhasm: stack256 stack_mod26

# qhasm: reg256 FVGS26

# qhasm: reg256 GSFV26

# qhasm: stack256 stack_FVGS26

# qhasm: reg256 out27

# qhasm: reg256 out27plus

# qhasm: reg256 out28plus2

# qhasm: int64 a27

# qhasm: int64 t27

# qhasm: reg256 mod27

# qhasm: stack256 stack_mod27

# qhasm: reg256 FVGS27

# qhasm: reg256 GSFV27

# qhasm: stack256 stack_FVGS27

# qhasm: reg256 out28

# qhasm: reg256 out28plus

# qhasm: reg256 out29plus2

# qhasm: int64 a28

# qhasm: int64 t28

# qhasm: reg256 mod28

# qhasm: stack256 stack_mod28

# qhasm: reg256 FVGS28

# qhasm: reg256 GSFV28

# qhasm: stack256 stack_FVGS28

# qhasm: reg256 out29

# qhasm: reg256 out29plus

# qhasm: reg256 out30plus2

# qhasm: int64 a29

# qhasm: int64 t29

# qhasm: reg256 mod29

# qhasm: stack256 stack_mod29

# qhasm: reg256 FVGS29

# qhasm: reg256 GSFV29

# qhasm: stack256 stack_FVGS29

# qhasm: reg256 out30

# qhasm: reg256 out30plus

# qhasm: reg256 out31plus2

# qhasm: int64 a30

# qhasm: int64 t30

# qhasm: reg256 mod30

# qhasm: stack256 stack_mod30

# qhasm: reg256 FVGS30

# qhasm: reg256 GSFV30

# qhasm: stack256 stack_FVGS30

# qhasm: reg256 out31

# qhasm: reg256 out31plus

# qhasm: reg256 out32plus2

# qhasm: int64 a31

# qhasm: int64 t31

# qhasm: reg256 mod31

# qhasm: stack256 stack_mod31

# qhasm: reg256 FVGS31

# qhasm: reg256 GSFV31

# qhasm: stack256 stack_FVGS31

# qhasm: reg256 out32

# qhasm: reg256 out32plus

# qhasm: reg256 out33plus2

# qhasm: int64 a32

# qhasm: int64 t32

# qhasm: reg256 mod32

# qhasm: stack256 stack_mod32

# qhasm: reg256 FVGS32

# qhasm: reg256 GSFV32

# qhasm: stack256 stack_FVGS32

# qhasm: reg256 out33

# qhasm: reg256 out33plus

# qhasm: reg256 out34plus2

# qhasm: int64 a33

# qhasm: int64 t33

# qhasm: reg256 mod33

# qhasm: stack256 stack_mod33

# qhasm: reg256 FVGS33

# qhasm: reg256 GSFV33

# qhasm: stack256 stack_FVGS33

# qhasm: reg256 out34

# qhasm: reg256 out34plus

# qhasm: int64 a34

# qhasm: int64 t34

# qhasm: reg256 mod34

# qhasm: stack256 stack_mod34

# qhasm: reg256 FVGS34

# qhasm: reg256 GSFV34

# qhasm: stack256 stack_FVGS34

# qhasm: reg256 out35

# qhasm: reg256 out35plus

# qhasm: int64 t35

# qhasm: reg256 out36

# qhasm: reg256 out36plus

# qhasm: reg256 out37

# qhasm: reg256 ta

# qhasm: reg256 tb

# qhasm: reg256 uuss

# qhasm: reg256 uuss0

# qhasm: reg256 uuss1

# qhasm: reg256 vvrr

# qhasm: reg256 vvrr0

# qhasm: reg256 vvrr1

# qhasm: int64            _m2p20

# qhasm: stack64     stack_m2p20

# qhasm: int64             _2p20

# qhasm: stack64      stack_2p20

# qhasm: int64            _m2p41

# qhasm: stack64     stack_m2p41

# qhasm: int64            _m2p62

# qhasm: stack64     stack_m2p62

# qhasm: int64        _2p20a2p41

# qhasm: stack64 stack_2p20a2p41

# qhasm: reg256 _2p30m1x4

# qhasm: reg256 _2p33x4

# qhasm: reg256 _2p63x4

# qhasm: reg256 _2p63m2p33x4

# qhasm: reg256 _2p29x4

# qhasm: reg256 _prime0x4

# qhasm: reg256 _prime1x4

# qhasm: reg256 _prime2x4

# qhasm: reg256 _prime3x4

# qhasm: stack256 stack_2p30m1x4

# qhasm: stack256 stack_2p33x4

# qhasm: stack256 stack_2p63x4

# qhasm: stack256 stack_2p63m2p33x4

# qhasm: stack256 stack_2p29x4

# qhasm: stack256 stack_prime0x4

# qhasm: stack256 stack_prime1x4

# qhasm: stack256 stack_prime2x4

# qhasm: stack256 stack_prime3x4

# qhasm: enter inverse_1024
.p2align 5
.global _inverse_1024
.global inverse_1024
_inverse_1024:
inverse_1024:
mov %rsp,%r11
and $31,%r11
add $2656,%r11
sub %r11,%rsp

# qhasm: new stack_m1

# qhasm: stack_out = input_1
# asm 1: movq <input_1=int64#2,>stack_out=stack64#1
# asm 2: movq <input_1=%rsi,>stack_out=0(%rsp)
movq %rsi,0(%rsp)

# qhasm: table = input_2
# asm 1: mov  <input_2=int64#3,>table=int64#2
# asm 2: mov  <input_2=%rdx,>table=%rsi
mov  %rdx,%rsi

# qhasm: stack64 stack_r11

# qhasm: stack_r11 = caller_r11
# asm 1: movq <caller_r11=int64#9,>stack_r11=stack64#2
# asm 2: movq <caller_r11=%r11,>stack_r11=8(%rsp)
movq %r11,8(%rsp)

# qhasm: stack64 stack_r12

# qhasm: stack_r12 = caller_r12
# asm 1: movq <caller_r12=int64#10,>stack_r12=stack64#3
# asm 2: movq <caller_r12=%r12,>stack_r12=16(%rsp)
movq %r12,16(%rsp)

# qhasm: stack64 stack_r13

# qhasm: stack_r13 = caller_r13
# asm 1: movq <caller_r13=int64#11,>stack_r13=stack64#4
# asm 2: movq <caller_r13=%r13,>stack_r13=24(%rsp)
movq %r13,24(%rsp)

# qhasm: stack64 stack_r14

# qhasm: stack_r14 = caller_r14
# asm 1: movq <caller_r14=int64#12,>stack_r14=stack64#5
# asm 2: movq <caller_r14=%r14,>stack_r14=32(%rsp)
movq %r14,32(%rsp)

# qhasm: stack64 stack_r15

# qhasm: stack_r15 = caller_r15
# asm 1: movq <caller_r15=int64#13,>stack_r15=stack64#6
# asm 2: movq <caller_r15=%r15,>stack_r15=40(%rsp)
movq %r15,40(%rsp)

# qhasm: stack64 stack_rbx

# qhasm: stack_rbx = caller_rbx
# asm 1: movq <caller_rbx=int64#14,>stack_rbx=stack64#7
# asm 2: movq <caller_rbx=%rbx,>stack_rbx=48(%rsp)
movq %rbx,48(%rsp)

# qhasm: stack64 stack_rbp

# qhasm: stack_rbp = caller_rbp
# asm 1: movq <caller_rbp=int64#15,>stack_rbp=stack64#8
# asm 2: movq <caller_rbp=%rbp,>stack_rbp=56(%rsp)
movq %rbp,56(%rsp)

# qhasm: d1 = mem256[ table + 288 ]
# asm 1: vmovupd   288(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   288(<table=%rsi),>d1=%ymm0
vmovupd   288(%rsi),%ymm0

# qhasm: stack_FVGS0 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS0=stack256#2
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS0=160(%rsp)
vmovapd %ymm0,160(%rsp)

# qhasm: d1 = mem256[ table + 320 ]
# asm 1: vmovupd   320(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   320(<table=%rsi),>d1=%ymm0
vmovupd   320(%rsi),%ymm0

# qhasm: stack_FVGS1 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS1=stack256#3
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS1=192(%rsp)
vmovapd %ymm0,192(%rsp)

# qhasm: d1 = mem256[ table + 352 ]
# asm 1: vmovupd   352(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   352(<table=%rsi),>d1=%ymm0
vmovupd   352(%rsi),%ymm0

# qhasm: stack_FVGS2 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS2=stack256#4
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS2=224(%rsp)
vmovapd %ymm0,224(%rsp)

# qhasm: d1 = mem256[ table + 384 ]
# asm 1: vmovupd   384(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   384(<table=%rsi),>d1=%ymm0
vmovupd   384(%rsi),%ymm0

# qhasm: stack_FVGS3 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS3=stack256#5
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS3=256(%rsp)
vmovapd %ymm0,256(%rsp)

# qhasm: d1 = mem256[ table + 416 ]
# asm 1: vmovupd   416(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   416(<table=%rsi),>d1=%ymm0
vmovupd   416(%rsi),%ymm0

# qhasm: stack_FVGS4 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS4=stack256#6
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS4=288(%rsp)
vmovapd %ymm0,288(%rsp)

# qhasm: d1 = mem256[ table + 448 ]
# asm 1: vmovupd   448(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   448(<table=%rsi),>d1=%ymm0
vmovupd   448(%rsi),%ymm0

# qhasm: stack_FVGS5 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS5=stack256#7
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS5=320(%rsp)
vmovapd %ymm0,320(%rsp)

# qhasm: d1 = mem256[ table + 480 ]
# asm 1: vmovupd   480(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   480(<table=%rsi),>d1=%ymm0
vmovupd   480(%rsi),%ymm0

# qhasm: stack_FVGS6 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS6=stack256#8
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS6=352(%rsp)
vmovapd %ymm0,352(%rsp)

# qhasm: d1 = mem256[ table + 512 ]
# asm 1: vmovupd   512(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   512(<table=%rsi),>d1=%ymm0
vmovupd   512(%rsi),%ymm0

# qhasm: stack_FVGS7 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS7=stack256#9
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS7=384(%rsp)
vmovapd %ymm0,384(%rsp)

# qhasm: d1 = mem256[ table + 544 ]
# asm 1: vmovupd   544(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   544(<table=%rsi),>d1=%ymm0
vmovupd   544(%rsi),%ymm0

# qhasm: stack_FVGS8 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS8=stack256#10
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS8=416(%rsp)
vmovapd %ymm0,416(%rsp)

# qhasm: d1 = mem256[ table + 576 ]
# asm 1: vmovupd   576(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   576(<table=%rsi),>d1=%ymm0
vmovupd   576(%rsi),%ymm0

# qhasm: stack_FVGS9 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS9=stack256#11
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS9=448(%rsp)
vmovapd %ymm0,448(%rsp)

# qhasm: d1 = mem256[ table + 608 ]
# asm 1: vmovupd   608(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   608(<table=%rsi),>d1=%ymm0
vmovupd   608(%rsi),%ymm0

# qhasm: stack_FVGS10 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS10=stack256#12
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS10=480(%rsp)
vmovapd %ymm0,480(%rsp)

# qhasm: d1 = mem256[ table + 640 ]
# asm 1: vmovupd   640(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   640(<table=%rsi),>d1=%ymm0
vmovupd   640(%rsi),%ymm0

# qhasm: stack_FVGS11 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS11=stack256#13
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS11=512(%rsp)
vmovapd %ymm0,512(%rsp)

# qhasm: d1 = mem256[ table + 672 ]
# asm 1: vmovupd   672(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   672(<table=%rsi),>d1=%ymm0
vmovupd   672(%rsi),%ymm0

# qhasm: stack_FVGS12 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS12=stack256#14
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS12=544(%rsp)
vmovapd %ymm0,544(%rsp)

# qhasm: d1 = mem256[ table + 704 ]
# asm 1: vmovupd   704(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   704(<table=%rsi),>d1=%ymm0
vmovupd   704(%rsi),%ymm0

# qhasm: stack_FVGS13 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS13=stack256#15
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS13=576(%rsp)
vmovapd %ymm0,576(%rsp)

# qhasm: d1 = mem256[ table + 736 ]
# asm 1: vmovupd   736(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   736(<table=%rsi),>d1=%ymm0
vmovupd   736(%rsi),%ymm0

# qhasm: stack_FVGS14 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS14=stack256#16
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS14=608(%rsp)
vmovapd %ymm0,608(%rsp)

# qhasm: d1 = mem256[ table + 768 ]
# asm 1: vmovupd   768(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   768(<table=%rsi),>d1=%ymm0
vmovupd   768(%rsi),%ymm0

# qhasm: stack_FVGS15 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS15=stack256#17
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS15=640(%rsp)
vmovapd %ymm0,640(%rsp)

# qhasm: d1 = mem256[ table + 800 ]
# asm 1: vmovupd   800(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   800(<table=%rsi),>d1=%ymm0
vmovupd   800(%rsi),%ymm0

# qhasm: stack_FVGS16 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS16=stack256#18
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS16=672(%rsp)
vmovapd %ymm0,672(%rsp)

# qhasm: d1 = mem256[ table + 832 ]
# asm 1: vmovupd   832(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   832(<table=%rsi),>d1=%ymm0
vmovupd   832(%rsi),%ymm0

# qhasm: stack_FVGS17 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS17=stack256#19
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS17=704(%rsp)
vmovapd %ymm0,704(%rsp)

# qhasm: d1 = mem256[ table + 864 ]
# asm 1: vmovupd   864(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   864(<table=%rsi),>d1=%ymm0
vmovupd   864(%rsi),%ymm0

# qhasm: stack_FVGS18 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS18=stack256#20
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS18=736(%rsp)
vmovapd %ymm0,736(%rsp)

# qhasm: d1 = mem256[ table + 896 ]
# asm 1: vmovupd   896(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   896(<table=%rsi),>d1=%ymm0
vmovupd   896(%rsi),%ymm0

# qhasm: stack_FVGS19 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS19=stack256#21
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS19=768(%rsp)
vmovapd %ymm0,768(%rsp)

# qhasm: d1 = mem256[ table + 928 ]
# asm 1: vmovupd   928(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   928(<table=%rsi),>d1=%ymm0
vmovupd   928(%rsi),%ymm0

# qhasm: stack_FVGS20 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS20=stack256#22
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS20=800(%rsp)
vmovapd %ymm0,800(%rsp)

# qhasm: d1 = mem256[ table + 960 ]
# asm 1: vmovupd   960(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   960(<table=%rsi),>d1=%ymm0
vmovupd   960(%rsi),%ymm0

# qhasm: stack_FVGS21 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS21=stack256#23
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS21=832(%rsp)
vmovapd %ymm0,832(%rsp)

# qhasm: d1 = mem256[ table + 992 ]
# asm 1: vmovupd   992(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   992(<table=%rsi),>d1=%ymm0
vmovupd   992(%rsi),%ymm0

# qhasm: stack_FVGS22 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS22=stack256#24
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS22=864(%rsp)
vmovapd %ymm0,864(%rsp)

# qhasm: d1 = mem256[ table + 1024 ]
# asm 1: vmovupd   1024(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1024(<table=%rsi),>d1=%ymm0
vmovupd   1024(%rsi),%ymm0

# qhasm: stack_FVGS23 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS23=stack256#25
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS23=896(%rsp)
vmovapd %ymm0,896(%rsp)

# qhasm: d1 = mem256[ table + 1056 ]
# asm 1: vmovupd   1056(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1056(<table=%rsi),>d1=%ymm0
vmovupd   1056(%rsi),%ymm0

# qhasm: stack_FVGS24 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS24=stack256#26
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS24=928(%rsp)
vmovapd %ymm0,928(%rsp)

# qhasm: d1 = mem256[ table + 1088 ]
# asm 1: vmovupd   1088(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1088(<table=%rsi),>d1=%ymm0
vmovupd   1088(%rsi),%ymm0

# qhasm: stack_FVGS25 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS25=stack256#27
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS25=960(%rsp)
vmovapd %ymm0,960(%rsp)

# qhasm: d1 = mem256[ table + 1120 ]
# asm 1: vmovupd   1120(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1120(<table=%rsi),>d1=%ymm0
vmovupd   1120(%rsi),%ymm0

# qhasm: stack_FVGS26 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS26=stack256#28
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS26=992(%rsp)
vmovapd %ymm0,992(%rsp)

# qhasm: d1 = mem256[ table + 1152 ]
# asm 1: vmovupd   1152(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1152(<table=%rsi),>d1=%ymm0
vmovupd   1152(%rsi),%ymm0

# qhasm: stack_FVGS27 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS27=stack256#29
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS27=1024(%rsp)
vmovapd %ymm0,1024(%rsp)

# qhasm: d1 = mem256[ table + 1184 ]
# asm 1: vmovupd   1184(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1184(<table=%rsi),>d1=%ymm0
vmovupd   1184(%rsi),%ymm0

# qhasm: stack_FVGS28 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS28=stack256#30
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS28=1056(%rsp)
vmovapd %ymm0,1056(%rsp)

# qhasm: d1 = mem256[ table + 1216 ]
# asm 1: vmovupd   1216(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1216(<table=%rsi),>d1=%ymm0
vmovupd   1216(%rsi),%ymm0

# qhasm: stack_FVGS29 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS29=stack256#31
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS29=1088(%rsp)
vmovapd %ymm0,1088(%rsp)

# qhasm: d1 = mem256[ table + 1248 ]
# asm 1: vmovupd   1248(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1248(<table=%rsi),>d1=%ymm0
vmovupd   1248(%rsi),%ymm0

# qhasm: stack_FVGS30 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS30=stack256#32
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS30=1120(%rsp)
vmovapd %ymm0,1120(%rsp)

# qhasm: d1 = mem256[ table + 1280 ]
# asm 1: vmovupd   1280(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1280(<table=%rsi),>d1=%ymm0
vmovupd   1280(%rsi),%ymm0

# qhasm: stack_FVGS31 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS31=stack256#33
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS31=1152(%rsp)
vmovapd %ymm0,1152(%rsp)

# qhasm: d1 = mem256[ table + 1312 ]
# asm 1: vmovupd   1312(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1312(<table=%rsi),>d1=%ymm0
vmovupd   1312(%rsi),%ymm0

# qhasm: stack_FVGS32 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS32=stack256#34
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS32=1184(%rsp)
vmovapd %ymm0,1184(%rsp)

# qhasm: d1 = mem256[ table + 1344 ]
# asm 1: vmovupd   1344(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1344(<table=%rsi),>d1=%ymm0
vmovupd   1344(%rsi),%ymm0

# qhasm: stack_FVGS33 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS33=stack256#35
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS33=1216(%rsp)
vmovapd %ymm0,1216(%rsp)

# qhasm: d1 = mem256[ table + 1376 ]
# asm 1: vmovupd   1376(<table=int64#2),>d1=reg256#1
# asm 2: vmovupd   1376(<table=%rsi),>d1=%ymm0
vmovupd   1376(%rsi),%ymm0

# qhasm: stack_FVGS34 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_FVGS34=stack256#36
# asm 2: vmovapd <d1=%ymm0,>stack_FVGS34=1248(%rsp)
vmovapd %ymm0,1248(%rsp)

# qhasm: d1 = 4x stack_FVGS0[0]
# asm 1: vpbroadcastq <stack_FVGS0=stack256#2,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS0=160(%rsp),>d1=%ymm0
vpbroadcastq 160(%rsp),%ymm0

# qhasm: stack_mod0 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod0=stack256#37
# asm 2: vmovapd <d1=%ymm0,>stack_mod0=1280(%rsp)
vmovapd %ymm0,1280(%rsp)

# qhasm: d1 = 4x stack_FVGS1[0]
# asm 1: vpbroadcastq <stack_FVGS1=stack256#3,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS1=192(%rsp),>d1=%ymm0
vpbroadcastq 192(%rsp),%ymm0

# qhasm: stack_mod1 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod1=stack256#38
# asm 2: vmovapd <d1=%ymm0,>stack_mod1=1312(%rsp)
vmovapd %ymm0,1312(%rsp)

# qhasm: d1 = 4x stack_FVGS2[0]
# asm 1: vpbroadcastq <stack_FVGS2=stack256#4,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS2=224(%rsp),>d1=%ymm0
vpbroadcastq 224(%rsp),%ymm0

# qhasm: stack_mod2 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod2=stack256#39
# asm 2: vmovapd <d1=%ymm0,>stack_mod2=1344(%rsp)
vmovapd %ymm0,1344(%rsp)

# qhasm: d1 = 4x stack_FVGS3[0]
# asm 1: vpbroadcastq <stack_FVGS3=stack256#5,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS3=256(%rsp),>d1=%ymm0
vpbroadcastq 256(%rsp),%ymm0

# qhasm: stack_mod3 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod3=stack256#40
# asm 2: vmovapd <d1=%ymm0,>stack_mod3=1376(%rsp)
vmovapd %ymm0,1376(%rsp)

# qhasm: d1 = 4x stack_FVGS4[0]
# asm 1: vpbroadcastq <stack_FVGS4=stack256#6,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS4=288(%rsp),>d1=%ymm0
vpbroadcastq 288(%rsp),%ymm0

# qhasm: stack_mod4 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod4=stack256#41
# asm 2: vmovapd <d1=%ymm0,>stack_mod4=1408(%rsp)
vmovapd %ymm0,1408(%rsp)

# qhasm: d1 = 4x stack_FVGS5[0]
# asm 1: vpbroadcastq <stack_FVGS5=stack256#7,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS5=320(%rsp),>d1=%ymm0
vpbroadcastq 320(%rsp),%ymm0

# qhasm: stack_mod5 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod5=stack256#42
# asm 2: vmovapd <d1=%ymm0,>stack_mod5=1440(%rsp)
vmovapd %ymm0,1440(%rsp)

# qhasm: d1 = 4x stack_FVGS6[0]
# asm 1: vpbroadcastq <stack_FVGS6=stack256#8,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS6=352(%rsp),>d1=%ymm0
vpbroadcastq 352(%rsp),%ymm0

# qhasm: stack_mod6 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod6=stack256#43
# asm 2: vmovapd <d1=%ymm0,>stack_mod6=1472(%rsp)
vmovapd %ymm0,1472(%rsp)

# qhasm: d1 = 4x stack_FVGS7[0]
# asm 1: vpbroadcastq <stack_FVGS7=stack256#9,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS7=384(%rsp),>d1=%ymm0
vpbroadcastq 384(%rsp),%ymm0

# qhasm: stack_mod7 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod7=stack256#44
# asm 2: vmovapd <d1=%ymm0,>stack_mod7=1504(%rsp)
vmovapd %ymm0,1504(%rsp)

# qhasm: d1 = 4x stack_FVGS8[0]
# asm 1: vpbroadcastq <stack_FVGS8=stack256#10,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS8=416(%rsp),>d1=%ymm0
vpbroadcastq 416(%rsp),%ymm0

# qhasm: stack_mod8 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod8=stack256#45
# asm 2: vmovapd <d1=%ymm0,>stack_mod8=1536(%rsp)
vmovapd %ymm0,1536(%rsp)

# qhasm: d1 = 4x stack_FVGS9[0]
# asm 1: vpbroadcastq <stack_FVGS9=stack256#11,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS9=448(%rsp),>d1=%ymm0
vpbroadcastq 448(%rsp),%ymm0

# qhasm: stack_mod9 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod9=stack256#46
# asm 2: vmovapd <d1=%ymm0,>stack_mod9=1568(%rsp)
vmovapd %ymm0,1568(%rsp)

# qhasm: d1 = 4x stack_FVGS10[0]
# asm 1: vpbroadcastq <stack_FVGS10=stack256#12,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS10=480(%rsp),>d1=%ymm0
vpbroadcastq 480(%rsp),%ymm0

# qhasm: stack_mod10 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod10=stack256#47
# asm 2: vmovapd <d1=%ymm0,>stack_mod10=1600(%rsp)
vmovapd %ymm0,1600(%rsp)

# qhasm: d1 = 4x stack_FVGS11[0]
# asm 1: vpbroadcastq <stack_FVGS11=stack256#13,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS11=512(%rsp),>d1=%ymm0
vpbroadcastq 512(%rsp),%ymm0

# qhasm: stack_mod11 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod11=stack256#48
# asm 2: vmovapd <d1=%ymm0,>stack_mod11=1632(%rsp)
vmovapd %ymm0,1632(%rsp)

# qhasm: d1 = 4x stack_FVGS12[0]
# asm 1: vpbroadcastq <stack_FVGS12=stack256#14,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS12=544(%rsp),>d1=%ymm0
vpbroadcastq 544(%rsp),%ymm0

# qhasm: stack_mod12 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod12=stack256#49
# asm 2: vmovapd <d1=%ymm0,>stack_mod12=1664(%rsp)
vmovapd %ymm0,1664(%rsp)

# qhasm: d1 = 4x stack_FVGS13[0]
# asm 1: vpbroadcastq <stack_FVGS13=stack256#15,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS13=576(%rsp),>d1=%ymm0
vpbroadcastq 576(%rsp),%ymm0

# qhasm: stack_mod13 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod13=stack256#50
# asm 2: vmovapd <d1=%ymm0,>stack_mod13=1696(%rsp)
vmovapd %ymm0,1696(%rsp)

# qhasm: d1 = 4x stack_FVGS14[0]
# asm 1: vpbroadcastq <stack_FVGS14=stack256#16,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS14=608(%rsp),>d1=%ymm0
vpbroadcastq 608(%rsp),%ymm0

# qhasm: stack_mod14 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod14=stack256#51
# asm 2: vmovapd <d1=%ymm0,>stack_mod14=1728(%rsp)
vmovapd %ymm0,1728(%rsp)

# qhasm: d1 = 4x stack_FVGS15[0]
# asm 1: vpbroadcastq <stack_FVGS15=stack256#17,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS15=640(%rsp),>d1=%ymm0
vpbroadcastq 640(%rsp),%ymm0

# qhasm: stack_mod15 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod15=stack256#52
# asm 2: vmovapd <d1=%ymm0,>stack_mod15=1760(%rsp)
vmovapd %ymm0,1760(%rsp)

# qhasm: d1 = 4x stack_FVGS16[0]
# asm 1: vpbroadcastq <stack_FVGS16=stack256#18,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS16=672(%rsp),>d1=%ymm0
vpbroadcastq 672(%rsp),%ymm0

# qhasm: stack_mod16 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod16=stack256#53
# asm 2: vmovapd <d1=%ymm0,>stack_mod16=1792(%rsp)
vmovapd %ymm0,1792(%rsp)

# qhasm: d1 = 4x stack_FVGS17[0]
# asm 1: vpbroadcastq <stack_FVGS17=stack256#19,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS17=704(%rsp),>d1=%ymm0
vpbroadcastq 704(%rsp),%ymm0

# qhasm: stack_mod17 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod17=stack256#54
# asm 2: vmovapd <d1=%ymm0,>stack_mod17=1824(%rsp)
vmovapd %ymm0,1824(%rsp)

# qhasm: d1 = 4x stack_FVGS18[0]
# asm 1: vpbroadcastq <stack_FVGS18=stack256#20,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS18=736(%rsp),>d1=%ymm0
vpbroadcastq 736(%rsp),%ymm0

# qhasm: stack_mod18 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod18=stack256#55
# asm 2: vmovapd <d1=%ymm0,>stack_mod18=1856(%rsp)
vmovapd %ymm0,1856(%rsp)

# qhasm: d1 = 4x stack_FVGS19[0]
# asm 1: vpbroadcastq <stack_FVGS19=stack256#21,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS19=768(%rsp),>d1=%ymm0
vpbroadcastq 768(%rsp),%ymm0

# qhasm: stack_mod19 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod19=stack256#56
# asm 2: vmovapd <d1=%ymm0,>stack_mod19=1888(%rsp)
vmovapd %ymm0,1888(%rsp)

# qhasm: d1 = 4x stack_FVGS20[0]
# asm 1: vpbroadcastq <stack_FVGS20=stack256#22,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS20=800(%rsp),>d1=%ymm0
vpbroadcastq 800(%rsp),%ymm0

# qhasm: stack_mod20 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod20=stack256#57
# asm 2: vmovapd <d1=%ymm0,>stack_mod20=1920(%rsp)
vmovapd %ymm0,1920(%rsp)

# qhasm: d1 = 4x stack_FVGS21[0]
# asm 1: vpbroadcastq <stack_FVGS21=stack256#23,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS21=832(%rsp),>d1=%ymm0
vpbroadcastq 832(%rsp),%ymm0

# qhasm: stack_mod21 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod21=stack256#58
# asm 2: vmovapd <d1=%ymm0,>stack_mod21=1952(%rsp)
vmovapd %ymm0,1952(%rsp)

# qhasm: d1 = 4x stack_FVGS22[0]
# asm 1: vpbroadcastq <stack_FVGS22=stack256#24,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS22=864(%rsp),>d1=%ymm0
vpbroadcastq 864(%rsp),%ymm0

# qhasm: stack_mod22 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod22=stack256#59
# asm 2: vmovapd <d1=%ymm0,>stack_mod22=1984(%rsp)
vmovapd %ymm0,1984(%rsp)

# qhasm: d1 = 4x stack_FVGS23[0]
# asm 1: vpbroadcastq <stack_FVGS23=stack256#25,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS23=896(%rsp),>d1=%ymm0
vpbroadcastq 896(%rsp),%ymm0

# qhasm: stack_mod23 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod23=stack256#60
# asm 2: vmovapd <d1=%ymm0,>stack_mod23=2016(%rsp)
vmovapd %ymm0,2016(%rsp)

# qhasm: d1 = 4x stack_FVGS24[0]
# asm 1: vpbroadcastq <stack_FVGS24=stack256#26,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS24=928(%rsp),>d1=%ymm0
vpbroadcastq 928(%rsp),%ymm0

# qhasm: stack_mod24 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod24=stack256#61
# asm 2: vmovapd <d1=%ymm0,>stack_mod24=2048(%rsp)
vmovapd %ymm0,2048(%rsp)

# qhasm: d1 = 4x stack_FVGS25[0]
# asm 1: vpbroadcastq <stack_FVGS25=stack256#27,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS25=960(%rsp),>d1=%ymm0
vpbroadcastq 960(%rsp),%ymm0

# qhasm: stack_mod25 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod25=stack256#62
# asm 2: vmovapd <d1=%ymm0,>stack_mod25=2080(%rsp)
vmovapd %ymm0,2080(%rsp)

# qhasm: d1 = 4x stack_FVGS26[0]
# asm 1: vpbroadcastq <stack_FVGS26=stack256#28,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS26=992(%rsp),>d1=%ymm0
vpbroadcastq 992(%rsp),%ymm0

# qhasm: stack_mod26 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod26=stack256#63
# asm 2: vmovapd <d1=%ymm0,>stack_mod26=2112(%rsp)
vmovapd %ymm0,2112(%rsp)

# qhasm: d1 = 4x stack_FVGS27[0]
# asm 1: vpbroadcastq <stack_FVGS27=stack256#29,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS27=1024(%rsp),>d1=%ymm0
vpbroadcastq 1024(%rsp),%ymm0

# qhasm: stack_mod27 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod27=stack256#64
# asm 2: vmovapd <d1=%ymm0,>stack_mod27=2144(%rsp)
vmovapd %ymm0,2144(%rsp)

# qhasm: d1 = 4x stack_FVGS28[0]
# asm 1: vpbroadcastq <stack_FVGS28=stack256#30,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS28=1056(%rsp),>d1=%ymm0
vpbroadcastq 1056(%rsp),%ymm0

# qhasm: stack_mod28 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod28=stack256#65
# asm 2: vmovapd <d1=%ymm0,>stack_mod28=2176(%rsp)
vmovapd %ymm0,2176(%rsp)

# qhasm: d1 = 4x stack_FVGS29[0]
# asm 1: vpbroadcastq <stack_FVGS29=stack256#31,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS29=1088(%rsp),>d1=%ymm0
vpbroadcastq 1088(%rsp),%ymm0

# qhasm: stack_mod29 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod29=stack256#66
# asm 2: vmovapd <d1=%ymm0,>stack_mod29=2208(%rsp)
vmovapd %ymm0,2208(%rsp)

# qhasm: d1 = 4x stack_FVGS30[0]
# asm 1: vpbroadcastq <stack_FVGS30=stack256#32,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS30=1120(%rsp),>d1=%ymm0
vpbroadcastq 1120(%rsp),%ymm0

# qhasm: stack_mod30 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod30=stack256#67
# asm 2: vmovapd <d1=%ymm0,>stack_mod30=2240(%rsp)
vmovapd %ymm0,2240(%rsp)

# qhasm: d1 = 4x stack_FVGS31[0]
# asm 1: vpbroadcastq <stack_FVGS31=stack256#33,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS31=1152(%rsp),>d1=%ymm0
vpbroadcastq 1152(%rsp),%ymm0

# qhasm: stack_mod31 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod31=stack256#68
# asm 2: vmovapd <d1=%ymm0,>stack_mod31=2272(%rsp)
vmovapd %ymm0,2272(%rsp)

# qhasm: d1 = 4x stack_FVGS32[0]
# asm 1: vpbroadcastq <stack_FVGS32=stack256#34,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS32=1184(%rsp),>d1=%ymm0
vpbroadcastq 1184(%rsp),%ymm0

# qhasm: stack_mod32 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod32=stack256#69
# asm 2: vmovapd <d1=%ymm0,>stack_mod32=2304(%rsp)
vmovapd %ymm0,2304(%rsp)

# qhasm: d1 = 4x stack_FVGS33[0]
# asm 1: vpbroadcastq <stack_FVGS33=stack256#35,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS33=1216(%rsp),>d1=%ymm0
vpbroadcastq 1216(%rsp),%ymm0

# qhasm: stack_mod33 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod33=stack256#70
# asm 2: vmovapd <d1=%ymm0,>stack_mod33=2336(%rsp)
vmovapd %ymm0,2336(%rsp)

# qhasm: d1 = 4x stack_FVGS34[0]
# asm 1: vpbroadcastq <stack_FVGS34=stack256#36,>d1=reg256#1
# asm 2: vpbroadcastq <stack_FVGS34=1248(%rsp),>d1=%ymm0
vpbroadcastq 1248(%rsp),%ymm0

# qhasm: stack_mod34 = d1
# asm 1: vmovapd <d1=reg256#1,>stack_mod34=stack256#71
# asm 2: vmovapd <d1=%ymm0,>stack_mod34=2368(%rsp)
vmovapd %ymm0,2368(%rsp)

# qhasm: minv = mem64[ table + 1408]
# asm 1: movq   1408(<table=int64#2),>minv=int64#3
# asm 2: movq   1408(<table=%rsi),>minv=%rdx
movq   1408(%rsi),%rdx

# qhasm: stack_minv = minv
# asm 1: movq <minv=int64#3,>stack_minv=stack64#9
# asm 2: movq <minv=%rdx,>stack_minv=64(%rsp)
movq %rdx,64(%rsp)

# qhasm: a0 = mem64[input_0 +  0]
# asm 1: movq   0(<input_0=int64#1),>a0=int64#4
# asm 2: movq   0(<input_0=%rdi),>a0=%rcx
movq   0(%rdi),%rcx

# qhasm: minv *= a0
# asm 1: imul  <a0=int64#4,<minv=int64#3
# asm 2: imul  <a0=%rcx,<minv=%rdx
imul  %rcx,%rdx

# qhasm: (uint128) t1 t0 = minv * mem64[ table + 160 ]
# asm 1: mulx  160(<table=int64#2),>t0=int64#5,>t1=int64#6
# asm 2: mulx  160(<table=%rsi),>t0=%r8,>t1=%r9
mulx  160(%rsi),%r8,%r9

# qhasm: carry? t0 += a0
# asm 1: add  <a0=int64#4,<t0=int64#5
# asm 2: add  <a0=%rcx,<t0=%r8
add  %rcx,%r8

# qhasm: t1 += 0 + carry
# asm 1: adc $0,<t1=int64#6
# asm 2: adc $0,<t1=%r9
adc $0,%r9

# qhasm: a1 = mem64[input_0 +  8]
# asm 1: movq   8(<input_0=int64#1),>a1=int64#4
# asm 2: movq   8(<input_0=%rdi),>a1=%rcx
movq   8(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a1 += t1
# asm 1: add  <t1=int64#6,<a1=int64#4
# asm 2: add  <t1=%r9,<a1=%rcx
add  %r9,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t2 t1 = minv * mem64[ table + 168 ]
# asm 1: mulx  168(<table=int64#2),>t1=int64#6,>t2=int64#7
# asm 2: mulx  168(<table=%rsi),>t1=%r9,>t2=%rax
mulx  168(%rsi),%r9,%rax

# qhasm: carry? t1 += a1
# asm 1: add  <a1=int64#4,<t1=int64#6
# asm 2: add  <a1=%rcx,<t1=%r9
add  %rcx,%r9

# qhasm: t2 += h + carry
# asm 1: adc <h=int64#5,<t2=int64#7
# asm 2: adc <h=%r8,<t2=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS0[2] = t1
# asm 1: movq <t1=int64#6,<stack_FVGS0=stack256#2
# asm 2: movq <t1=%r9,<stack_FVGS0=176(%rsp)
movq %r9,176(%rsp)

# qhasm: a2 = mem64[input_0 + 16]
# asm 1: movq   16(<input_0=int64#1),>a2=int64#4
# asm 2: movq   16(<input_0=%rdi),>a2=%rcx
movq   16(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a2 += t2
# asm 1: add  <t2=int64#7,<a2=int64#4
# asm 2: add  <t2=%rax,<a2=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t3 t2 = minv * mem64[ table + 176 ]
# asm 1: mulx  176(<table=int64#2),>t2=int64#6,>t3=int64#7
# asm 2: mulx  176(<table=%rsi),>t2=%r9,>t3=%rax
mulx  176(%rsi),%r9,%rax

# qhasm: carry? t2 += a2
# asm 1: add  <a2=int64#4,<t2=int64#6
# asm 2: add  <a2=%rcx,<t2=%r9
add  %rcx,%r9

# qhasm: t3 += h + carry
# asm 1: adc <h=int64#5,<t3=int64#7
# asm 2: adc <h=%r8,<t3=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS1[2] = t2
# asm 1: movq <t2=int64#6,<stack_FVGS1=stack256#3
# asm 2: movq <t2=%r9,<stack_FVGS1=208(%rsp)
movq %r9,208(%rsp)

# qhasm: a3 = mem64[input_0 + 24]
# asm 1: movq   24(<input_0=int64#1),>a3=int64#4
# asm 2: movq   24(<input_0=%rdi),>a3=%rcx
movq   24(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a3 += t3
# asm 1: add  <t3=int64#7,<a3=int64#4
# asm 2: add  <t3=%rax,<a3=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t4 t3 = minv * mem64[ table + 184 ]
# asm 1: mulx  184(<table=int64#2),>t3=int64#6,>t4=int64#7
# asm 2: mulx  184(<table=%rsi),>t3=%r9,>t4=%rax
mulx  184(%rsi),%r9,%rax

# qhasm: carry? t3 += a3
# asm 1: add  <a3=int64#4,<t3=int64#6
# asm 2: add  <a3=%rcx,<t3=%r9
add  %rcx,%r9

# qhasm: t4 += h + carry
# asm 1: adc <h=int64#5,<t4=int64#7
# asm 2: adc <h=%r8,<t4=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS2[2] = t3
# asm 1: movq <t3=int64#6,<stack_FVGS2=stack256#4
# asm 2: movq <t3=%r9,<stack_FVGS2=240(%rsp)
movq %r9,240(%rsp)

# qhasm: a4 = mem64[input_0 + 32]
# asm 1: movq   32(<input_0=int64#1),>a4=int64#4
# asm 2: movq   32(<input_0=%rdi),>a4=%rcx
movq   32(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a4 += t4
# asm 1: add  <t4=int64#7,<a4=int64#4
# asm 2: add  <t4=%rax,<a4=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t5 t4 = minv * mem64[ table + 192 ]
# asm 1: mulx  192(<table=int64#2),>t4=int64#6,>t5=int64#7
# asm 2: mulx  192(<table=%rsi),>t4=%r9,>t5=%rax
mulx  192(%rsi),%r9,%rax

# qhasm: carry? t4 += a4
# asm 1: add  <a4=int64#4,<t4=int64#6
# asm 2: add  <a4=%rcx,<t4=%r9
add  %rcx,%r9

# qhasm: t5 += h + carry
# asm 1: adc <h=int64#5,<t5=int64#7
# asm 2: adc <h=%r8,<t5=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS3[2] = t4
# asm 1: movq <t4=int64#6,<stack_FVGS3=stack256#5
# asm 2: movq <t4=%r9,<stack_FVGS3=272(%rsp)
movq %r9,272(%rsp)

# qhasm: a5 = mem64[input_0 + 40]
# asm 1: movq   40(<input_0=int64#1),>a5=int64#4
# asm 2: movq   40(<input_0=%rdi),>a5=%rcx
movq   40(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a5 += t5
# asm 1: add  <t5=int64#7,<a5=int64#4
# asm 2: add  <t5=%rax,<a5=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t6 t5 = minv * mem64[ table + 200 ]
# asm 1: mulx  200(<table=int64#2),>t5=int64#6,>t6=int64#7
# asm 2: mulx  200(<table=%rsi),>t5=%r9,>t6=%rax
mulx  200(%rsi),%r9,%rax

# qhasm: carry? t5 += a5
# asm 1: add  <a5=int64#4,<t5=int64#6
# asm 2: add  <a5=%rcx,<t5=%r9
add  %rcx,%r9

# qhasm: t6 += h + carry
# asm 1: adc <h=int64#5,<t6=int64#7
# asm 2: adc <h=%r8,<t6=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS4[2] = t5
# asm 1: movq <t5=int64#6,<stack_FVGS4=stack256#6
# asm 2: movq <t5=%r9,<stack_FVGS4=304(%rsp)
movq %r9,304(%rsp)

# qhasm: a6 = mem64[input_0 + 48]
# asm 1: movq   48(<input_0=int64#1),>a6=int64#4
# asm 2: movq   48(<input_0=%rdi),>a6=%rcx
movq   48(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a6 += t6
# asm 1: add  <t6=int64#7,<a6=int64#4
# asm 2: add  <t6=%rax,<a6=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t7 t6 = minv * mem64[ table + 208 ]
# asm 1: mulx  208(<table=int64#2),>t6=int64#6,>t7=int64#7
# asm 2: mulx  208(<table=%rsi),>t6=%r9,>t7=%rax
mulx  208(%rsi),%r9,%rax

# qhasm: carry? t6 += a6
# asm 1: add  <a6=int64#4,<t6=int64#6
# asm 2: add  <a6=%rcx,<t6=%r9
add  %rcx,%r9

# qhasm: t7 += h + carry
# asm 1: adc <h=int64#5,<t7=int64#7
# asm 2: adc <h=%r8,<t7=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS5[2] = t6
# asm 1: movq <t6=int64#6,<stack_FVGS5=stack256#7
# asm 2: movq <t6=%r9,<stack_FVGS5=336(%rsp)
movq %r9,336(%rsp)

# qhasm: a7 = mem64[input_0 + 56]
# asm 1: movq   56(<input_0=int64#1),>a7=int64#4
# asm 2: movq   56(<input_0=%rdi),>a7=%rcx
movq   56(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a7 += t7
# asm 1: add  <t7=int64#7,<a7=int64#4
# asm 2: add  <t7=%rax,<a7=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t8 t7 = minv * mem64[ table + 216 ]
# asm 1: mulx  216(<table=int64#2),>t7=int64#6,>t8=int64#7
# asm 2: mulx  216(<table=%rsi),>t7=%r9,>t8=%rax
mulx  216(%rsi),%r9,%rax

# qhasm: carry? t7 += a7
# asm 1: add  <a7=int64#4,<t7=int64#6
# asm 2: add  <a7=%rcx,<t7=%r9
add  %rcx,%r9

# qhasm: t8 += h + carry
# asm 1: adc <h=int64#5,<t8=int64#7
# asm 2: adc <h=%r8,<t8=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS6[2] = t7
# asm 1: movq <t7=int64#6,<stack_FVGS6=stack256#8
# asm 2: movq <t7=%r9,<stack_FVGS6=368(%rsp)
movq %r9,368(%rsp)

# qhasm: a8 = mem64[input_0 + 64]
# asm 1: movq   64(<input_0=int64#1),>a8=int64#4
# asm 2: movq   64(<input_0=%rdi),>a8=%rcx
movq   64(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a8 += t8
# asm 1: add  <t8=int64#7,<a8=int64#4
# asm 2: add  <t8=%rax,<a8=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t9 t8 = minv * mem64[ table + 224 ]
# asm 1: mulx  224(<table=int64#2),>t8=int64#6,>t9=int64#7
# asm 2: mulx  224(<table=%rsi),>t8=%r9,>t9=%rax
mulx  224(%rsi),%r9,%rax

# qhasm: carry? t8 += a8
# asm 1: add  <a8=int64#4,<t8=int64#6
# asm 2: add  <a8=%rcx,<t8=%r9
add  %rcx,%r9

# qhasm: t9 += h + carry
# asm 1: adc <h=int64#5,<t9=int64#7
# asm 2: adc <h=%r8,<t9=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS7[2] = t8
# asm 1: movq <t8=int64#6,<stack_FVGS7=stack256#9
# asm 2: movq <t8=%r9,<stack_FVGS7=400(%rsp)
movq %r9,400(%rsp)

# qhasm: a9 = mem64[input_0 + 72]
# asm 1: movq   72(<input_0=int64#1),>a9=int64#4
# asm 2: movq   72(<input_0=%rdi),>a9=%rcx
movq   72(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a9 += t9
# asm 1: add  <t9=int64#7,<a9=int64#4
# asm 2: add  <t9=%rax,<a9=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t10 t9 = minv * mem64[ table + 232 ]
# asm 1: mulx  232(<table=int64#2),>t9=int64#7,>t10=int64#6
# asm 2: mulx  232(<table=%rsi),>t9=%rax,>t10=%r9
mulx  232(%rsi),%rax,%r9

# qhasm: carry? t9 += a9
# asm 1: add  <a9=int64#4,<t9=int64#7
# asm 2: add  <a9=%rcx,<t9=%rax
add  %rcx,%rax

# qhasm: t10 += h + carry
# asm 1: adc <h=int64#5,<t10=int64#6
# asm 2: adc <h=%r8,<t10=%r9
adc %r8,%r9

# qhasm: inplace stack_FVGS8[2] = t9
# asm 1: movq <t9=int64#7,<stack_FVGS8=stack256#10
# asm 2: movq <t9=%rax,<stack_FVGS8=432(%rsp)
movq %rax,432(%rsp)

# qhasm: a10 = mem64[input_0 + 80]
# asm 1: movq   80(<input_0=int64#1),>a10=int64#4
# asm 2: movq   80(<input_0=%rdi),>a10=%rcx
movq   80(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a10 += t10
# asm 1: add  <t10=int64#6,<a10=int64#4
# asm 2: add  <t10=%r9,<a10=%rcx
add  %r9,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t11 t10 = minv * mem64[ table + 240 ]
# asm 1: mulx  240(<table=int64#2),>t10=int64#6,>t11=int64#7
# asm 2: mulx  240(<table=%rsi),>t10=%r9,>t11=%rax
mulx  240(%rsi),%r9,%rax

# qhasm: carry? t10 += a10
# asm 1: add  <a10=int64#4,<t10=int64#6
# asm 2: add  <a10=%rcx,<t10=%r9
add  %rcx,%r9

# qhasm: t11 += h + carry
# asm 1: adc <h=int64#5,<t11=int64#7
# asm 2: adc <h=%r8,<t11=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS9[2] = t10
# asm 1: movq <t10=int64#6,<stack_FVGS9=stack256#11
# asm 2: movq <t10=%r9,<stack_FVGS9=464(%rsp)
movq %r9,464(%rsp)

# qhasm: a11 = mem64[input_0 + 88]
# asm 1: movq   88(<input_0=int64#1),>a11=int64#4
# asm 2: movq   88(<input_0=%rdi),>a11=%rcx
movq   88(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a11 += t11
# asm 1: add  <t11=int64#7,<a11=int64#4
# asm 2: add  <t11=%rax,<a11=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t12 t11 = minv * mem64[ table + 248 ]
# asm 1: mulx  248(<table=int64#2),>t11=int64#6,>t12=int64#7
# asm 2: mulx  248(<table=%rsi),>t11=%r9,>t12=%rax
mulx  248(%rsi),%r9,%rax

# qhasm: carry? t11 += a11
# asm 1: add  <a11=int64#4,<t11=int64#6
# asm 2: add  <a11=%rcx,<t11=%r9
add  %rcx,%r9

# qhasm: t12 += h + carry
# asm 1: adc <h=int64#5,<t12=int64#7
# asm 2: adc <h=%r8,<t12=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS10[2] = t11
# asm 1: movq <t11=int64#6,<stack_FVGS10=stack256#12
# asm 2: movq <t11=%r9,<stack_FVGS10=496(%rsp)
movq %r9,496(%rsp)

# qhasm: a12 = mem64[input_0 + 96]
# asm 1: movq   96(<input_0=int64#1),>a12=int64#4
# asm 2: movq   96(<input_0=%rdi),>a12=%rcx
movq   96(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a12 += t12
# asm 1: add  <t12=int64#7,<a12=int64#4
# asm 2: add  <t12=%rax,<a12=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t13 t12 = minv * mem64[ table + 256 ]
# asm 1: mulx  256(<table=int64#2),>t12=int64#6,>t13=int64#7
# asm 2: mulx  256(<table=%rsi),>t12=%r9,>t13=%rax
mulx  256(%rsi),%r9,%rax

# qhasm: carry? t12 += a12
# asm 1: add  <a12=int64#4,<t12=int64#6
# asm 2: add  <a12=%rcx,<t12=%r9
add  %rcx,%r9

# qhasm: t13 += h + carry
# asm 1: adc <h=int64#5,<t13=int64#7
# asm 2: adc <h=%r8,<t13=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS11[2] = t12
# asm 1: movq <t12=int64#6,<stack_FVGS11=stack256#13
# asm 2: movq <t12=%r9,<stack_FVGS11=528(%rsp)
movq %r9,528(%rsp)

# qhasm: a13 = mem64[input_0 + 104]
# asm 1: movq   104(<input_0=int64#1),>a13=int64#4
# asm 2: movq   104(<input_0=%rdi),>a13=%rcx
movq   104(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a13 += t13
# asm 1: add  <t13=int64#7,<a13=int64#4
# asm 2: add  <t13=%rax,<a13=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t14 t13 = minv * mem64[ table + 264 ]
# asm 1: mulx  264(<table=int64#2),>t13=int64#6,>t14=int64#7
# asm 2: mulx  264(<table=%rsi),>t13=%r9,>t14=%rax
mulx  264(%rsi),%r9,%rax

# qhasm: carry? t13 += a13
# asm 1: add  <a13=int64#4,<t13=int64#6
# asm 2: add  <a13=%rcx,<t13=%r9
add  %rcx,%r9

# qhasm: t14 += h + carry
# asm 1: adc <h=int64#5,<t14=int64#7
# asm 2: adc <h=%r8,<t14=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS12[2] = t13
# asm 1: movq <t13=int64#6,<stack_FVGS12=stack256#14
# asm 2: movq <t13=%r9,<stack_FVGS12=560(%rsp)
movq %r9,560(%rsp)

# qhasm: a14 = mem64[input_0 + 112]
# asm 1: movq   112(<input_0=int64#1),>a14=int64#4
# asm 2: movq   112(<input_0=%rdi),>a14=%rcx
movq   112(%rdi),%rcx

# qhasm: h = 0
# asm 1: xor  >h=int64#5,>h=int64#5
# asm 2: xor  >h=%r8,>h=%r8
xor  %r8,%r8

# qhasm: carry? a14 += t14
# asm 1: add  <t14=int64#7,<a14=int64#4
# asm 2: add  <t14=%rax,<a14=%rcx
add  %rax,%rcx

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#5
# asm 2: adc $0,<h=%r8
adc $0,%r8

# qhasm: (uint128) t15 t14 = minv * mem64[ table + 272 ]
# asm 1: mulx  272(<table=int64#2),>t14=int64#6,>t15=int64#7
# asm 2: mulx  272(<table=%rsi),>t14=%r9,>t15=%rax
mulx  272(%rsi),%r9,%rax

# qhasm: carry? t14 += a14
# asm 1: add  <a14=int64#4,<t14=int64#6
# asm 2: add  <a14=%rcx,<t14=%r9
add  %rcx,%r9

# qhasm: t15 += h + carry
# asm 1: adc <h=int64#5,<t15=int64#7
# asm 2: adc <h=%r8,<t15=%rax
adc %r8,%rax

# qhasm: inplace stack_FVGS13[2] = t14
# asm 1: movq <t14=int64#6,<stack_FVGS13=stack256#15
# asm 2: movq <t14=%r9,<stack_FVGS13=592(%rsp)
movq %r9,592(%rsp)

# qhasm: a15 = mem64[input_0 + 120]
# asm 1: movq   120(<input_0=int64#1),>a15=int64#1
# asm 2: movq   120(<input_0=%rdi),>a15=%rdi
movq   120(%rdi),%rdi

# qhasm: h = 0
# asm 1: xor  >h=int64#4,>h=int64#4
# asm 2: xor  >h=%rcx,>h=%rcx
xor  %rcx,%rcx

# qhasm: carry? a15 += t15
# asm 1: add  <t15=int64#7,<a15=int64#1
# asm 2: add  <t15=%rax,<a15=%rdi
add  %rax,%rdi

# qhasm: h += 0 + carry
# asm 1: adc $0,<h=int64#4
# asm 2: adc $0,<h=%rcx
adc $0,%rcx

# qhasm: (uint128) t16 t15 = minv * mem64[ table + 280 ]
# asm 1: mulx  280(<table=int64#2),>t15=int64#3,>t16=int64#5
# asm 2: mulx  280(<table=%rsi),>t15=%rdx,>t16=%r8
mulx  280(%rsi),%rdx,%r8

# qhasm: carry? t15 += a15
# asm 1: add  <a15=int64#1,<t15=int64#3
# asm 2: add  <a15=%rdi,<t15=%rdx
add  %rdi,%rdx

# qhasm: t16 += h + carry
# asm 1: adc <h=int64#4,<t16=int64#5
# asm 2: adc <h=%rcx,<t16=%r8
adc %rcx,%r8

# qhasm: inplace stack_FVGS14[2] = t15
# asm 1: movq <t15=int64#3,<stack_FVGS14=stack256#16
# asm 2: movq <t15=%rdx,<stack_FVGS14=624(%rsp)
movq %rdx,624(%rsp)

# qhasm: inplace stack_FVGS15[2] = t16
# asm 1: movq <t16=int64#5,<stack_FVGS15=stack256#17
# asm 2: movq <t16=%r8,<stack_FVGS15=656(%rsp)
movq %r8,656(%rsp)

# qhasm: a0 = stack_FVGS0[2]
# asm 1: movq <stack_FVGS0=stack256#2,>a0=int64#1
# asm 2: movq <stack_FVGS0=176(%rsp),>a0=%rdi
movq 176(%rsp),%rdi

# qhasm: carry? a0 -= mem64[ table + 160]
# asm 1: subq 160(<table=int64#2),<a0=int64#1
# asm 2: subq 160(<table=%rsi),<a0=%rdi
subq 160(%rsi),%rdi

# qhasm: inplace stack_FVGS19[2] = a0
# asm 1: movq <a0=int64#1,<stack_FVGS19=stack256#21
# asm 2: movq <a0=%rdi,<stack_FVGS19=784(%rsp)
movq %rdi,784(%rsp)

# qhasm: a1 = stack_FVGS1[2]
# asm 1: movq <stack_FVGS1=stack256#3,>a1=int64#1
# asm 2: movq <stack_FVGS1=208(%rsp),>a1=%rdi
movq 208(%rsp),%rdi

# qhasm: carry? a1 -= mem64[ table + 168] - carry
# asm 1: sbbq 168(<table=int64#2),<a1=int64#1
# asm 2: sbbq 168(<table=%rsi),<a1=%rdi
sbbq 168(%rsi),%rdi

# qhasm: inplace stack_FVGS20[2] = a1
# asm 1: movq <a1=int64#1,<stack_FVGS20=stack256#22
# asm 2: movq <a1=%rdi,<stack_FVGS20=816(%rsp)
movq %rdi,816(%rsp)

# qhasm: a2 = stack_FVGS2[2]
# asm 1: movq <stack_FVGS2=stack256#4,>a2=int64#1
# asm 2: movq <stack_FVGS2=240(%rsp),>a2=%rdi
movq 240(%rsp),%rdi

# qhasm: carry? a2 -= mem64[ table + 176] - carry
# asm 1: sbbq 176(<table=int64#2),<a2=int64#1
# asm 2: sbbq 176(<table=%rsi),<a2=%rdi
sbbq 176(%rsi),%rdi

# qhasm: inplace stack_FVGS21[2] = a2
# asm 1: movq <a2=int64#1,<stack_FVGS21=stack256#23
# asm 2: movq <a2=%rdi,<stack_FVGS21=848(%rsp)
movq %rdi,848(%rsp)

# qhasm: a3 = stack_FVGS3[2]
# asm 1: movq <stack_FVGS3=stack256#5,>a3=int64#1
# asm 2: movq <stack_FVGS3=272(%rsp),>a3=%rdi
movq 272(%rsp),%rdi

# qhasm: carry? a3 -= mem64[ table + 184] - carry
# asm 1: sbbq 184(<table=int64#2),<a3=int64#1
# asm 2: sbbq 184(<table=%rsi),<a3=%rdi
sbbq 184(%rsi),%rdi

# qhasm: inplace stack_FVGS22[2] = a3
# asm 1: movq <a3=int64#1,<stack_FVGS22=stack256#24
# asm 2: movq <a3=%rdi,<stack_FVGS22=880(%rsp)
movq %rdi,880(%rsp)

# qhasm: a4 = stack_FVGS4[2]
# asm 1: movq <stack_FVGS4=stack256#6,>a4=int64#1
# asm 2: movq <stack_FVGS4=304(%rsp),>a4=%rdi
movq 304(%rsp),%rdi

# qhasm: carry? a4 -= mem64[ table + 192] - carry
# asm 1: sbbq 192(<table=int64#2),<a4=int64#1
# asm 2: sbbq 192(<table=%rsi),<a4=%rdi
sbbq 192(%rsi),%rdi

# qhasm: inplace stack_FVGS23[2] = a4
# asm 1: movq <a4=int64#1,<stack_FVGS23=stack256#25
# asm 2: movq <a4=%rdi,<stack_FVGS23=912(%rsp)
movq %rdi,912(%rsp)

# qhasm: a5 = stack_FVGS5[2]
# asm 1: movq <stack_FVGS5=stack256#7,>a5=int64#1
# asm 2: movq <stack_FVGS5=336(%rsp),>a5=%rdi
movq 336(%rsp),%rdi

# qhasm: carry? a5 -= mem64[ table + 200] - carry
# asm 1: sbbq 200(<table=int64#2),<a5=int64#1
# asm 2: sbbq 200(<table=%rsi),<a5=%rdi
sbbq 200(%rsi),%rdi

# qhasm: inplace stack_FVGS24[2] = a5
# asm 1: movq <a5=int64#1,<stack_FVGS24=stack256#26
# asm 2: movq <a5=%rdi,<stack_FVGS24=944(%rsp)
movq %rdi,944(%rsp)

# qhasm: a6 = stack_FVGS6[2]
# asm 1: movq <stack_FVGS6=stack256#8,>a6=int64#1
# asm 2: movq <stack_FVGS6=368(%rsp),>a6=%rdi
movq 368(%rsp),%rdi

# qhasm: carry? a6 -= mem64[ table + 208] - carry
# asm 1: sbbq 208(<table=int64#2),<a6=int64#1
# asm 2: sbbq 208(<table=%rsi),<a6=%rdi
sbbq 208(%rsi),%rdi

# qhasm: inplace stack_FVGS25[2] = a6
# asm 1: movq <a6=int64#1,<stack_FVGS25=stack256#27
# asm 2: movq <a6=%rdi,<stack_FVGS25=976(%rsp)
movq %rdi,976(%rsp)

# qhasm: a7 = stack_FVGS7[2]
# asm 1: movq <stack_FVGS7=stack256#9,>a7=int64#1
# asm 2: movq <stack_FVGS7=400(%rsp),>a7=%rdi
movq 400(%rsp),%rdi

# qhasm: carry? a7 -= mem64[ table + 216] - carry
# asm 1: sbbq 216(<table=int64#2),<a7=int64#1
# asm 2: sbbq 216(<table=%rsi),<a7=%rdi
sbbq 216(%rsi),%rdi

# qhasm: inplace stack_FVGS26[2] = a7
# asm 1: movq <a7=int64#1,<stack_FVGS26=stack256#28
# asm 2: movq <a7=%rdi,<stack_FVGS26=1008(%rsp)
movq %rdi,1008(%rsp)

# qhasm: a8 = stack_FVGS8[2]
# asm 1: movq <stack_FVGS8=stack256#10,>a8=int64#1
# asm 2: movq <stack_FVGS8=432(%rsp),>a8=%rdi
movq 432(%rsp),%rdi

# qhasm: carry? a8 -= mem64[ table + 224] - carry
# asm 1: sbbq 224(<table=int64#2),<a8=int64#1
# asm 2: sbbq 224(<table=%rsi),<a8=%rdi
sbbq 224(%rsi),%rdi

# qhasm: inplace stack_FVGS27[2] = a8
# asm 1: movq <a8=int64#1,<stack_FVGS27=stack256#29
# asm 2: movq <a8=%rdi,<stack_FVGS27=1040(%rsp)
movq %rdi,1040(%rsp)

# qhasm: a9 = stack_FVGS9[2]
# asm 1: movq <stack_FVGS9=stack256#11,>a9=int64#1
# asm 2: movq <stack_FVGS9=464(%rsp),>a9=%rdi
movq 464(%rsp),%rdi

# qhasm: carry? a9 -= mem64[ table + 232] - carry
# asm 1: sbbq 232(<table=int64#2),<a9=int64#1
# asm 2: sbbq 232(<table=%rsi),<a9=%rdi
sbbq 232(%rsi),%rdi

# qhasm: inplace stack_FVGS28[2] = a9
# asm 1: movq <a9=int64#1,<stack_FVGS28=stack256#30
# asm 2: movq <a9=%rdi,<stack_FVGS28=1072(%rsp)
movq %rdi,1072(%rsp)

# qhasm: a10 = stack_FVGS10[2]
# asm 1: movq <stack_FVGS10=stack256#12,>a10=int64#1
# asm 2: movq <stack_FVGS10=496(%rsp),>a10=%rdi
movq 496(%rsp),%rdi

# qhasm: carry? a10 -= mem64[ table + 240] - carry
# asm 1: sbbq 240(<table=int64#2),<a10=int64#1
# asm 2: sbbq 240(<table=%rsi),<a10=%rdi
sbbq 240(%rsi),%rdi

# qhasm: inplace stack_FVGS29[2] = a10
# asm 1: movq <a10=int64#1,<stack_FVGS29=stack256#31
# asm 2: movq <a10=%rdi,<stack_FVGS29=1104(%rsp)
movq %rdi,1104(%rsp)

# qhasm: a11 = stack_FVGS11[2]
# asm 1: movq <stack_FVGS11=stack256#13,>a11=int64#1
# asm 2: movq <stack_FVGS11=528(%rsp),>a11=%rdi
movq 528(%rsp),%rdi

# qhasm: carry? a11 -= mem64[ table + 248] - carry
# asm 1: sbbq 248(<table=int64#2),<a11=int64#1
# asm 2: sbbq 248(<table=%rsi),<a11=%rdi
sbbq 248(%rsi),%rdi

# qhasm: inplace stack_FVGS30[2] = a11
# asm 1: movq <a11=int64#1,<stack_FVGS30=stack256#32
# asm 2: movq <a11=%rdi,<stack_FVGS30=1136(%rsp)
movq %rdi,1136(%rsp)

# qhasm: a12 = stack_FVGS12[2]
# asm 1: movq <stack_FVGS12=stack256#14,>a12=int64#1
# asm 2: movq <stack_FVGS12=560(%rsp),>a12=%rdi
movq 560(%rsp),%rdi

# qhasm: carry? a12 -= mem64[ table + 256] - carry
# asm 1: sbbq 256(<table=int64#2),<a12=int64#1
# asm 2: sbbq 256(<table=%rsi),<a12=%rdi
sbbq 256(%rsi),%rdi

# qhasm: inplace stack_FVGS31[2] = a12
# asm 1: movq <a12=int64#1,<stack_FVGS31=stack256#33
# asm 2: movq <a12=%rdi,<stack_FVGS31=1168(%rsp)
movq %rdi,1168(%rsp)

# qhasm: a13 = stack_FVGS13[2]
# asm 1: movq <stack_FVGS13=stack256#15,>a13=int64#1
# asm 2: movq <stack_FVGS13=592(%rsp),>a13=%rdi
movq 592(%rsp),%rdi

# qhasm: carry? a13 -= mem64[ table + 264] - carry
# asm 1: sbbq 264(<table=int64#2),<a13=int64#1
# asm 2: sbbq 264(<table=%rsi),<a13=%rdi
sbbq 264(%rsi),%rdi

# qhasm: inplace stack_FVGS32[2] = a13
# asm 1: movq <a13=int64#1,<stack_FVGS32=stack256#34
# asm 2: movq <a13=%rdi,<stack_FVGS32=1200(%rsp)
movq %rdi,1200(%rsp)

# qhasm: a14 = stack_FVGS14[2]
# asm 1: movq <stack_FVGS14=stack256#16,>a14=int64#1
# asm 2: movq <stack_FVGS14=624(%rsp),>a14=%rdi
movq 624(%rsp),%rdi

# qhasm: carry? a14 -= mem64[ table + 272] - carry
# asm 1: sbbq 272(<table=int64#2),<a14=int64#1
# asm 2: sbbq 272(<table=%rsi),<a14=%rdi
sbbq 272(%rsi),%rdi

# qhasm: inplace stack_FVGS33[2] = a14
# asm 1: movq <a14=int64#1,<stack_FVGS33=stack256#35
# asm 2: movq <a14=%rdi,<stack_FVGS33=1232(%rsp)
movq %rdi,1232(%rsp)

# qhasm: a15 = stack_FVGS15[2]
# asm 1: movq <stack_FVGS15=stack256#17,>a15=int64#1
# asm 2: movq <stack_FVGS15=656(%rsp),>a15=%rdi
movq 656(%rsp),%rdi

# qhasm: carry? a15 -= mem64[ table + 280] - carry
# asm 1: sbbq 280(<table=int64#2),<a15=int64#1
# asm 2: sbbq 280(<table=%rsi),<a15=%rdi
sbbq 280(%rsi),%rdi

# qhasm: inplace stack_FVGS34[2] = a15
# asm 1: movq <a15=int64#1,<stack_FVGS34=stack256#36
# asm 2: movq <a15=%rdi,<stack_FVGS34=1264(%rsp)
movq %rdi,1264(%rsp)

# qhasm: a15 = stack_FVGS34[2]
# asm 1: movq <stack_FVGS34=stack256#36,>a15=int64#1
# asm 2: movq <stack_FVGS34=1264(%rsp),>a15=%rdi
movq 1264(%rsp),%rdi

# qhasm: a15 = stack_FVGS15[2] if carry
# asm 1: cmovc <stack_FVGS15=stack256#17,<a15=int64#1
# asm 2: cmovc <stack_FVGS15=656(%rsp),<a15=%rdi
cmovc 656(%rsp),%rdi

# qhasm: inplace stack_FVGS34[2] = a15
# asm 1: movq <a15=int64#1,<stack_FVGS34=stack256#36
# asm 2: movq <a15=%rdi,<stack_FVGS34=1264(%rsp)
movq %rdi,1264(%rsp)

# qhasm: a14 = stack_FVGS33[2]
# asm 1: movq <stack_FVGS33=stack256#35,>a14=int64#1
# asm 2: movq <stack_FVGS33=1232(%rsp),>a14=%rdi
movq 1232(%rsp),%rdi

# qhasm: a14 = stack_FVGS14[2] if carry
# asm 1: cmovc <stack_FVGS14=stack256#16,<a14=int64#1
# asm 2: cmovc <stack_FVGS14=624(%rsp),<a14=%rdi
cmovc 624(%rsp),%rdi

# qhasm: inplace stack_FVGS33[2] = a14
# asm 1: movq <a14=int64#1,<stack_FVGS33=stack256#35
# asm 2: movq <a14=%rdi,<stack_FVGS33=1232(%rsp)
movq %rdi,1232(%rsp)

# qhasm: a13 = stack_FVGS32[2]
# asm 1: movq <stack_FVGS32=stack256#34,>a13=int64#1
# asm 2: movq <stack_FVGS32=1200(%rsp),>a13=%rdi
movq 1200(%rsp),%rdi

# qhasm: a13 = stack_FVGS13[2] if carry
# asm 1: cmovc <stack_FVGS13=stack256#15,<a13=int64#1
# asm 2: cmovc <stack_FVGS13=592(%rsp),<a13=%rdi
cmovc 592(%rsp),%rdi

# qhasm: inplace stack_FVGS32[2] = a13
# asm 1: movq <a13=int64#1,<stack_FVGS32=stack256#34
# asm 2: movq <a13=%rdi,<stack_FVGS32=1200(%rsp)
movq %rdi,1200(%rsp)

# qhasm: a12 = stack_FVGS31[2]
# asm 1: movq <stack_FVGS31=stack256#33,>a12=int64#1
# asm 2: movq <stack_FVGS31=1168(%rsp),>a12=%rdi
movq 1168(%rsp),%rdi

# qhasm: a12 = stack_FVGS12[2] if carry
# asm 1: cmovc <stack_FVGS12=stack256#14,<a12=int64#1
# asm 2: cmovc <stack_FVGS12=560(%rsp),<a12=%rdi
cmovc 560(%rsp),%rdi

# qhasm: inplace stack_FVGS31[2] = a12
# asm 1: movq <a12=int64#1,<stack_FVGS31=stack256#33
# asm 2: movq <a12=%rdi,<stack_FVGS31=1168(%rsp)
movq %rdi,1168(%rsp)

# qhasm: a11 = stack_FVGS30[2]
# asm 1: movq <stack_FVGS30=stack256#32,>a11=int64#1
# asm 2: movq <stack_FVGS30=1136(%rsp),>a11=%rdi
movq 1136(%rsp),%rdi

# qhasm: a11 = stack_FVGS11[2] if carry
# asm 1: cmovc <stack_FVGS11=stack256#13,<a11=int64#1
# asm 2: cmovc <stack_FVGS11=528(%rsp),<a11=%rdi
cmovc 528(%rsp),%rdi

# qhasm: inplace stack_FVGS30[2] = a11
# asm 1: movq <a11=int64#1,<stack_FVGS30=stack256#32
# asm 2: movq <a11=%rdi,<stack_FVGS30=1136(%rsp)
movq %rdi,1136(%rsp)

# qhasm: a10 = stack_FVGS29[2]
# asm 1: movq <stack_FVGS29=stack256#31,>a10=int64#1
# asm 2: movq <stack_FVGS29=1104(%rsp),>a10=%rdi
movq 1104(%rsp),%rdi

# qhasm: a10 = stack_FVGS10[2] if carry
# asm 1: cmovc <stack_FVGS10=stack256#12,<a10=int64#1
# asm 2: cmovc <stack_FVGS10=496(%rsp),<a10=%rdi
cmovc 496(%rsp),%rdi

# qhasm: inplace stack_FVGS29[2] = a10
# asm 1: movq <a10=int64#1,<stack_FVGS29=stack256#31
# asm 2: movq <a10=%rdi,<stack_FVGS29=1104(%rsp)
movq %rdi,1104(%rsp)

# qhasm: a9 = stack_FVGS28[2]
# asm 1: movq <stack_FVGS28=stack256#30,>a9=int64#1
# asm 2: movq <stack_FVGS28=1072(%rsp),>a9=%rdi
movq 1072(%rsp),%rdi

# qhasm: a9 = stack_FVGS9[2] if carry
# asm 1: cmovc <stack_FVGS9=stack256#11,<a9=int64#1
# asm 2: cmovc <stack_FVGS9=464(%rsp),<a9=%rdi
cmovc 464(%rsp),%rdi

# qhasm: inplace stack_FVGS28[2] = a9
# asm 1: movq <a9=int64#1,<stack_FVGS28=stack256#30
# asm 2: movq <a9=%rdi,<stack_FVGS28=1072(%rsp)
movq %rdi,1072(%rsp)

# qhasm: a8 = stack_FVGS27[2]
# asm 1: movq <stack_FVGS27=stack256#29,>a8=int64#1
# asm 2: movq <stack_FVGS27=1040(%rsp),>a8=%rdi
movq 1040(%rsp),%rdi

# qhasm: a8 = stack_FVGS8[2] if carry
# asm 1: cmovc <stack_FVGS8=stack256#10,<a8=int64#1
# asm 2: cmovc <stack_FVGS8=432(%rsp),<a8=%rdi
cmovc 432(%rsp),%rdi

# qhasm: inplace stack_FVGS27[2] = a8
# asm 1: movq <a8=int64#1,<stack_FVGS27=stack256#29
# asm 2: movq <a8=%rdi,<stack_FVGS27=1040(%rsp)
movq %rdi,1040(%rsp)

# qhasm: a7 = stack_FVGS26[2]
# asm 1: movq <stack_FVGS26=stack256#28,>a7=int64#1
# asm 2: movq <stack_FVGS26=1008(%rsp),>a7=%rdi
movq 1008(%rsp),%rdi

# qhasm: a7 = stack_FVGS7[2] if carry
# asm 1: cmovc <stack_FVGS7=stack256#9,<a7=int64#1
# asm 2: cmovc <stack_FVGS7=400(%rsp),<a7=%rdi
cmovc 400(%rsp),%rdi

# qhasm: inplace stack_FVGS26[2] = a7
# asm 1: movq <a7=int64#1,<stack_FVGS26=stack256#28
# asm 2: movq <a7=%rdi,<stack_FVGS26=1008(%rsp)
movq %rdi,1008(%rsp)

# qhasm: a6 = stack_FVGS25[2]
# asm 1: movq <stack_FVGS25=stack256#27,>a6=int64#1
# asm 2: movq <stack_FVGS25=976(%rsp),>a6=%rdi
movq 976(%rsp),%rdi

# qhasm: a6 = stack_FVGS6[2] if carry
# asm 1: cmovc <stack_FVGS6=stack256#8,<a6=int64#1
# asm 2: cmovc <stack_FVGS6=368(%rsp),<a6=%rdi
cmovc 368(%rsp),%rdi

# qhasm: inplace stack_FVGS25[2] = a6
# asm 1: movq <a6=int64#1,<stack_FVGS25=stack256#27
# asm 2: movq <a6=%rdi,<stack_FVGS25=976(%rsp)
movq %rdi,976(%rsp)

# qhasm: a5 = stack_FVGS24[2]
# asm 1: movq <stack_FVGS24=stack256#26,>a5=int64#1
# asm 2: movq <stack_FVGS24=944(%rsp),>a5=%rdi
movq 944(%rsp),%rdi

# qhasm: a5 = stack_FVGS5[2] if carry
# asm 1: cmovc <stack_FVGS5=stack256#7,<a5=int64#1
# asm 2: cmovc <stack_FVGS5=336(%rsp),<a5=%rdi
cmovc 336(%rsp),%rdi

# qhasm: inplace stack_FVGS24[2] = a5
# asm 1: movq <a5=int64#1,<stack_FVGS24=stack256#26
# asm 2: movq <a5=%rdi,<stack_FVGS24=944(%rsp)
movq %rdi,944(%rsp)

# qhasm: a4 = stack_FVGS23[2]
# asm 1: movq <stack_FVGS23=stack256#25,>a4=int64#1
# asm 2: movq <stack_FVGS23=912(%rsp),>a4=%rdi
movq 912(%rsp),%rdi

# qhasm: a4 = stack_FVGS4[2] if carry
# asm 1: cmovc <stack_FVGS4=stack256#6,<a4=int64#1
# asm 2: cmovc <stack_FVGS4=304(%rsp),<a4=%rdi
cmovc 304(%rsp),%rdi

# qhasm: inplace stack_FVGS23[2] = a4
# asm 1: movq <a4=int64#1,<stack_FVGS23=stack256#25
# asm 2: movq <a4=%rdi,<stack_FVGS23=912(%rsp)
movq %rdi,912(%rsp)

# qhasm: a3 = stack_FVGS22[2]
# asm 1: movq <stack_FVGS22=stack256#24,>a3=int64#1
# asm 2: movq <stack_FVGS22=880(%rsp),>a3=%rdi
movq 880(%rsp),%rdi

# qhasm: a3 = stack_FVGS3[2] if carry
# asm 1: cmovc <stack_FVGS3=stack256#5,<a3=int64#1
# asm 2: cmovc <stack_FVGS3=272(%rsp),<a3=%rdi
cmovc 272(%rsp),%rdi

# qhasm: inplace stack_FVGS22[2] = a3
# asm 1: movq <a3=int64#1,<stack_FVGS22=stack256#24
# asm 2: movq <a3=%rdi,<stack_FVGS22=880(%rsp)
movq %rdi,880(%rsp)

# qhasm: a2 = stack_FVGS21[2]
# asm 1: movq <stack_FVGS21=stack256#23,>a2=int64#1
# asm 2: movq <stack_FVGS21=848(%rsp),>a2=%rdi
movq 848(%rsp),%rdi

# qhasm: a2 = stack_FVGS2[2] if carry
# asm 1: cmovc <stack_FVGS2=stack256#4,<a2=int64#1
# asm 2: cmovc <stack_FVGS2=240(%rsp),<a2=%rdi
cmovc 240(%rsp),%rdi

# qhasm: inplace stack_FVGS21[2] = a2
# asm 1: movq <a2=int64#1,<stack_FVGS21=stack256#23
# asm 2: movq <a2=%rdi,<stack_FVGS21=848(%rsp)
movq %rdi,848(%rsp)

# qhasm: a1 = stack_FVGS20[2]
# asm 1: movq <stack_FVGS20=stack256#22,>a1=int64#1
# asm 2: movq <stack_FVGS20=816(%rsp),>a1=%rdi
movq 816(%rsp),%rdi

# qhasm: a1 = stack_FVGS1[2] if carry
# asm 1: cmovc <stack_FVGS1=stack256#3,<a1=int64#1
# asm 2: cmovc <stack_FVGS1=208(%rsp),<a1=%rdi
cmovc 208(%rsp),%rdi

# qhasm: inplace stack_FVGS20[2] = a1
# asm 1: movq <a1=int64#1,<stack_FVGS20=stack256#22
# asm 2: movq <a1=%rdi,<stack_FVGS20=816(%rsp)
movq %rdi,816(%rsp)

# qhasm: a0 = stack_FVGS19[2]
# asm 1: movq <stack_FVGS19=stack256#21,>a0=int64#1
# asm 2: movq <stack_FVGS19=784(%rsp),>a0=%rdi
movq 784(%rsp),%rdi

# qhasm: a0 = stack_FVGS0[2] if carry
# asm 1: cmovc <stack_FVGS0=stack256#2,<a0=int64#1
# asm 2: cmovc <stack_FVGS0=176(%rsp),<a0=%rdi
cmovc 176(%rsp),%rdi

# qhasm: inplace stack_FVGS19[2] = a0
# asm 1: movq <a0=int64#1,<stack_FVGS19=stack256#21
# asm 2: movq <a0=%rdi,<stack_FVGS19=784(%rsp)
movq %rdi,784(%rsp)

# qhasm: t0 = -1152921504606846976
# asm 1: mov  $-1152921504606846976,>t0=int64#3
# asm 2: mov  $-1152921504606846976,>t0=%rdx
mov  $-1152921504606846976,%rdx

# qhasm: g = a0 & ~ t0
# asm 1: andn  <a0=int64#1,<t0=int64#3,>g=int64#1
# asm 2: andn  <a0=%rdi,<t0=%rdx,>g=%rdi
andn  %rdi,%rdx,%rdi

# qhasm: a0 = stack_FVGS19[2]
# asm 1: movq <stack_FVGS19=stack256#21,>a0=int64#3
# asm 2: movq <stack_FVGS19=784(%rsp),>a0=%rdx
movq 784(%rsp),%rdx

# qhasm: t0 = a0
# asm 1: mov  <a0=int64#3,>t0=int64#4
# asm 2: mov  <a0=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS0[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS0=stack256#2
# asm 2: movq <t0=%rcx,<stack_FVGS0=176(%rsp)
movq %rcx,176(%rsp)

# qhasm: t0 = a0
# asm 1: mov  <a0=int64#3,>t0=int64#4
# asm 2: mov  <a0=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 30
# asm 1: shr  $30,<t0=int64#4
# asm 2: shr  $30,<t0=%rcx
shr  $30,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS1[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS1=stack256#3
# asm 2: movq <t0=%rcx,<stack_FVGS1=208(%rsp)
movq %rcx,208(%rsp)

# qhasm: a1 = stack_FVGS20[2]
# asm 1: movq <stack_FVGS20=stack256#22,>a1=int64#4
# asm 2: movq <stack_FVGS20=816(%rsp),>a1=%rcx
movq 816(%rsp),%rcx

# qhasm: a0 = (a1 a0) >> 60
# asm 1: shrd $60,<a1=int64#4,<a0=int64#3
# asm 2: shrd $60,<a1=%rcx,<a0=%rdx
shrd $60,%rcx,%rdx

# qhasm: a0 &= 1073741823
# asm 1: and  $1073741823,<a0=int64#3
# asm 2: and  $1073741823,<a0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS2[2] = a0
# asm 1: movq <a0=int64#3,<stack_FVGS2=stack256#4
# asm 2: movq <a0=%rdx,<stack_FVGS2=240(%rsp)
movq %rdx,240(%rsp)

# qhasm: t0 = a1
# asm 1: mov  <a1=int64#4,>t0=int64#3
# asm 2: mov  <a1=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 26
# asm 1: shr  $26,<t0=int64#3
# asm 2: shr  $26,<t0=%rdx
shr  $26,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS3[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS3=stack256#5
# asm 2: movq <t0=%rdx,<stack_FVGS3=272(%rsp)
movq %rdx,272(%rsp)

# qhasm: a2 = stack_FVGS21[2]
# asm 1: movq <stack_FVGS21=stack256#23,>a2=int64#3
# asm 2: movq <stack_FVGS21=848(%rsp),>a2=%rdx
movq 848(%rsp),%rdx

# qhasm: a1 = (a2 a1) >> 56
# asm 1: shrd $56,<a2=int64#3,<a1=int64#4
# asm 2: shrd $56,<a2=%rdx,<a1=%rcx
shrd $56,%rdx,%rcx

# qhasm: a1 &= 1073741823
# asm 1: and  $1073741823,<a1=int64#4
# asm 2: and  $1073741823,<a1=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS4[2] = a1
# asm 1: movq <a1=int64#4,<stack_FVGS4=stack256#6
# asm 2: movq <a1=%rcx,<stack_FVGS4=304(%rsp)
movq %rcx,304(%rsp)

# qhasm: t0 = a2
# asm 1: mov  <a2=int64#3,>t0=int64#4
# asm 2: mov  <a2=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 22
# asm 1: shr  $22,<t0=int64#4
# asm 2: shr  $22,<t0=%rcx
shr  $22,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS5[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS5=stack256#7
# asm 2: movq <t0=%rcx,<stack_FVGS5=336(%rsp)
movq %rcx,336(%rsp)

# qhasm: a3 = stack_FVGS22[2]
# asm 1: movq <stack_FVGS22=stack256#24,>a3=int64#4
# asm 2: movq <stack_FVGS22=880(%rsp),>a3=%rcx
movq 880(%rsp),%rcx

# qhasm: a2 = (a3 a2) >> 52
# asm 1: shrd $52,<a3=int64#4,<a2=int64#3
# asm 2: shrd $52,<a3=%rcx,<a2=%rdx
shrd $52,%rcx,%rdx

# qhasm: a2 &= 1073741823
# asm 1: and  $1073741823,<a2=int64#3
# asm 2: and  $1073741823,<a2=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS6[2] = a2
# asm 1: movq <a2=int64#3,<stack_FVGS6=stack256#8
# asm 2: movq <a2=%rdx,<stack_FVGS6=368(%rsp)
movq %rdx,368(%rsp)

# qhasm: t0 = a3
# asm 1: mov  <a3=int64#4,>t0=int64#3
# asm 2: mov  <a3=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 18
# asm 1: shr  $18,<t0=int64#3
# asm 2: shr  $18,<t0=%rdx
shr  $18,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS7[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS7=stack256#9
# asm 2: movq <t0=%rdx,<stack_FVGS7=400(%rsp)
movq %rdx,400(%rsp)

# qhasm: a4 = stack_FVGS23[2]
# asm 1: movq <stack_FVGS23=stack256#25,>a4=int64#3
# asm 2: movq <stack_FVGS23=912(%rsp),>a4=%rdx
movq 912(%rsp),%rdx

# qhasm: a3 = (a4 a3) >> 48
# asm 1: shrd $48,<a4=int64#3,<a3=int64#4
# asm 2: shrd $48,<a4=%rdx,<a3=%rcx
shrd $48,%rdx,%rcx

# qhasm: a3 &= 1073741823
# asm 1: and  $1073741823,<a3=int64#4
# asm 2: and  $1073741823,<a3=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS8[2] = a3
# asm 1: movq <a3=int64#4,<stack_FVGS8=stack256#10
# asm 2: movq <a3=%rcx,<stack_FVGS8=432(%rsp)
movq %rcx,432(%rsp)

# qhasm: t0 = a4
# asm 1: mov  <a4=int64#3,>t0=int64#4
# asm 2: mov  <a4=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 14
# asm 1: shr  $14,<t0=int64#4
# asm 2: shr  $14,<t0=%rcx
shr  $14,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS9[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS9=stack256#11
# asm 2: movq <t0=%rcx,<stack_FVGS9=464(%rsp)
movq %rcx,464(%rsp)

# qhasm: a5 = stack_FVGS24[2]
# asm 1: movq <stack_FVGS24=stack256#26,>a5=int64#4
# asm 2: movq <stack_FVGS24=944(%rsp),>a5=%rcx
movq 944(%rsp),%rcx

# qhasm: a4 = (a5 a4) >> 44
# asm 1: shrd $44,<a5=int64#4,<a4=int64#3
# asm 2: shrd $44,<a5=%rcx,<a4=%rdx
shrd $44,%rcx,%rdx

# qhasm: a4 &= 1073741823
# asm 1: and  $1073741823,<a4=int64#3
# asm 2: and  $1073741823,<a4=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS10[2] = a4
# asm 1: movq <a4=int64#3,<stack_FVGS10=stack256#12
# asm 2: movq <a4=%rdx,<stack_FVGS10=496(%rsp)
movq %rdx,496(%rsp)

# qhasm: t0 = a5
# asm 1: mov  <a5=int64#4,>t0=int64#3
# asm 2: mov  <a5=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 10
# asm 1: shr  $10,<t0=int64#3
# asm 2: shr  $10,<t0=%rdx
shr  $10,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS11[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS11=stack256#13
# asm 2: movq <t0=%rdx,<stack_FVGS11=528(%rsp)
movq %rdx,528(%rsp)

# qhasm: a6 = stack_FVGS25[2]
# asm 1: movq <stack_FVGS25=stack256#27,>a6=int64#3
# asm 2: movq <stack_FVGS25=976(%rsp),>a6=%rdx
movq 976(%rsp),%rdx

# qhasm: a5 = (a6 a5) >> 40
# asm 1: shrd $40,<a6=int64#3,<a5=int64#4
# asm 2: shrd $40,<a6=%rdx,<a5=%rcx
shrd $40,%rdx,%rcx

# qhasm: a5 &= 1073741823
# asm 1: and  $1073741823,<a5=int64#4
# asm 2: and  $1073741823,<a5=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS12[2] = a5
# asm 1: movq <a5=int64#4,<stack_FVGS12=stack256#14
# asm 2: movq <a5=%rcx,<stack_FVGS12=560(%rsp)
movq %rcx,560(%rsp)

# qhasm: t0 = a6
# asm 1: mov  <a6=int64#3,>t0=int64#4
# asm 2: mov  <a6=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 6
# asm 1: shr  $6,<t0=int64#4
# asm 2: shr  $6,<t0=%rcx
shr  $6,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS13[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS13=stack256#15
# asm 2: movq <t0=%rcx,<stack_FVGS13=592(%rsp)
movq %rcx,592(%rsp)

# qhasm: a7 = stack_FVGS26[2]
# asm 1: movq <stack_FVGS26=stack256#28,>a7=int64#4
# asm 2: movq <stack_FVGS26=1008(%rsp),>a7=%rcx
movq 1008(%rsp),%rcx

# qhasm: a6 = (a7 a6) >> 36
# asm 1: shrd $36,<a7=int64#4,<a6=int64#3
# asm 2: shrd $36,<a7=%rcx,<a6=%rdx
shrd $36,%rcx,%rdx

# qhasm: a6 &= 1073741823
# asm 1: and  $1073741823,<a6=int64#3
# asm 2: and  $1073741823,<a6=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS14[2] = a6
# asm 1: movq <a6=int64#3,<stack_FVGS14=stack256#16
# asm 2: movq <a6=%rdx,<stack_FVGS14=624(%rsp)
movq %rdx,624(%rsp)

# qhasm: t0 = a7
# asm 1: mov  <a7=int64#4,>t0=int64#3
# asm 2: mov  <a7=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 2
# asm 1: shr  $2,<t0=int64#3
# asm 2: shr  $2,<t0=%rdx
shr  $2,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS15[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS15=stack256#17
# asm 2: movq <t0=%rdx,<stack_FVGS15=656(%rsp)
movq %rdx,656(%rsp)

# qhasm: t0 = a7
# asm 1: mov  <a7=int64#4,>t0=int64#3
# asm 2: mov  <a7=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 32
# asm 1: shr  $32,<t0=int64#3
# asm 2: shr  $32,<t0=%rdx
shr  $32,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS16[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS16=stack256#18
# asm 2: movq <t0=%rdx,<stack_FVGS16=688(%rsp)
movq %rdx,688(%rsp)

# qhasm: a8 = stack_FVGS27[2]
# asm 1: movq <stack_FVGS27=stack256#29,>a8=int64#3
# asm 2: movq <stack_FVGS27=1040(%rsp),>a8=%rdx
movq 1040(%rsp),%rdx

# qhasm: a7 = (a8 a7) >> 62
# asm 1: shrd $62,<a8=int64#3,<a7=int64#4
# asm 2: shrd $62,<a8=%rdx,<a7=%rcx
shrd $62,%rdx,%rcx

# qhasm: a7 &= 1073741823
# asm 1: and  $1073741823,<a7=int64#4
# asm 2: and  $1073741823,<a7=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS17[2] = a7
# asm 1: movq <a7=int64#4,<stack_FVGS17=stack256#19
# asm 2: movq <a7=%rcx,<stack_FVGS17=720(%rsp)
movq %rcx,720(%rsp)

# qhasm: t0 = a8
# asm 1: mov  <a8=int64#3,>t0=int64#4
# asm 2: mov  <a8=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 28
# asm 1: shr  $28,<t0=int64#4
# asm 2: shr  $28,<t0=%rcx
shr  $28,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS18[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS18=stack256#20
# asm 2: movq <t0=%rcx,<stack_FVGS18=752(%rsp)
movq %rcx,752(%rsp)

# qhasm: a9 = stack_FVGS28[2]
# asm 1: movq <stack_FVGS28=stack256#30,>a9=int64#4
# asm 2: movq <stack_FVGS28=1072(%rsp),>a9=%rcx
movq 1072(%rsp),%rcx

# qhasm: a8 = (a9 a8) >> 58
# asm 1: shrd $58,<a9=int64#4,<a8=int64#3
# asm 2: shrd $58,<a9=%rcx,<a8=%rdx
shrd $58,%rcx,%rdx

# qhasm: a8 &= 1073741823
# asm 1: and  $1073741823,<a8=int64#3
# asm 2: and  $1073741823,<a8=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS19[2] = a8
# asm 1: movq <a8=int64#3,<stack_FVGS19=stack256#21
# asm 2: movq <a8=%rdx,<stack_FVGS19=784(%rsp)
movq %rdx,784(%rsp)

# qhasm: t0 = a9
# asm 1: mov  <a9=int64#4,>t0=int64#3
# asm 2: mov  <a9=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 24
# asm 1: shr  $24,<t0=int64#3
# asm 2: shr  $24,<t0=%rdx
shr  $24,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS20[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS20=stack256#22
# asm 2: movq <t0=%rdx,<stack_FVGS20=816(%rsp)
movq %rdx,816(%rsp)

# qhasm: a10 = stack_FVGS29[2]
# asm 1: movq <stack_FVGS29=stack256#31,>a10=int64#3
# asm 2: movq <stack_FVGS29=1104(%rsp),>a10=%rdx
movq 1104(%rsp),%rdx

# qhasm: a9 = (a10 a9) >> 54
# asm 1: shrd $54,<a10=int64#3,<a9=int64#4
# asm 2: shrd $54,<a10=%rdx,<a9=%rcx
shrd $54,%rdx,%rcx

# qhasm: a9 &= 1073741823
# asm 1: and  $1073741823,<a9=int64#4
# asm 2: and  $1073741823,<a9=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS21[2] = a9
# asm 1: movq <a9=int64#4,<stack_FVGS21=stack256#23
# asm 2: movq <a9=%rcx,<stack_FVGS21=848(%rsp)
movq %rcx,848(%rsp)

# qhasm: t0 = a10
# asm 1: mov  <a10=int64#3,>t0=int64#4
# asm 2: mov  <a10=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 20
# asm 1: shr  $20,<t0=int64#4
# asm 2: shr  $20,<t0=%rcx
shr  $20,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS22[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS22=stack256#24
# asm 2: movq <t0=%rcx,<stack_FVGS22=880(%rsp)
movq %rcx,880(%rsp)

# qhasm: a11 = stack_FVGS30[2]
# asm 1: movq <stack_FVGS30=stack256#32,>a11=int64#4
# asm 2: movq <stack_FVGS30=1136(%rsp),>a11=%rcx
movq 1136(%rsp),%rcx

# qhasm: a10 = (a11 a10) >> 50
# asm 1: shrd $50,<a11=int64#4,<a10=int64#3
# asm 2: shrd $50,<a11=%rcx,<a10=%rdx
shrd $50,%rcx,%rdx

# qhasm: a10 &= 1073741823
# asm 1: and  $1073741823,<a10=int64#3
# asm 2: and  $1073741823,<a10=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS23[2] = a10
# asm 1: movq <a10=int64#3,<stack_FVGS23=stack256#25
# asm 2: movq <a10=%rdx,<stack_FVGS23=912(%rsp)
movq %rdx,912(%rsp)

# qhasm: t0 = a11
# asm 1: mov  <a11=int64#4,>t0=int64#3
# asm 2: mov  <a11=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 16
# asm 1: shr  $16,<t0=int64#3
# asm 2: shr  $16,<t0=%rdx
shr  $16,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS24[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS24=stack256#26
# asm 2: movq <t0=%rdx,<stack_FVGS24=944(%rsp)
movq %rdx,944(%rsp)

# qhasm: a12 = stack_FVGS31[2]
# asm 1: movq <stack_FVGS31=stack256#33,>a12=int64#3
# asm 2: movq <stack_FVGS31=1168(%rsp),>a12=%rdx
movq 1168(%rsp),%rdx

# qhasm: a11 = (a12 a11) >> 46
# asm 1: shrd $46,<a12=int64#3,<a11=int64#4
# asm 2: shrd $46,<a12=%rdx,<a11=%rcx
shrd $46,%rdx,%rcx

# qhasm: a11 &= 1073741823
# asm 1: and  $1073741823,<a11=int64#4
# asm 2: and  $1073741823,<a11=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS25[2] = a11
# asm 1: movq <a11=int64#4,<stack_FVGS25=stack256#27
# asm 2: movq <a11=%rcx,<stack_FVGS25=976(%rsp)
movq %rcx,976(%rsp)

# qhasm: t0 = a12
# asm 1: mov  <a12=int64#3,>t0=int64#4
# asm 2: mov  <a12=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 12
# asm 1: shr  $12,<t0=int64#4
# asm 2: shr  $12,<t0=%rcx
shr  $12,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS26[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS26=stack256#28
# asm 2: movq <t0=%rcx,<stack_FVGS26=1008(%rsp)
movq %rcx,1008(%rsp)

# qhasm: a13 = stack_FVGS32[2]
# asm 1: movq <stack_FVGS32=stack256#34,>a13=int64#4
# asm 2: movq <stack_FVGS32=1200(%rsp),>a13=%rcx
movq 1200(%rsp),%rcx

# qhasm: a12 = (a13 a12) >> 42
# asm 1: shrd $42,<a13=int64#4,<a12=int64#3
# asm 2: shrd $42,<a13=%rcx,<a12=%rdx
shrd $42,%rcx,%rdx

# qhasm: a12 &= 1073741823
# asm 1: and  $1073741823,<a12=int64#3
# asm 2: and  $1073741823,<a12=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS27[2] = a12
# asm 1: movq <a12=int64#3,<stack_FVGS27=stack256#29
# asm 2: movq <a12=%rdx,<stack_FVGS27=1040(%rsp)
movq %rdx,1040(%rsp)

# qhasm: t0 = a13
# asm 1: mov  <a13=int64#4,>t0=int64#3
# asm 2: mov  <a13=%rcx,>t0=%rdx
mov  %rcx,%rdx

# qhasm: (uint64) t0 >>= 8
# asm 1: shr  $8,<t0=int64#3
# asm 2: shr  $8,<t0=%rdx
shr  $8,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS28[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS28=stack256#30
# asm 2: movq <t0=%rdx,<stack_FVGS28=1072(%rsp)
movq %rdx,1072(%rsp)

# qhasm: a14 = stack_FVGS33[2]
# asm 1: movq <stack_FVGS33=stack256#35,>a14=int64#3
# asm 2: movq <stack_FVGS33=1232(%rsp),>a14=%rdx
movq 1232(%rsp),%rdx

# qhasm: a13 = (a14 a13) >> 38
# asm 1: shrd $38,<a14=int64#3,<a13=int64#4
# asm 2: shrd $38,<a14=%rdx,<a13=%rcx
shrd $38,%rdx,%rcx

# qhasm: a13 &= 1073741823
# asm 1: and  $1073741823,<a13=int64#4
# asm 2: and  $1073741823,<a13=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS29[2] = a13
# asm 1: movq <a13=int64#4,<stack_FVGS29=stack256#31
# asm 2: movq <a13=%rcx,<stack_FVGS29=1104(%rsp)
movq %rcx,1104(%rsp)

# qhasm: t0 = a14
# asm 1: mov  <a14=int64#3,>t0=int64#4
# asm 2: mov  <a14=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 4
# asm 1: shr  $4,<t0=int64#4
# asm 2: shr  $4,<t0=%rcx
shr  $4,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS30[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS30=stack256#32
# asm 2: movq <t0=%rcx,<stack_FVGS30=1136(%rsp)
movq %rcx,1136(%rsp)

# qhasm: t0 = a14
# asm 1: mov  <a14=int64#3,>t0=int64#3
# asm 2: mov  <a14=%rdx,>t0=%rdx
mov  %rdx,%rdx

# qhasm: (uint64) t0 >>= 34
# asm 1: shr  $34,<t0=int64#3
# asm 2: shr  $34,<t0=%rdx
shr  $34,%rdx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#3
# asm 2: and  $1073741823,<t0=%rdx
and  $1073741823,%rdx

# qhasm: inplace stack_FVGS31[2] = t0
# asm 1: movq <t0=int64#3,<stack_FVGS31=stack256#33
# asm 2: movq <t0=%rdx,<stack_FVGS31=1168(%rsp)
movq %rdx,1168(%rsp)

# qhasm: a15 = stack_FVGS34[2]
# asm 1: movq <stack_FVGS34=stack256#36,>a15=int64#3
# asm 2: movq <stack_FVGS34=1264(%rsp),>a15=%rdx
movq 1264(%rsp),%rdx

# qhasm: t0 = a15
# asm 1: mov  <a15=int64#3,>t0=int64#4
# asm 2: mov  <a15=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS32[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS32=stack256#34
# asm 2: movq <t0=%rcx,<stack_FVGS32=1200(%rsp)
movq %rcx,1200(%rsp)

# qhasm: t0 = a15
# asm 1: mov  <a15=int64#3,>t0=int64#4
# asm 2: mov  <a15=%rdx,>t0=%rcx
mov  %rdx,%rcx

# qhasm: (uint64) t0 >>= 30
# asm 1: shr  $30,<t0=int64#4
# asm 2: shr  $30,<t0=%rcx
shr  $30,%rcx

# qhasm: t0 &= 1073741823
# asm 1: and  $1073741823,<t0=int64#4
# asm 2: and  $1073741823,<t0=%rcx
and  $1073741823,%rcx

# qhasm: inplace stack_FVGS33[2] = t0
# asm 1: movq <t0=int64#4,<stack_FVGS33=stack256#35
# asm 2: movq <t0=%rcx,<stack_FVGS33=1232(%rsp)
movq %rcx,1232(%rsp)

# qhasm: (uint64) a15 >>= 60
# asm 1: shr  $60,<a15=int64#3
# asm 2: shr  $60,<a15=%rdx
shr  $60,%rdx

# qhasm: inplace stack_FVGS34[2] = a15
# asm 1: movq <a15=int64#3,<stack_FVGS34=stack256#36
# asm 2: movq <a15=%rdx,<stack_FVGS34=1264(%rsp)
movq %rdx,1264(%rsp)

# qhasm: f = stack_FVGS0[0]
# asm 1: movq <stack_FVGS0=stack256#2,>f=int64#4
# asm 2: movq <stack_FVGS0=160(%rsp),>f=%rcx
movq 160(%rsp),%rcx

# qhasm: f0 = stack_FVGS1[0]
# asm 1: movq <stack_FVGS1=stack256#3,>f0=int64#5
# asm 2: movq <stack_FVGS1=192(%rsp),>f0=%r8
movq 192(%rsp),%r8

# qhasm: f0 <<= 30
# asm 1: shl  $30,<f0=int64#5
# asm 2: shl  $30,<f0=%r8
shl  $30,%r8

# qhasm: f += f0 
# asm 1: add  <f0=int64#5,<f=int64#4
# asm 2: add  <f0=%r8,<f=%rcx
add  %r8,%rcx

# qhasm:                   m = 0
# asm 1: xor  >m=int64#6,>m=int64#6
# asm 2: xor  >m=%r9,>m=%r9
xor  %r9,%r9

# qhasm:                   z = -1
# asm 1: mov  $-1,>z=int64#3
# asm 2: mov  $-1,>z=%rdx
mov  $-1,%rdx

# qhasm: inplace stack_m1[0] = m
# asm 1: movq <m=int64#6,<stack_m1=stack256#1
# asm 2: movq <m=%r9,<stack_m1=128(%rsp)
movq %r9,128(%rsp)

# qhasm: inplace stack_m1[1] = z
# asm 1: movq <z=int64#3,<stack_m1=stack256#1
# asm 2: movq <z=%rdx,<stack_m1=136(%rsp)
movq %rdx,136(%rsp)

# qhasm:              _m2p20 = -1048576
# asm 1: mov  $-1048576,>_m2p20=int64#8
# asm 2: mov  $-1048576,>_m2p20=%r10
mov  $-1048576,%r10

# qhasm:         stack_m2p20 = _m2p20
# asm 1: movq <_m2p20=int64#8,>stack_m2p20=stack64#10
# asm 2: movq <_m2p20=%r10,>stack_m2p20=72(%rsp)
movq %r10,72(%rsp)

# qhasm:               _2p20 = 1048576
# asm 1: mov  $1048576,>_2p20=int64#3
# asm 2: mov  $1048576,>_2p20=%rdx
mov  $1048576,%rdx

# qhasm:          stack_2p20 = _2p20
# asm 1: movq <_2p20=int64#3,>stack_2p20=stack64#11
# asm 2: movq <_2p20=%rdx,>stack_2p20=80(%rsp)
movq %rdx,80(%rsp)

# qhasm:              _m2p41 = -2199023255552
# asm 1: mov  $-2199023255552,>_m2p41=int64#3
# asm 2: mov  $-2199023255552,>_m2p41=%rdx
mov  $-2199023255552,%rdx

# qhasm:         stack_m2p41 = _m2p41
# asm 1: movq <_m2p41=int64#3,>stack_m2p41=stack64#12
# asm 2: movq <_m2p41=%rdx,>stack_m2p41=88(%rsp)
movq %rdx,88(%rsp)

# qhasm:              _m2p62 = -4611686018427387904
# asm 1: mov  $-4611686018427387904,>_m2p62=int64#3
# asm 2: mov  $-4611686018427387904,>_m2p62=%rdx
mov  $-4611686018427387904,%rdx

# qhasm:         stack_m2p62 = _m2p62
# asm 1: movq <_m2p62=int64#3,>stack_m2p62=stack64#13
# asm 2: movq <_m2p62=%rdx,>stack_m2p62=96(%rsp)
movq %rdx,96(%rsp)

# qhasm:          _2p20a2p41 = 2199024304128
# asm 1: mov  $2199024304128,>_2p20a2p41=int64#3
# asm 2: mov  $2199024304128,>_2p20a2p41=%rdx
mov  $2199024304128,%rdx

# qhasm:     stack_2p20a2p41 = _2p20a2p41
# asm 1: movq <_2p20a2p41=int64#3,>stack_2p20a2p41=stack64#14
# asm 2: movq <_2p20a2p41=%rdx,>stack_2p20a2p41=104(%rsp)
movq %rdx,104(%rsp)

# qhasm:           _2p30m1x4 = mem256[ table +   0 ]
# asm 1: vmovupd   0(<table=int64#2),>_2p30m1x4=reg256#1
# asm 2: vmovupd   0(<table=%rsi),>_2p30m1x4=%ymm0
vmovupd   0(%rsi),%ymm0

# qhasm:      stack_2p30m1x4 = _2p30m1x4
# asm 1: vmovapd <_2p30m1x4=reg256#1,>stack_2p30m1x4=stack256#72
# asm 2: vmovapd <_2p30m1x4=%ymm0,>stack_2p30m1x4=2400(%rsp)
vmovapd %ymm0,2400(%rsp)

# qhasm:             _2p33x4 = mem256[ table +  32 ]
# asm 1: vmovupd   32(<table=int64#2),>_2p33x4=reg256#1
# asm 2: vmovupd   32(<table=%rsi),>_2p33x4=%ymm0
vmovupd   32(%rsi),%ymm0

# qhasm:        stack_2p33x4 = _2p33x4
# asm 1: vmovapd <_2p33x4=reg256#1,>stack_2p33x4=stack256#73
# asm 2: vmovapd <_2p33x4=%ymm0,>stack_2p33x4=2432(%rsp)
vmovapd %ymm0,2432(%rsp)

# qhasm:             _2p63x4 = mem256[ table +  64 ]
# asm 1: vmovupd   64(<table=int64#2),>_2p63x4=reg256#1
# asm 2: vmovupd   64(<table=%rsi),>_2p63x4=%ymm0
vmovupd   64(%rsi),%ymm0

# qhasm:        stack_2p63x4 = _2p63x4
# asm 1: vmovapd <_2p63x4=reg256#1,>stack_2p63x4=stack256#74
# asm 2: vmovapd <_2p63x4=%ymm0,>stack_2p63x4=2464(%rsp)
vmovapd %ymm0,2464(%rsp)

# qhasm:        _2p63m2p33x4 = mem256[ table +  96 ]
# asm 1: vmovupd   96(<table=int64#2),>_2p63m2p33x4=reg256#1
# asm 2: vmovupd   96(<table=%rsi),>_2p63m2p33x4=%ymm0
vmovupd   96(%rsi),%ymm0

# qhasm:   stack_2p63m2p33x4 = _2p63m2p33x4
# asm 1: vmovapd <_2p63m2p33x4=reg256#1,>stack_2p63m2p33x4=stack256#75
# asm 2: vmovapd <_2p63m2p33x4=%ymm0,>stack_2p63m2p33x4=2496(%rsp)
vmovapd %ymm0,2496(%rsp)

# qhasm:             _2p29x4 = mem256[ table + 128 ]
# asm 1: vmovupd   128(<table=int64#2),>_2p29x4=reg256#1
# asm 2: vmovupd   128(<table=%rsi),>_2p29x4=%ymm0
vmovupd   128(%rsi),%ymm0

# qhasm:        stack_2p29x4 = _2p29x4
# asm 1: vmovapd <_2p29x4=reg256#1,>stack_2p29x4=stack256#76
# asm 2: vmovapd <_2p29x4=%ymm0,>stack_2p29x4=2528(%rsp)
vmovapd %ymm0,2528(%rsp)

# qhasm:           _prime0x4 = mem256[ table + 160 ]
# asm 1: vmovupd   160(<table=int64#2),>_prime0x4=reg256#1
# asm 2: vmovupd   160(<table=%rsi),>_prime0x4=%ymm0
vmovupd   160(%rsi),%ymm0

# qhasm:      stack_prime0x4 = _prime0x4
# asm 1: vmovapd <_prime0x4=reg256#1,>stack_prime0x4=stack256#77
# asm 2: vmovapd <_prime0x4=%ymm0,>stack_prime0x4=2560(%rsp)
vmovapd %ymm0,2560(%rsp)

# qhasm:           _prime1x4 = mem256[ table + 192 ]
# asm 1: vmovupd   192(<table=int64#2),>_prime1x4=reg256#1
# asm 2: vmovupd   192(<table=%rsi),>_prime1x4=%ymm0
vmovupd   192(%rsi),%ymm0

# qhasm:      stack_prime1x4 = _prime1x4
# asm 1: vmovapd <_prime1x4=reg256#1,>stack_prime1x4=stack256#78
# asm 2: vmovapd <_prime1x4=%ymm0,>stack_prime1x4=2592(%rsp)
vmovapd %ymm0,2592(%rsp)

# qhasm:           _prime2x4 = mem256[ table + 224 ]
# asm 1: vmovupd   224(<table=int64#2),>_prime2x4=reg256#1
# asm 2: vmovupd   224(<table=%rsi),>_prime2x4=%ymm0
vmovupd   224(%rsi),%ymm0

# qhasm:      stack_prime2x4 = _prime2x4
# asm 1: vmovapd <_prime2x4=reg256#1,>stack_prime2x4=stack256#79
# asm 2: vmovapd <_prime2x4=%ymm0,>stack_prime2x4=2624(%rsp)
vmovapd %ymm0,2624(%rsp)

# qhasm: i = 40
# asm 1: mov  $40,>i=int64#2
# asm 2: mov  $40,>i=%rsi
mov  $40,%rsi

# qhasm: u = 1152921504606846976
# asm 1: mov  $1152921504606846976,>u=int64#9
# asm 2: mov  $1152921504606846976,>u=%r11
mov  $1152921504606846976,%r11

# qhasm: v = 0
# asm 1: xor  >v=int64#10,>v=int64#10
# asm 2: xor  >v=%r12,>v=%r12
xor  %r12,%r12

# qhasm: s = u
# asm 1: mov  <u=int64#9,>s=int64#11
# asm 2: mov  <u=%r11,>s=%r13
mov  %r11,%r13

# qhasm: r = 0
# asm 1: xor  >r=int64#12,>r=int64#12
# asm 2: xor  >r=%r14,>r=%r14
xor  %r14,%r14

# qhasm: nop
nop

# qhasm: nop
nop

# qhasm: bigloop:
._bigloop:

# qhasm:       rax = g
# asm 1: mov  <g=int64#1,>rax=int64#7
# asm 2: mov  <g=%rdi,>rax=%rax
mov  %rdi,%rax

# qhasm:       (int128) rdx rax = rax * s
# asm 1: imul <s=int64#11
# asm 2: imul <s=%r13
imul %r13

# qhasm:       t2 = rax
# asm 1: mov  <rax=int64#7,>t2=int64#14
# asm 2: mov  <rax=%rax,>t2=%rbx
mov  %rax,%rbx

# qhasm:       t1 = rdx
# asm 1: mov  <rdx=int64#3,>t1=int64#15
# asm 2: mov  <rdx=%rdx,>t1=%rbp
mov  %rdx,%rbp

# qhasm:       rax = f
# asm 1: mov  <f=int64#4,>rax=int64#7
# asm 2: mov  <f=%rcx,>rax=%rax
mov  %rcx,%rax

# qhasm:       (int128) rdx rax = rax * r
# asm 1: imul <r=int64#12
# asm 2: imul <r=%r14
imul %r14

# qhasm:       carry? t2 += rax
# asm 1: add  <rax=int64#7,<t2=int64#14
# asm 2: add  <rax=%rax,<t2=%rbx
add  %rax,%rbx

# qhasm:              t1 += rdx + carry
# asm 1: adc <rdx=int64#3,<t1=int64#15
# asm 2: adc <rdx=%rdx,<t1=%rbp
adc %rdx,%rbp

# qhasm:       t2 = (t1 t2) >> 60	 
# asm 1: shrd $60,<t1=int64#15,<t2=int64#14
# asm 2: shrd $60,<t1=%rbp,<t2=%rbx
shrd $60,%rbp,%rbx

# qhasm:       rax = f
# asm 1: mov  <f=int64#4,>rax=int64#7
# asm 2: mov  <f=%rcx,>rax=%rax
mov  %rcx,%rax

# qhasm:       (int128) rdx rax = rax * u
# asm 1: imul <u=int64#9
# asm 2: imul <u=%r11
imul %r11

# qhasm:       f = rax
# asm 1: mov  <rax=int64#7,>f=int64#4
# asm 2: mov  <rax=%rax,>f=%rcx
mov  %rax,%rcx

# qhasm:       t0 = rdx
# asm 1: mov  <rdx=int64#3,>t0=int64#15
# asm 2: mov  <rdx=%rdx,>t0=%rbp
mov  %rdx,%rbp

# qhasm:       rax = g
# asm 1: mov  <g=int64#1,>rax=int64#7
# asm 2: mov  <g=%rdi,>rax=%rax
mov  %rdi,%rax

# qhasm:       (int128) rdx rax = rax * v
# asm 1: imul <v=int64#10
# asm 2: imul <v=%r12
imul %r12

# qhasm:       carry? f += rax
# asm 1: add  <rax=int64#7,<f=int64#4
# asm 2: add  <rax=%rax,<f=%rcx
add  %rax,%rcx

# qhasm:              t0 += rdx + carry
# asm 1: adc <rdx=int64#3,<t0=int64#15
# asm 2: adc <rdx=%rdx,<t0=%rbp
adc %rdx,%rbp

# qhasm:       f = (t0 f) >> 60
# asm 1: shrd $60,<t0=int64#15,<f=int64#4
# asm 2: shrd $60,<t0=%rbp,<f=%rcx
shrd $60,%rbp,%rcx

# qhasm: new vvrr

# qhasm: vvrr = v,vvrr[1],0,0
# asm 1: vpinsrq $0x0,<v=int64#10,<vvrr=reg256#1%128,<vvrr=reg256#1%128
# asm 2: vpinsrq $0x0,<v=%r12,<vvrr=%xmm0,<vvrr=%xmm0
vpinsrq $0x0,%r12,%xmm0,%xmm0

# qhasm: vvrr = vvrr[0],r,0,0
# asm 1: vpinsrq $0x1,<r=int64#12,<vvrr=reg256#1%128,<vvrr=reg256#1%128
# asm 2: vpinsrq $0x1,<r=%r14,<vvrr=%xmm0,<vvrr=%xmm0
vpinsrq $0x1,%r14,%xmm0,%xmm0

# qhasm:       v *= g0
# asm 1: imul  <g0=int64#13,<v=int64#10
# asm 2: imul  <g0=%r15,<v=%r12
imul  %r15,%r12

# qhasm:       g0 *= s
# asm 1: imul  <s=int64#11,<g0=int64#13
# asm 2: imul  <s=%r13,<g0=%r15
imul  %r13,%r15

# qhasm:       r *= f0
# asm 1: imul  <f0=int64#5,<r=int64#12
# asm 2: imul  <f0=%r8,<r=%r14
imul  %r8,%r14

# qhasm:       f0 *= u
# asm 1: imul  <u=int64#9,<f0=int64#5
# asm 2: imul  <u=%r11,<f0=%r8
imul  %r11,%r8

# qhasm:       f0 += v
# asm 1: add  <v=int64#10,<f0=int64#5
# asm 2: add  <v=%r12,<f0=%r8
add  %r12,%r8

# qhasm:       g0 += r
# asm 1: add  <r=int64#12,<g0=int64#13
# asm 2: add  <r=%r14,<g0=%r15
add  %r14,%r15

# qhasm:       f += f0
# asm 1: add  <f0=int64#5,<f=int64#4
# asm 2: add  <f0=%r8,<f=%rcx
add  %r8,%rcx

# qhasm:       g = t2+g0
# asm 1: lea  (<t2=int64#14,<g0=int64#13),>g=int64#1
# asm 2: lea  (<t2=%rbx,<g0=%r15),>g=%rdi
lea  (%rbx,%r15),%rdi

# qhasm: loop20_init:
._loop20_init:

# qhasm:   fuv = f & ~ _m2p20
# asm 1: andn  <f=int64#4,<_m2p20=int64#8,>fuv=int64#3
# asm 2: andn  <f=%rcx,<_m2p20=%r10,>fuv=%rdx
andn  %rcx,%r10,%rdx

# qhasm: FVGS0 = stack_FVGS0
# asm 1: vmovapd <stack_FVGS0=stack256#2,>FVGS0=reg256#2
# asm 2: vmovapd <stack_FVGS0=160(%rsp),>FVGS0=%ymm1
vmovapd 160(%rsp),%ymm1

# qhasm: new uuss

# qhasm: uuss = u,uuss[1],0,0
# asm 1: vpinsrq $0x0,<u=int64#9,<uuss=reg256#3%128,<uuss=reg256#3%128
# asm 2: vpinsrq $0x0,<u=%r11,<uuss=%xmm2,<uuss=%xmm2
vpinsrq $0x0,%r11,%xmm2,%xmm2

# qhasm: uuss = uuss[0],s,0,0
# asm 1: vpinsrq $0x1,<s=int64#11,<uuss=reg256#3%128,<uuss=reg256#3%128
# asm 2: vpinsrq $0x1,<s=%r13,<uuss=%xmm2,<uuss=%xmm2
vpinsrq $0x1,%r13,%xmm2,%xmm2

# qhasm: GSFV0 = FVGS0[1,0]
# asm 1: vpermq $0x4e,<FVGS0=reg256#2,>GSFV0=reg256#4
# asm 2: vpermq $0x4e,<FVGS0=%ymm1,>GSFV0=%ymm3
vpermq $0x4e,%ymm1,%ymm3

# qhasm:   grs = g & ~ _m2p20
# asm 1: andn  <g=int64#1,<_m2p20=int64#8,>grs=int64#5
# asm 2: andn  <g=%rdi,<_m2p20=%r10,>grs=%r8
andn  %rdi,%r10,%r8

# qhasm: uuss = uuss[0,0,1,1]
# asm 1: vpermq $0x50,<uuss=reg256#3,>uuss=reg256#3
# asm 2: vpermq $0x50,<uuss=%ymm2,>uuss=%ymm2
vpermq $0x50,%ymm2,%ymm2

# qhasm: vvrr = vvrr[0,0,1,1]
# asm 1: vpermq $0x50,<vvrr=reg256#1,>vvrr=reg256#1
# asm 2: vpermq $0x50,<vvrr=%ymm0,>vvrr=%ymm0
vpermq $0x50,%ymm0,%ymm0

# qhasm:   fuv += stack_m2p41
# asm 1: addq <stack_m2p41=stack64#12,<fuv=int64#3
# asm 2: addq <stack_m2p41=88(%rsp),<fuv=%rdx
addq 88(%rsp),%rdx

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: uuss0 = uuss & _2p30m1x4
# asm 1: vpand <uuss=reg256#3,<_2p30m1x4=reg256#5,>uuss0=reg256#6
# asm 2: vpand <uuss=%ymm2,<_2p30m1x4=%ymm4,>uuss0=%ymm5
vpand %ymm2,%ymm4,%ymm5

# qhasm:   grs += stack_m2p62
# asm 1: addq <stack_m2p62=stack64#13,<grs=int64#5
# asm 2: addq <stack_m2p62=96(%rsp),<grs=%r8
addq 96(%rsp),%r8

# qhasm: vvrr0 = vvrr & _2p30m1x4 
# asm 1: vpand <vvrr=reg256#1,<_2p30m1x4=reg256#5,>vvrr0=reg256#7
# asm 2: vpand <vvrr=%ymm0,<_2p30m1x4=%ymm4,>vvrr0=%ymm6
vpand %ymm0,%ymm4,%ymm6

# qhasm: _2p63x4 = stack_2p63x4
# asm 1: vmovapd <stack_2p63x4=stack256#74,>_2p63x4=reg256#8
# asm 2: vmovapd <stack_2p63x4=2464(%rsp),>_2p63x4=%ymm7
vmovapd 2464(%rsp),%ymm7

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: uuss1 = uuss ^ _2p63x4
# asm 1: vpxor <uuss=reg256#3,<_2p63x4=reg256#8,>uuss1=reg256#3
# asm 2: vpxor <uuss=%ymm2,<_2p63x4=%ymm7,>uuss1=%ymm2
vpxor %ymm2,%ymm7,%ymm2

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: vvrr1 = vvrr ^ _2p63x4
# asm 1: vpxor <vvrr=reg256#1,<_2p63x4=reg256#8,>vvrr1=reg256#1
# asm 2: vpxor <vvrr=%ymm0,<_2p63x4=%ymm7,>vvrr1=%ymm0
vpxor %ymm0,%ymm7,%ymm0

# qhasm: 4x uuss1 unsigned>>= 30
# asm 1: vpsrlq $30,<uuss1=reg256#3,<uuss1=reg256#3
# asm 2: vpsrlq $30,<uuss1=%ymm2,<uuss1=%ymm2
vpsrlq $30,%ymm2,%ymm2

# qhasm: 4x vvrr1 unsigned>>= 30
# asm 1: vpsrlq $30,<vvrr1=reg256#1,<vvrr1=reg256#1
# asm 2: vpsrlq $30,<vvrr1=%ymm0,<vvrr1=%ymm0
vpsrlq $30,%ymm0,%ymm0

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: _2p33x4 = stack_2p33x4
# asm 1: vmovapd <stack_2p33x4=stack256#73,>_2p33x4=reg256#9
# asm 2: vmovapd <stack_2p33x4=2432(%rsp),>_2p33x4=%ymm8
vmovapd 2432(%rsp),%ymm8

# qhasm: 4x uuss1 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#9,<uuss1=reg256#3,<uuss1=reg256#3
# asm 2: vpsubq <_2p33x4=%ymm8,<uuss1=%ymm2,<uuss1=%ymm2
vpsubq %ymm8,%ymm2,%ymm2

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x vvrr1 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#9,<vvrr1=reg256#1,<vvrr1=reg256#1
# asm 2: vpsubq <_2p33x4=%ymm8,<vvrr1=%ymm0,<vvrr1=%ymm0
vpsubq %ymm8,%ymm0,%ymm0

# qhasm: 4x ta = int32 uuss0 * int32 FVGS0
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS0=reg256#2,>ta=reg256#9
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS0=%ymm1,>ta=%ymm8
vpmuldq %ymm5,%ymm1,%ymm8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV0
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV0=reg256#4,>tb=reg256#10
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV0=%ymm3,>tb=%ymm9
vpmuldq %ymm6,%ymm3,%ymm9

# qhasm: 4x out0 = ta + tb
# asm 1: vpaddq <tb=reg256#10,<ta=reg256#9,>out0=reg256#9
# asm 2: vpaddq <tb=%ymm9,<ta=%ymm8,>out0=%ymm8
vpaddq %ymm9,%ymm8,%ymm8

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: minvx4 = 4x stack_minv
# asm 1: vpbroadcastq <stack_minv=stack64#9,>minvx4=reg256#10
# asm 2: vpbroadcastq <stack_minv=64(%rsp),>minvx4=%ymm9
vpbroadcastq 64(%rsp),%ymm9

# qhasm: mod0 = stack_mod0
# asm 1: vmovapd <stack_mod0=stack256#37,>mod0=reg256#11
# asm 2: vmovapd <stack_mod0=1280(%rsp),>mod0=%ymm10
vmovapd 1280(%rsp),%ymm10

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x d0 = int32 minvx4 * int32 out0
# asm 1: vpmuldq <minvx4=reg256#10,<out0=reg256#9,>d0=reg256#12
# asm 2: vpmuldq <minvx4=%ymm9,<out0=%ymm8,>d0=%ymm11
vpmuldq %ymm9,%ymm8,%ymm11

# qhasm: d0 &= _2p30m1x4
# asm 1: vpand <d0=reg256#12,<_2p30m1x4=reg256#5,<d0=reg256#12
# asm 2: vpand <d0=%ymm11,<_2p30m1x4=%ymm4,<d0=%ymm11
vpand %ymm11,%ymm4,%ymm11

# qhasm: 4x ta = int32 mod0 * int32 d0
# asm 1: vpmuldq <mod0=reg256#11,<d0=reg256#12,>ta=reg256#13
# asm 2: vpmuldq <mod0=%ymm10,<d0=%ymm11,>ta=%ymm12
vpmuldq %ymm10,%ymm11,%ymm12

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out0 += ta
# asm 1: vpaddq <out0=reg256#9,<ta=reg256#13,<out0=reg256#9
# asm 2: vpaddq <out0=%ymm8,<ta=%ymm12,<out0=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x carryy = out0 +_2p63x4
# asm 1: vpaddq <_2p63x4=reg256#8,<out0=reg256#9,>carryy=reg256#8
# asm 2: vpaddq <_2p63x4=%ymm7,<out0=%ymm8,>carryy=%ymm7
vpaddq %ymm7,%ymm8,%ymm7

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#8,<carryy=reg256#8
# asm 2: vpsrlq $30,<carryy=%ymm7,<carryy=%ymm7
vpsrlq $30,%ymm7,%ymm7

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: FVGS1 = stack_FVGS1
# asm 1: vmovapd <stack_FVGS1=stack256#3,>FVGS1=reg256#9
# asm 2: vmovapd <stack_FVGS1=192(%rsp),>FVGS1=%ymm8
vmovapd 192(%rsp),%ymm8

# qhasm: GSFV1 = FVGS1[1,0]
# asm 1: vpermq $0x4e,<FVGS1=reg256#9,>GSFV1=reg256#13
# asm 2: vpermq $0x4e,<FVGS1=%ymm8,>GSFV1=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod1 = stack_mod1
# asm 1: vmovapd <stack_mod1=stack256#38,>mod1=reg256#14
# asm 2: vmovapd <stack_mod1=1312(%rsp),>mod1=%ymm13
vmovapd 1312(%rsp),%ymm13

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x ta = int32 uuss1 * int32 FVGS0
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS0=reg256#2,>ta=reg256#2
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS0=%ymm1,>ta=%ymm1
vpmuldq %ymm2,%ymm1,%ymm1

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV0
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV0=reg256#4,>tb=reg256#4
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV0=%ymm3,>tb=%ymm3
vpmuldq %ymm0,%ymm3,%ymm3

# qhasm: 4x out1plus = ta + tb
# asm 1: vpaddq <tb=reg256#4,<ta=reg256#2,>out1plus=reg256#2
# asm 2: vpaddq <tb=%ymm3,<ta=%ymm1,>out1plus=%ymm1
vpaddq %ymm3,%ymm1,%ymm1

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x ta = int32 uuss0 * int32 FVGS1
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS1=reg256#9,>ta=reg256#4
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS1=%ymm8,>ta=%ymm3
vpmuldq %ymm5,%ymm8,%ymm3

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV1
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV1=reg256#13,>tb=reg256#15
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV1=%ymm12,>tb=%ymm14
vpmuldq %ymm6,%ymm12,%ymm14

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x out1 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#4,>out1=reg256#4
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm3,>out1=%ymm3
vpaddq %ymm14,%ymm3,%ymm3

# qhasm: 4x out1 += out1plus
# asm 1: vpaddq <out1=reg256#4,<out1plus=reg256#2,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<out1plus=%ymm1,<out1=%ymm3
vpaddq %ymm3,%ymm1,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod1
# asm 1: vpmuldq <d0=reg256#12,<mod1=reg256#14,>ta=reg256#2
# asm 2: vpmuldq <d0=%ymm11,<mod1=%ymm13,>ta=%ymm1
vpmuldq %ymm11,%ymm13,%ymm1

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x ta += carryy
# asm 1: vpaddq <ta=reg256#2,<carryy=reg256#8,<ta=reg256#2
# asm 2: vpaddq <ta=%ymm1,<carryy=%ymm7,<ta=%ymm1
vpaddq %ymm1,%ymm7,%ymm1

# qhasm: 4x out1 += ta
# asm 1: vpaddq <out1=reg256#4,<ta=reg256#2,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<ta=%ymm1,<out1=%ymm3
vpaddq %ymm3,%ymm1,%ymm3

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x d1 = int32 minvx4 * int32 out1
# asm 1: vpmuldq <minvx4=reg256#10,<out1=reg256#4,>d1=reg256#2
# asm 2: vpmuldq <minvx4=%ymm9,<out1=%ymm3,>d1=%ymm1
vpmuldq %ymm9,%ymm3,%ymm1

# qhasm: d1 &= _2p30m1x4
# asm 1: vpand <d1=reg256#2,<_2p30m1x4=reg256#5,<d1=reg256#2
# asm 2: vpand <d1=%ymm1,<_2p30m1x4=%ymm4,<d1=%ymm1
vpand %ymm1,%ymm4,%ymm1

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x ta = int32 mod0 * int32 d1
# asm 1: vpmuldq <mod0=reg256#11,<d1=reg256#2,>ta=reg256#8
# asm 2: vpmuldq <mod0=%ymm10,<d1=%ymm1,>ta=%ymm7
vpmuldq %ymm10,%ymm1,%ymm7

# qhasm: 4x out1 += ta
# asm 1: vpaddq <out1=reg256#4,<ta=reg256#8,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<ta=%ymm7,<out1=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#8
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm7
vmovapd 2496(%rsp),%ymm7

# qhasm: 4x carryy = out1 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out1=reg256#4,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out1=%ymm3,>carryy=%ymm3
vpaddq %ymm7,%ymm3,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: FVGS2 = stack_FVGS2
# asm 1: vmovapd <stack_FVGS2=stack256#4,>FVGS2=reg256#10
# asm 2: vmovapd <stack_FVGS2=224(%rsp),>FVGS2=%ymm9
vmovapd 224(%rsp),%ymm9

# qhasm: GSFV2 = FVGS2[1,0]
# asm 1: vpermq $0x4e,<FVGS2=reg256#10,>GSFV2=reg256#11
# asm 2: vpermq $0x4e,<FVGS2=%ymm9,>GSFV2=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: mod2 = stack_mod2
# asm 1: vmovapd <stack_mod2=stack256#39,>mod2=reg256#15
# asm 2: vmovapd <stack_mod2=1344(%rsp),>mod2=%ymm14
vmovapd 1344(%rsp),%ymm14

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS1
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS1=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS1=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV1
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV1=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV1=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out2plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out2plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out2plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x ta = int32 uuss0 * int32 FVGS2
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS2=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS2=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV2
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV2=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV2=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out2 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out2=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out2=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm: 4x out2 += out2plus
# asm 1: vpaddq <out2=reg256#13,<out2plus=reg256#9,<out2=reg256#13
# asm 2: vpaddq <out2=%ymm12,<out2plus=%ymm8,<out2=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x ta = int32 d0 * int32 mod2
# asm 1: vpmuldq <d0=reg256#12,<mod2=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod2=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod1
# asm 1: vpmuldq <d1=reg256#2,<mod1=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod1=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out2plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out2plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out2plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out2plus2 += carryy
# asm 1: vpaddq <out2plus2=reg256#9,<carryy=reg256#4,<out2plus2=reg256#9
# asm 2: vpaddq <out2plus2=%ymm8,<carryy=%ymm3,<out2plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x out2 += out2plus2
# asm 1: vpaddq <out2=reg256#13,<out2plus2=reg256#9,<out2=reg256#13
# asm 2: vpaddq <out2=%ymm12,<out2plus2=%ymm8,<out2=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out2 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out2=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out2=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out2 &= _2p30m1x4
# asm 1: vpand <out2=reg256#13,<_2p30m1x4=reg256#5,<out2=reg256#13
# asm 2: vpand <out2=%ymm12,<_2p30m1x4=%ymm4,<out2=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS0 = out2
# asm 1: vmovapd <out2=reg256#13,>stack_FVGS0=stack256#2
# asm 2: vmovapd <out2=%ymm12,>stack_FVGS0=160(%rsp)
vmovapd %ymm12,160(%rsp)

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: FVGS3 = stack_FVGS3
# asm 1: vmovapd <stack_FVGS3=stack256#5,>FVGS3=reg256#9
# asm 2: vmovapd <stack_FVGS3=256(%rsp),>FVGS3=%ymm8
vmovapd 256(%rsp),%ymm8

# qhasm: GSFV3 = FVGS3[1,0]
# asm 1: vpermq $0x4e,<FVGS3=reg256#9,>GSFV3=reg256#13
# asm 2: vpermq $0x4e,<FVGS3=%ymm8,>GSFV3=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod3 = stack_mod3
# asm 1: vmovapd <stack_mod3=stack256#40,>mod3=reg256#14
# asm 2: vmovapd <stack_mod3=1376(%rsp),>mod3=%ymm13
vmovapd 1376(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS2
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS2=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS2=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV2
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV2=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV2=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out3plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out3plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out3plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x ta = int32 uuss0 * int32 FVGS3
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS3=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS3=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV3
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV3=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV3=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out3 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out3=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out3=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm: 4x out3 += out3plus
# asm 1: vpaddq <out3=reg256#11,<out3plus=reg256#10,<out3=reg256#11
# asm 2: vpaddq <out3=%ymm10,<out3plus=%ymm9,<out3=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x ta = int32 d0 * int32 mod3
# asm 1: vpmuldq <d0=reg256#12,<mod3=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod3=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod2
# asm 1: vpmuldq <d1=reg256#2,<mod2=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod2=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out3plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out3plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out3plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out3plus2 += carryy
# asm 1: vpaddq <out3plus2=reg256#10,<carryy=reg256#4,<out3plus2=reg256#10
# asm 2: vpaddq <out3plus2=%ymm9,<carryy=%ymm3,<out3plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm: 4x out3 += out3plus2
# asm 1: vpaddq <out3=reg256#11,<out3plus2=reg256#10,<out3=reg256#11
# asm 2: vpaddq <out3=%ymm10,<out3plus2=%ymm9,<out3=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x carryy = out3 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out3=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out3=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out3 &= _2p30m1x4
# asm 1: vpand <out3=reg256#11,<_2p30m1x4=reg256#5,<out3=reg256#11
# asm 2: vpand <out3=%ymm10,<_2p30m1x4=%ymm4,<out3=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: stack_FVGS1 = out3
# asm 1: vmovapd <out3=reg256#11,>stack_FVGS1=stack256#3
# asm 2: vmovapd <out3=%ymm10,>stack_FVGS1=192(%rsp)
vmovapd %ymm10,192(%rsp)

# qhasm: FVGS4 = stack_FVGS4
# asm 1: vmovapd <stack_FVGS4=stack256#6,>FVGS4=reg256#10
# asm 2: vmovapd <stack_FVGS4=288(%rsp),>FVGS4=%ymm9
vmovapd 288(%rsp),%ymm9

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: GSFV4 = FVGS4[1,0]
# asm 1: vpermq $0x4e,<FVGS4=reg256#10,>GSFV4=reg256#11
# asm 2: vpermq $0x4e,<FVGS4=%ymm9,>GSFV4=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod4 = stack_mod4
# asm 1: vmovapd <stack_mod4=stack256#41,>mod4=reg256#15
# asm 2: vmovapd <stack_mod4=1408(%rsp),>mod4=%ymm14
vmovapd 1408(%rsp),%ymm14

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x ta = int32 uuss1 * int32 FVGS3
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS3=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS3=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV3
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV3=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV3=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out4plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out4plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out4plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS4
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS4=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS4=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV4
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV4=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV4=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x out4 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out4=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out4=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm: 4x out4 += out4plus
# asm 1: vpaddq <out4=reg256#13,<out4plus=reg256#9,<out4=reg256#13
# asm 2: vpaddq <out4=%ymm12,<out4plus=%ymm8,<out4=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x ta = int32 d0 * int32 mod4
# asm 1: vpmuldq <d0=reg256#12,<mod4=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod4=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod3
# asm 1: vpmuldq <d1=reg256#2,<mod3=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod3=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out4plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out4plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out4plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out4plus2 += carryy
# asm 1: vpaddq <out4plus2=reg256#9,<carryy=reg256#4,<out4plus2=reg256#9
# asm 2: vpaddq <out4plus2=%ymm8,<carryy=%ymm3,<out4plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x out4 += out4plus2
# asm 1: vpaddq <out4=reg256#13,<out4plus2=reg256#9,<out4=reg256#13
# asm 2: vpaddq <out4=%ymm12,<out4plus2=%ymm8,<out4=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out4 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out4=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out4=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out4 &= _2p30m1x4
# asm 1: vpand <out4=reg256#13,<_2p30m1x4=reg256#5,<out4=reg256#13
# asm 2: vpand <out4=%ymm12,<_2p30m1x4=%ymm4,<out4=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: stack_FVGS2 = out4
# asm 1: vmovapd <out4=reg256#13,>stack_FVGS2=stack256#4
# asm 2: vmovapd <out4=%ymm12,>stack_FVGS2=224(%rsp)
vmovapd %ymm12,224(%rsp)

# qhasm: FVGS5 = stack_FVGS5
# asm 1: vmovapd <stack_FVGS5=stack256#7,>FVGS5=reg256#9
# asm 2: vmovapd <stack_FVGS5=320(%rsp),>FVGS5=%ymm8
vmovapd 320(%rsp),%ymm8

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: GSFV5 = FVGS5[1,0]
# asm 1: vpermq $0x4e,<FVGS5=reg256#9,>GSFV5=reg256#13
# asm 2: vpermq $0x4e,<FVGS5=%ymm8,>GSFV5=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod5 = stack_mod5
# asm 1: vmovapd <stack_mod5=stack256#42,>mod5=reg256#14
# asm 2: vmovapd <stack_mod5=1440(%rsp),>mod5=%ymm13
vmovapd 1440(%rsp),%ymm13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS4
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS4=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS4=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV4
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV4=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV4=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out5plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out5plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out5plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS5
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS5=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS5=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV5
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV5=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV5=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm: 4x out5 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out5=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out5=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out5 += out5plus
# asm 1: vpaddq <out5=reg256#11,<out5plus=reg256#10,<out5=reg256#11
# asm 2: vpaddq <out5=%ymm10,<out5plus=%ymm9,<out5=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod5
# asm 1: vpmuldq <d0=reg256#12,<mod5=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod5=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod4
# asm 1: vpmuldq <d1=reg256#2,<mod4=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod4=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out5plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out5plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out5plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out5plus2 += carryy
# asm 1: vpaddq <out5plus2=reg256#10,<carryy=reg256#4,<out5plus2=reg256#10
# asm 2: vpaddq <out5plus2=%ymm9,<carryy=%ymm3,<out5plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out5 += out5plus2
# asm 1: vpaddq <out5=reg256#11,<out5plus2=reg256#10,<out5=reg256#11
# asm 2: vpaddq <out5=%ymm10,<out5plus2=%ymm9,<out5=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out5 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out5=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out5=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out5 &= _2p30m1x4
# asm 1: vpand <out5=reg256#11,<_2p30m1x4=reg256#5,<out5=reg256#11
# asm 2: vpand <out5=%ymm10,<_2p30m1x4=%ymm4,<out5=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: stack_FVGS3 = out5
# asm 1: vmovapd <out5=reg256#11,>stack_FVGS3=stack256#5
# asm 2: vmovapd <out5=%ymm10,>stack_FVGS3=256(%rsp)
vmovapd %ymm10,256(%rsp)

# qhasm: FVGS6 = stack_FVGS6
# asm 1: vmovapd <stack_FVGS6=stack256#8,>FVGS6=reg256#10
# asm 2: vmovapd <stack_FVGS6=352(%rsp),>FVGS6=%ymm9
vmovapd 352(%rsp),%ymm9

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: GSFV6 = FVGS6[1,0]
# asm 1: vpermq $0x4e,<FVGS6=reg256#10,>GSFV6=reg256#11
# asm 2: vpermq $0x4e,<FVGS6=%ymm9,>GSFV6=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod6 = stack_mod6
# asm 1: vmovapd <stack_mod6=stack256#43,>mod6=reg256#15
# asm 2: vmovapd <stack_mod6=1472(%rsp),>mod6=%ymm14
vmovapd 1472(%rsp),%ymm14

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x ta = int32 uuss1 * int32 FVGS5
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS5=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS5=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV5
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV5=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV5=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out6plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out6plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out6plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS6
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS6=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS6=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV6
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV6=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV6=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out6 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out6=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out6=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out6 += out6plus
# asm 1: vpaddq <out6=reg256#13,<out6plus=reg256#9,<out6=reg256#13
# asm 2: vpaddq <out6=%ymm12,<out6plus=%ymm8,<out6=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod6
# asm 1: vpmuldq <d0=reg256#12,<mod6=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod6=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x tb = int32 d1 * int32 mod5
# asm 1: vpmuldq <d1=reg256#2,<mod5=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod5=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm: 4x out6plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out6plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out6plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out6plus2 += carryy
# asm 1: vpaddq <out6plus2=reg256#9,<carryy=reg256#4,<out6plus2=reg256#9
# asm 2: vpaddq <out6plus2=%ymm8,<carryy=%ymm3,<out6plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out6 += out6plus2
# asm 1: vpaddq <out6=reg256#13,<out6plus2=reg256#9,<out6=reg256#13
# asm 2: vpaddq <out6=%ymm12,<out6plus2=%ymm8,<out6=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out6 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out6=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out6=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out6 &= _2p30m1x4
# asm 1: vpand <out6=reg256#13,<_2p30m1x4=reg256#5,<out6=reg256#13
# asm 2: vpand <out6=%ymm12,<_2p30m1x4=%ymm4,<out6=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: stack_FVGS4 = out6
# asm 1: vmovapd <out6=reg256#13,>stack_FVGS4=stack256#6
# asm 2: vmovapd <out6=%ymm12,>stack_FVGS4=288(%rsp)
vmovapd %ymm12,288(%rsp)

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: FVGS7 = stack_FVGS7
# asm 1: vmovapd <stack_FVGS7=stack256#9,>FVGS7=reg256#9
# asm 2: vmovapd <stack_FVGS7=384(%rsp),>FVGS7=%ymm8
vmovapd 384(%rsp),%ymm8

# qhasm: GSFV7 = FVGS7[1,0]
# asm 1: vpermq $0x4e,<FVGS7=reg256#9,>GSFV7=reg256#13
# asm 2: vpermq $0x4e,<FVGS7=%ymm8,>GSFV7=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod7 = stack_mod7
# asm 1: vmovapd <stack_mod7=stack256#44,>mod7=reg256#14
# asm 2: vmovapd <stack_mod7=1504(%rsp),>mod7=%ymm13
vmovapd 1504(%rsp),%ymm13

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS6
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS6=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS6=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV6
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV6=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV6=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out7plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out7plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out7plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS7
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS7=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS7=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV7
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV7=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV7=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm: 4x out7 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out7=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out7=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out7 += out7plus
# asm 1: vpaddq <out7=reg256#11,<out7plus=reg256#10,<out7=reg256#11
# asm 2: vpaddq <out7=%ymm10,<out7plus=%ymm9,<out7=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod7
# asm 1: vpmuldq <d0=reg256#12,<mod7=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod7=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x tb = int32 d1 * int32 mod6
# asm 1: vpmuldq <d1=reg256#2,<mod6=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod6=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out7plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out7plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out7plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x out7plus2 += carryy
# asm 1: vpaddq <out7plus2=reg256#10,<carryy=reg256#4,<out7plus2=reg256#10
# asm 2: vpaddq <out7plus2=%ymm9,<carryy=%ymm3,<out7plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm: 4x out7 += out7plus2
# asm 1: vpaddq <out7=reg256#11,<out7plus2=reg256#10,<out7=reg256#11
# asm 2: vpaddq <out7=%ymm10,<out7plus2=%ymm9,<out7=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x carryy = out7 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out7=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out7=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: out7 &= _2p30m1x4
# asm 1: vpand <out7=reg256#11,<_2p30m1x4=reg256#5,<out7=reg256#11
# asm 2: vpand <out7=%ymm10,<_2p30m1x4=%ymm4,<out7=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS5 = out7
# asm 1: vmovapd <out7=reg256#11,>stack_FVGS5=stack256#7
# asm 2: vmovapd <out7=%ymm10,>stack_FVGS5=320(%rsp)
vmovapd %ymm10,320(%rsp)

# qhasm: FVGS8 = stack_FVGS8
# asm 1: vmovapd <stack_FVGS8=stack256#10,>FVGS8=reg256#10
# asm 2: vmovapd <stack_FVGS8=416(%rsp),>FVGS8=%ymm9
vmovapd 416(%rsp),%ymm9

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: GSFV8 = FVGS8[1,0]
# asm 1: vpermq $0x4e,<FVGS8=reg256#10,>GSFV8=reg256#11
# asm 2: vpermq $0x4e,<FVGS8=%ymm9,>GSFV8=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: mod8 = stack_mod8
# asm 1: vmovapd <stack_mod8=stack256#45,>mod8=reg256#15
# asm 2: vmovapd <stack_mod8=1536(%rsp),>mod8=%ymm14
vmovapd 1536(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS7
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS7=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS7=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV7
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV7=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV7=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x out8plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out8plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out8plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x ta = int32 uuss0 * int32 FVGS8
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS8=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS8=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV8
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV8=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV8=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out8 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out8=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out8=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out8 += out8plus
# asm 1: vpaddq <out8=reg256#13,<out8plus=reg256#9,<out8=reg256#13
# asm 2: vpaddq <out8=%ymm12,<out8plus=%ymm8,<out8=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod8
# asm 1: vpmuldq <d0=reg256#12,<mod8=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod8=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x tb = int32 d1 * int32 mod7
# asm 1: vpmuldq <d1=reg256#2,<mod7=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod7=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm: 4x out8plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out8plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out8plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x out8plus2 += carryy
# asm 1: vpaddq <out8plus2=reg256#9,<carryy=reg256#4,<out8plus2=reg256#9
# asm 2: vpaddq <out8plus2=%ymm8,<carryy=%ymm3,<out8plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out8 += out8plus2
# asm 1: vpaddq <out8=reg256#13,<out8plus2=reg256#9,<out8=reg256#13
# asm 2: vpaddq <out8=%ymm12,<out8plus2=%ymm8,<out8=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x carryy = out8 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out8=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out8=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: out8 &= _2p30m1x4
# asm 1: vpand <out8=reg256#13,<_2p30m1x4=reg256#5,<out8=reg256#13
# asm 2: vpand <out8=%ymm12,<_2p30m1x4=%ymm4,<out8=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: stack_FVGS6 = out8
# asm 1: vmovapd <out8=reg256#13,>stack_FVGS6=stack256#8
# asm 2: vmovapd <out8=%ymm12,>stack_FVGS6=352(%rsp)
vmovapd %ymm12,352(%rsp)

# qhasm: FVGS9 = stack_FVGS9
# asm 1: vmovapd <stack_FVGS9=stack256#11,>FVGS9=reg256#9
# asm 2: vmovapd <stack_FVGS9=448(%rsp),>FVGS9=%ymm8
vmovapd 448(%rsp),%ymm8

# qhasm: GSFV9 = FVGS9[1,0]
# asm 1: vpermq $0x4e,<FVGS9=reg256#9,>GSFV9=reg256#13
# asm 2: vpermq $0x4e,<FVGS9=%ymm8,>GSFV9=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: mod9 = stack_mod9
# asm 1: vmovapd <stack_mod9=stack256#46,>mod9=reg256#14
# asm 2: vmovapd <stack_mod9=1568(%rsp),>mod9=%ymm13
vmovapd 1568(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS8
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS8=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS8=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV8
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV8=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV8=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out9plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out9plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out9plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS9
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS9=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS9=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV9
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV9=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV9=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm: 4x out9 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out9=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out9=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out9 += out9plus
# asm 1: vpaddq <out9=reg256#11,<out9plus=reg256#10,<out9=reg256#11
# asm 2: vpaddq <out9=%ymm10,<out9plus=%ymm9,<out9=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod9
# asm 1: vpmuldq <d0=reg256#12,<mod9=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod9=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x tb = int32 d1 * int32 mod8
# asm 1: vpmuldq <d1=reg256#2,<mod8=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod8=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out9plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out9plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out9plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out9plus2 += carryy
# asm 1: vpaddq <out9plus2=reg256#10,<carryy=reg256#4,<out9plus2=reg256#10
# asm 2: vpaddq <out9plus2=%ymm9,<carryy=%ymm3,<out9plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x out9 += out9plus2
# asm 1: vpaddq <out9=reg256#11,<out9plus2=reg256#10,<out9=reg256#11
# asm 2: vpaddq <out9=%ymm10,<out9plus2=%ymm9,<out9=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x carryy = out9 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out9=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out9=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: out9 &= _2p30m1x4
# asm 1: vpand <out9=reg256#11,<_2p30m1x4=reg256#5,<out9=reg256#11
# asm 2: vpand <out9=%ymm10,<_2p30m1x4=%ymm4,<out9=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS7 = out9
# asm 1: vmovapd <out9=reg256#11,>stack_FVGS7=stack256#9
# asm 2: vmovapd <out9=%ymm10,>stack_FVGS7=384(%rsp)
vmovapd %ymm10,384(%rsp)

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: FVGS10 = stack_FVGS10
# asm 1: vmovapd <stack_FVGS10=stack256#12,>FVGS10=reg256#10
# asm 2: vmovapd <stack_FVGS10=480(%rsp),>FVGS10=%ymm9
vmovapd 480(%rsp),%ymm9

# qhasm: GSFV10 = FVGS10[1,0]
# asm 1: vpermq $0x4e,<FVGS10=reg256#10,>GSFV10=reg256#11
# asm 2: vpermq $0x4e,<FVGS10=%ymm9,>GSFV10=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: mod10 = stack_mod10
# asm 1: vmovapd <stack_mod10=stack256#47,>mod10=reg256#15
# asm 2: vmovapd <stack_mod10=1600(%rsp),>mod10=%ymm14
vmovapd 1600(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS9
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS9=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS9=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV9
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV9=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV9=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out10plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out10plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out10plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x ta = int32 uuss0 * int32 FVGS10
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS10=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS10=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV10
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV10=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV10=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out10 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out10=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out10=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out10 += out10plus
# asm 1: vpaddq <out10=reg256#13,<out10plus=reg256#9,<out10=reg256#13
# asm 2: vpaddq <out10=%ymm12,<out10plus=%ymm8,<out10=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod10
# asm 1: vpmuldq <d0=reg256#12,<mod10=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod10=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x tb = int32 d1 * int32 mod9
# asm 1: vpmuldq <d1=reg256#2,<mod9=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod9=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm: 4x out10plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out10plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out10plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out10plus2 += carryy
# asm 1: vpaddq <out10plus2=reg256#9,<carryy=reg256#4,<out10plus2=reg256#9
# asm 2: vpaddq <out10plus2=%ymm8,<carryy=%ymm3,<out10plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out10 += out10plus2
# asm 1: vpaddq <out10=reg256#13,<out10plus2=reg256#9,<out10=reg256#13
# asm 2: vpaddq <out10=%ymm12,<out10plus2=%ymm8,<out10=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x carryy = out10 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out10=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out10=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: out10 &= _2p30m1x4
# asm 1: vpand <out10=reg256#13,<_2p30m1x4=reg256#5,<out10=reg256#13
# asm 2: vpand <out10=%ymm12,<_2p30m1x4=%ymm4,<out10=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS8 = out10
# asm 1: vmovapd <out10=reg256#13,>stack_FVGS8=stack256#10
# asm 2: vmovapd <out10=%ymm12,>stack_FVGS8=416(%rsp)
vmovapd %ymm12,416(%rsp)

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: FVGS11 = stack_FVGS11
# asm 1: vmovapd <stack_FVGS11=stack256#13,>FVGS11=reg256#9
# asm 2: vmovapd <stack_FVGS11=512(%rsp),>FVGS11=%ymm8
vmovapd 512(%rsp),%ymm8

# qhasm: GSFV11 = FVGS11[1,0]
# asm 1: vpermq $0x4e,<FVGS11=reg256#9,>GSFV11=reg256#13
# asm 2: vpermq $0x4e,<FVGS11=%ymm8,>GSFV11=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: mod11 = stack_mod11
# asm 1: vmovapd <stack_mod11=stack256#48,>mod11=reg256#14
# asm 2: vmovapd <stack_mod11=1632(%rsp),>mod11=%ymm13
vmovapd 1632(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS10
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS10=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS10=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV10
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV10=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV10=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out11plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out11plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out11plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS11
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS11=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS11=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV11
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV11=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV11=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out11 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out11=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out11=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm: 4x out11 += out11plus
# asm 1: vpaddq <out11=reg256#11,<out11plus=reg256#10,<out11=reg256#11
# asm 2: vpaddq <out11=%ymm10,<out11plus=%ymm9,<out11=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x ta = int32 d0 * int32 mod11
# asm 1: vpmuldq <d0=reg256#12,<mod11=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod11=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod10
# asm 1: vpmuldq <d1=reg256#2,<mod10=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod10=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out11plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out11plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out11plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out11plus2 += carryy
# asm 1: vpaddq <out11plus2=reg256#10,<carryy=reg256#4,<out11plus2=reg256#10
# asm 2: vpaddq <out11plus2=%ymm9,<carryy=%ymm3,<out11plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm: 4x out11 += out11plus2
# asm 1: vpaddq <out11=reg256#11,<out11plus2=reg256#10,<out11=reg256#11
# asm 2: vpaddq <out11=%ymm10,<out11plus2=%ymm9,<out11=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x carryy = out11 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out11=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out11=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: out11 &= _2p30m1x4
# asm 1: vpand <out11=reg256#11,<_2p30m1x4=reg256#5,<out11=reg256#11
# asm 2: vpand <out11=%ymm10,<_2p30m1x4=%ymm4,<out11=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS9 = out11
# asm 1: vmovapd <out11=reg256#11,>stack_FVGS9=stack256#11
# asm 2: vmovapd <out11=%ymm10,>stack_FVGS9=448(%rsp)
vmovapd %ymm10,448(%rsp)

# qhasm: FVGS12 = stack_FVGS12
# asm 1: vmovapd <stack_FVGS12=stack256#14,>FVGS12=reg256#10
# asm 2: vmovapd <stack_FVGS12=544(%rsp),>FVGS12=%ymm9
vmovapd 544(%rsp),%ymm9

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: GSFV12 = FVGS12[1,0]
# asm 1: vpermq $0x4e,<FVGS12=reg256#10,>GSFV12=reg256#11
# asm 2: vpermq $0x4e,<FVGS12=%ymm9,>GSFV12=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: mod12 = stack_mod12
# asm 1: vmovapd <stack_mod12=stack256#49,>mod12=reg256#15
# asm 2: vmovapd <stack_mod12=1664(%rsp),>mod12=%ymm14
vmovapd 1664(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS11
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS11=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS11=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV11
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV11=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV11=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out12plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out12plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out12plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS12
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS12=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS12=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV12
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV12=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV12=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out12 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out12=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out12=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm: 4x out12 += out12plus
# asm 1: vpaddq <out12=reg256#13,<out12plus=reg256#9,<out12=reg256#13
# asm 2: vpaddq <out12=%ymm12,<out12plus=%ymm8,<out12=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x ta = int32 d0 * int32 mod12
# asm 1: vpmuldq <d0=reg256#12,<mod12=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod12=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod11
# asm 1: vpmuldq <d1=reg256#2,<mod11=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod11=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x out12plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out12plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out12plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out12plus2 += carryy
# asm 1: vpaddq <out12plus2=reg256#9,<carryy=reg256#4,<out12plus2=reg256#9
# asm 2: vpaddq <out12plus2=%ymm8,<carryy=%ymm3,<out12plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out12 += out12plus2
# asm 1: vpaddq <out12=reg256#13,<out12plus2=reg256#9,<out12=reg256#13
# asm 2: vpaddq <out12=%ymm12,<out12plus2=%ymm8,<out12=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out12 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out12=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out12=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: out12 &= _2p30m1x4
# asm 1: vpand <out12=reg256#13,<_2p30m1x4=reg256#5,<out12=reg256#13
# asm 2: vpand <out12=%ymm12,<_2p30m1x4=%ymm4,<out12=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS10 = out12
# asm 1: vmovapd <out12=reg256#13,>stack_FVGS10=stack256#12
# asm 2: vmovapd <out12=%ymm12,>stack_FVGS10=480(%rsp)
vmovapd %ymm12,480(%rsp)

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: FVGS13 = stack_FVGS13
# asm 1: vmovapd <stack_FVGS13=stack256#15,>FVGS13=reg256#9
# asm 2: vmovapd <stack_FVGS13=576(%rsp),>FVGS13=%ymm8
vmovapd 576(%rsp),%ymm8

# qhasm: GSFV13 = FVGS13[1,0]
# asm 1: vpermq $0x4e,<FVGS13=reg256#9,>GSFV13=reg256#13
# asm 2: vpermq $0x4e,<FVGS13=%ymm8,>GSFV13=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: mod13 = stack_mod13
# asm 1: vmovapd <stack_mod13=stack256#50,>mod13=reg256#14
# asm 2: vmovapd <stack_mod13=1696(%rsp),>mod13=%ymm13
vmovapd 1696(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS12
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS12=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS12=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV12
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV12=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV12=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out13plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out13plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out13plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x ta = int32 uuss0 * int32 FVGS13
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS13=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS13=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV13
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV13=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV13=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out13 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out13=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out13=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm: 4x out13 += out13plus
# asm 1: vpaddq <out13=reg256#11,<out13plus=reg256#10,<out13=reg256#11
# asm 2: vpaddq <out13=%ymm10,<out13plus=%ymm9,<out13=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x ta = int32 d0 * int32 mod13
# asm 1: vpmuldq <d0=reg256#12,<mod13=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod13=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod12
# asm 1: vpmuldq <d1=reg256#2,<mod12=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod12=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x out13plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out13plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out13plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out13plus2 += carryy
# asm 1: vpaddq <out13plus2=reg256#10,<carryy=reg256#4,<out13plus2=reg256#10
# asm 2: vpaddq <out13plus2=%ymm9,<carryy=%ymm3,<out13plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out13 += out13plus2
# asm 1: vpaddq <out13=reg256#11,<out13plus2=reg256#10,<out13=reg256#11
# asm 2: vpaddq <out13=%ymm10,<out13plus2=%ymm9,<out13=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out13 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out13=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out13=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out13 &= _2p30m1x4
# asm 1: vpand <out13=reg256#11,<_2p30m1x4=reg256#5,<out13=reg256#11
# asm 2: vpand <out13=%ymm10,<_2p30m1x4=%ymm4,<out13=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: stack_FVGS11 = out13
# asm 1: vmovapd <out13=reg256#11,>stack_FVGS11=stack256#13
# asm 2: vmovapd <out13=%ymm10,>stack_FVGS11=512(%rsp)
vmovapd %ymm10,512(%rsp)

# qhasm: FVGS14 = stack_FVGS14
# asm 1: vmovapd <stack_FVGS14=stack256#16,>FVGS14=reg256#10
# asm 2: vmovapd <stack_FVGS14=608(%rsp),>FVGS14=%ymm9
vmovapd 608(%rsp),%ymm9

# qhasm: GSFV14 = FVGS14[1,0]
# asm 1: vpermq $0x4e,<FVGS14=reg256#10,>GSFV14=reg256#11
# asm 2: vpermq $0x4e,<FVGS14=%ymm9,>GSFV14=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: mod14 = stack_mod14
# asm 1: vmovapd <stack_mod14=stack256#51,>mod14=reg256#15
# asm 2: vmovapd <stack_mod14=1728(%rsp),>mod14=%ymm14
vmovapd 1728(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS13
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS13=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS13=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV13
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV13=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV13=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out14plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out14plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out14plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS14
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS14=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS14=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV14
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV14=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV14=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out14 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out14=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out14=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm: 4x out14 += out14plus
# asm 1: vpaddq <out14=reg256#13,<out14plus=reg256#9,<out14=reg256#13
# asm 2: vpaddq <out14=%ymm12,<out14plus=%ymm8,<out14=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x ta = int32 d0 * int32 mod14
# asm 1: vpmuldq <d0=reg256#12,<mod14=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod14=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod13
# asm 1: vpmuldq <d1=reg256#2,<mod13=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod13=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x out14plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out14plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out14plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out14plus2 += carryy
# asm 1: vpaddq <out14plus2=reg256#9,<carryy=reg256#4,<out14plus2=reg256#9
# asm 2: vpaddq <out14plus2=%ymm8,<carryy=%ymm3,<out14plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out14 += out14plus2
# asm 1: vpaddq <out14=reg256#13,<out14plus2=reg256#9,<out14=reg256#13
# asm 2: vpaddq <out14=%ymm12,<out14plus2=%ymm8,<out14=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out14 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out14=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out14=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out14 &= _2p30m1x4
# asm 1: vpand <out14=reg256#13,<_2p30m1x4=reg256#5,<out14=reg256#13
# asm 2: vpand <out14=%ymm12,<_2p30m1x4=%ymm4,<out14=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: stack_FVGS12 = out14
# asm 1: vmovapd <out14=reg256#13,>stack_FVGS12=stack256#14
# asm 2: vmovapd <out14=%ymm12,>stack_FVGS12=544(%rsp)
vmovapd %ymm12,544(%rsp)

# qhasm: FVGS15 = stack_FVGS15
# asm 1: vmovapd <stack_FVGS15=stack256#17,>FVGS15=reg256#9
# asm 2: vmovapd <stack_FVGS15=640(%rsp),>FVGS15=%ymm8
vmovapd 640(%rsp),%ymm8

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: GSFV15 = FVGS15[1,0]
# asm 1: vpermq $0x4e,<FVGS15=reg256#9,>GSFV15=reg256#13
# asm 2: vpermq $0x4e,<FVGS15=%ymm8,>GSFV15=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod15 = stack_mod15
# asm 1: vmovapd <stack_mod15=stack256#52,>mod15=reg256#14
# asm 2: vmovapd <stack_mod15=1760(%rsp),>mod15=%ymm13
vmovapd 1760(%rsp),%ymm13

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x ta = int32 uuss1 * int32 FVGS14
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS14=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS14=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV14
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV14=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV14=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out15plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out15plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out15plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x ta = int32 uuss0 * int32 FVGS15
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS15=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS15=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV15
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV15=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV15=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out15 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out15=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out15=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm: 4x out15 += out15plus
# asm 1: vpaddq <out15=reg256#11,<out15plus=reg256#10,<out15=reg256#11
# asm 2: vpaddq <out15=%ymm10,<out15plus=%ymm9,<out15=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x ta = int32 d0 * int32 mod15
# asm 1: vpmuldq <d0=reg256#12,<mod15=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod15=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod14
# asm 1: vpmuldq <d1=reg256#2,<mod14=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod14=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out15plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out15plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out15plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out15plus2 += carryy
# asm 1: vpaddq <out15plus2=reg256#10,<carryy=reg256#4,<out15plus2=reg256#10
# asm 2: vpaddq <out15plus2=%ymm9,<carryy=%ymm3,<out15plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out15 += out15plus2
# asm 1: vpaddq <out15=reg256#11,<out15plus2=reg256#10,<out15=reg256#11
# asm 2: vpaddq <out15=%ymm10,<out15plus2=%ymm9,<out15=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out15 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out15=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out15=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out15 &= _2p30m1x4
# asm 1: vpand <out15=reg256#11,<_2p30m1x4=reg256#5,<out15=reg256#11
# asm 2: vpand <out15=%ymm10,<_2p30m1x4=%ymm4,<out15=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: stack_FVGS13 = out15
# asm 1: vmovapd <out15=reg256#11,>stack_FVGS13=stack256#15
# asm 2: vmovapd <out15=%ymm10,>stack_FVGS13=576(%rsp)
vmovapd %ymm10,576(%rsp)

# qhasm: FVGS16 = stack_FVGS16
# asm 1: vmovapd <stack_FVGS16=stack256#18,>FVGS16=reg256#10
# asm 2: vmovapd <stack_FVGS16=672(%rsp),>FVGS16=%ymm9
vmovapd 672(%rsp),%ymm9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: GSFV16 = FVGS16[1,0]
# asm 1: vpermq $0x4e,<FVGS16=reg256#10,>GSFV16=reg256#11
# asm 2: vpermq $0x4e,<FVGS16=%ymm9,>GSFV16=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod16 = stack_mod16
# asm 1: vmovapd <stack_mod16=stack256#53,>mod16=reg256#15
# asm 2: vmovapd <stack_mod16=1792(%rsp),>mod16=%ymm14
vmovapd 1792(%rsp),%ymm14

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x ta = int32 uuss1 * int32 FVGS15
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS15=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS15=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV15
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV15=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV15=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x out16plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out16plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out16plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS16
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS16=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS16=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV16
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV16=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV16=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out16 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out16=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out16=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm: 4x out16 += out16plus
# asm 1: vpaddq <out16=reg256#13,<out16plus=reg256#9,<out16=reg256#13
# asm 2: vpaddq <out16=%ymm12,<out16plus=%ymm8,<out16=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x ta = int32 d0 * int32 mod16
# asm 1: vpmuldq <d0=reg256#12,<mod16=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod16=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod15
# asm 1: vpmuldq <d1=reg256#2,<mod15=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod15=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out16plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out16plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out16plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out16plus2 += carryy
# asm 1: vpaddq <out16plus2=reg256#9,<carryy=reg256#4,<out16plus2=reg256#9
# asm 2: vpaddq <out16plus2=%ymm8,<carryy=%ymm3,<out16plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out16 += out16plus2
# asm 1: vpaddq <out16=reg256#13,<out16plus2=reg256#9,<out16=reg256#13
# asm 2: vpaddq <out16=%ymm12,<out16plus2=%ymm8,<out16=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out16 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out16=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out16=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out16 &= _2p30m1x4
# asm 1: vpand <out16=reg256#13,<_2p30m1x4=reg256#5,<out16=reg256#13
# asm 2: vpand <out16=%ymm12,<_2p30m1x4=%ymm4,<out16=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS14 = out16
# asm 1: vmovapd <out16=reg256#13,>stack_FVGS14=stack256#16
# asm 2: vmovapd <out16=%ymm12,>stack_FVGS14=608(%rsp)
vmovapd %ymm12,608(%rsp)

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: FVGS17 = stack_FVGS17
# asm 1: vmovapd <stack_FVGS17=stack256#19,>FVGS17=reg256#9
# asm 2: vmovapd <stack_FVGS17=704(%rsp),>FVGS17=%ymm8
vmovapd 704(%rsp),%ymm8

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: GSFV17 = FVGS17[1,0]
# asm 1: vpermq $0x4e,<FVGS17=reg256#9,>GSFV17=reg256#13
# asm 2: vpermq $0x4e,<FVGS17=%ymm8,>GSFV17=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod17 = stack_mod17
# asm 1: vmovapd <stack_mod17=stack256#54,>mod17=reg256#14
# asm 2: vmovapd <stack_mod17=1824(%rsp),>mod17=%ymm13
vmovapd 1824(%rsp),%ymm13

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS16
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS16=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS16=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV16
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV16=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV16=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out17plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out17plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out17plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS17
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS17=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS17=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV17
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV17=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV17=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm: 4x out17 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out17=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out17=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out17 += out17plus
# asm 1: vpaddq <out17=reg256#11,<out17plus=reg256#10,<out17=reg256#11
# asm 2: vpaddq <out17=%ymm10,<out17plus=%ymm9,<out17=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod17
# asm 1: vpmuldq <d0=reg256#12,<mod17=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod17=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x tb = int32 d1 * int32 mod16
# asm 1: vpmuldq <d1=reg256#2,<mod16=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod16=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out17plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out17plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out17plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out17plus2 += carryy
# asm 1: vpaddq <out17plus2=reg256#10,<carryy=reg256#4,<out17plus2=reg256#10
# asm 2: vpaddq <out17plus2=%ymm9,<carryy=%ymm3,<out17plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out17 += out17plus2
# asm 1: vpaddq <out17=reg256#11,<out17plus2=reg256#10,<out17=reg256#11
# asm 2: vpaddq <out17=%ymm10,<out17plus2=%ymm9,<out17=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out17 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out17=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out17=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out17 &= _2p30m1x4
# asm 1: vpand <out17=reg256#11,<_2p30m1x4=reg256#5,<out17=reg256#11
# asm 2: vpand <out17=%ymm10,<_2p30m1x4=%ymm4,<out17=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: stack_FVGS15 = out17
# asm 1: vmovapd <out17=reg256#11,>stack_FVGS15=stack256#17
# asm 2: vmovapd <out17=%ymm10,>stack_FVGS15=640(%rsp)
vmovapd %ymm10,640(%rsp)

# qhasm: FVGS18 = stack_FVGS18
# asm 1: vmovapd <stack_FVGS18=stack256#20,>FVGS18=reg256#10
# asm 2: vmovapd <stack_FVGS18=736(%rsp),>FVGS18=%ymm9
vmovapd 736(%rsp),%ymm9

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: GSFV18 = FVGS18[1,0]
# asm 1: vpermq $0x4e,<FVGS18=reg256#10,>GSFV18=reg256#11
# asm 2: vpermq $0x4e,<FVGS18=%ymm9,>GSFV18=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod18 = stack_mod18
# asm 1: vmovapd <stack_mod18=stack256#55,>mod18=reg256#15
# asm 2: vmovapd <stack_mod18=1856(%rsp),>mod18=%ymm14
vmovapd 1856(%rsp),%ymm14

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x ta = int32 uuss1 * int32 FVGS17
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS17=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS17=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV17
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV17=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV17=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out18plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out18plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out18plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x ta = int32 uuss0 * int32 FVGS18
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS18=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS18=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV18
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV18=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV18=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out18 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out18=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out18=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out18 += out18plus
# asm 1: vpaddq <out18=reg256#13,<out18plus=reg256#9,<out18=reg256#13
# asm 2: vpaddq <out18=%ymm12,<out18plus=%ymm8,<out18=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod18
# asm 1: vpmuldq <d0=reg256#12,<mod18=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod18=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x tb = int32 d1 * int32 mod17
# asm 1: vpmuldq <d1=reg256#2,<mod17=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod17=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm: 4x out18plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out18plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out18plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out18plus2 += carryy
# asm 1: vpaddq <out18plus2=reg256#9,<carryy=reg256#4,<out18plus2=reg256#9
# asm 2: vpaddq <out18plus2=%ymm8,<carryy=%ymm3,<out18plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out18 += out18plus2
# asm 1: vpaddq <out18=reg256#13,<out18plus2=reg256#9,<out18=reg256#13
# asm 2: vpaddq <out18=%ymm12,<out18plus2=%ymm8,<out18=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x carryy = out18 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out18=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out18=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out18 &= _2p30m1x4
# asm 1: vpand <out18=reg256#13,<_2p30m1x4=reg256#5,<out18=reg256#13
# asm 2: vpand <out18=%ymm12,<_2p30m1x4=%ymm4,<out18=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: stack_FVGS16 = out18
# asm 1: vmovapd <out18=reg256#13,>stack_FVGS16=stack256#18
# asm 2: vmovapd <out18=%ymm12,>stack_FVGS16=672(%rsp)
vmovapd %ymm12,672(%rsp)

# qhasm: FVGS19 = stack_FVGS19
# asm 1: vmovapd <stack_FVGS19=stack256#21,>FVGS19=reg256#9
# asm 2: vmovapd <stack_FVGS19=768(%rsp),>FVGS19=%ymm8
vmovapd 768(%rsp),%ymm8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: GSFV19 = FVGS19[1,0]
# asm 1: vpermq $0x4e,<FVGS19=reg256#9,>GSFV19=reg256#13
# asm 2: vpermq $0x4e,<FVGS19=%ymm8,>GSFV19=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod19 = stack_mod19
# asm 1: vmovapd <stack_mod19=stack256#56,>mod19=reg256#14
# asm 2: vmovapd <stack_mod19=1888(%rsp),>mod19=%ymm13
vmovapd 1888(%rsp),%ymm13

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS18
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS18=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS18=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV18
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV18=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV18=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x out19plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out19plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out19plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS19
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS19=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS19=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV19
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV19=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV19=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm: 4x out19 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out19=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out19=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out19 += out19plus
# asm 1: vpaddq <out19=reg256#11,<out19plus=reg256#10,<out19=reg256#11
# asm 2: vpaddq <out19=%ymm10,<out19plus=%ymm9,<out19=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod19
# asm 1: vpmuldq <d0=reg256#12,<mod19=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod19=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x tb = int32 d1 * int32 mod18
# asm 1: vpmuldq <d1=reg256#2,<mod18=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod18=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out19plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out19plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out19plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out19plus2 += carryy
# asm 1: vpaddq <out19plus2=reg256#10,<carryy=reg256#4,<out19plus2=reg256#10
# asm 2: vpaddq <out19plus2=%ymm9,<carryy=%ymm3,<out19plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm: 4x out19 += out19plus2
# asm 1: vpaddq <out19=reg256#11,<out19plus2=reg256#10,<out19=reg256#11
# asm 2: vpaddq <out19=%ymm10,<out19plus2=%ymm9,<out19=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x carryy = out19 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out19=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out19=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out19 &= _2p30m1x4
# asm 1: vpand <out19=reg256#11,<_2p30m1x4=reg256#5,<out19=reg256#11
# asm 2: vpand <out19=%ymm10,<_2p30m1x4=%ymm4,<out19=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS17 = out19
# asm 1: vmovapd <out19=reg256#11,>stack_FVGS17=stack256#19
# asm 2: vmovapd <out19=%ymm10,>stack_FVGS17=704(%rsp)
vmovapd %ymm10,704(%rsp)

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: FVGS20 = stack_FVGS20
# asm 1: vmovapd <stack_FVGS20=stack256#22,>FVGS20=reg256#10
# asm 2: vmovapd <stack_FVGS20=800(%rsp),>FVGS20=%ymm9
vmovapd 800(%rsp),%ymm9

# qhasm: GSFV20 = FVGS20[1,0]
# asm 1: vpermq $0x4e,<FVGS20=reg256#10,>GSFV20=reg256#11
# asm 2: vpermq $0x4e,<FVGS20=%ymm9,>GSFV20=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod20 = stack_mod20
# asm 1: vmovapd <stack_mod20=stack256#57,>mod20=reg256#15
# asm 2: vmovapd <stack_mod20=1920(%rsp),>mod20=%ymm14
vmovapd 1920(%rsp),%ymm14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x ta = int32 uuss1 * int32 FVGS19
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS19=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS19=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV19
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV19=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV19=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x out20plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out20plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out20plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS20
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS20=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS20=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV20
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV20=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV20=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out20 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out20=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out20=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out20 += out20plus
# asm 1: vpaddq <out20=reg256#13,<out20plus=reg256#9,<out20=reg256#13
# asm 2: vpaddq <out20=%ymm12,<out20plus=%ymm8,<out20=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod20
# asm 1: vpmuldq <d0=reg256#12,<mod20=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod20=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x tb = int32 d1 * int32 mod19
# asm 1: vpmuldq <d1=reg256#2,<mod19=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod19=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm: 4x out20plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out20plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out20plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out20plus2 += carryy
# asm 1: vpaddq <out20plus2=reg256#9,<carryy=reg256#4,<out20plus2=reg256#9
# asm 2: vpaddq <out20plus2=%ymm8,<carryy=%ymm3,<out20plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out20 += out20plus2
# asm 1: vpaddq <out20=reg256#13,<out20plus2=reg256#9,<out20=reg256#13
# asm 2: vpaddq <out20=%ymm12,<out20plus2=%ymm8,<out20=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x carryy = out20 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out20=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out20=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: out20 &= _2p30m1x4
# asm 1: vpand <out20=reg256#13,<_2p30m1x4=reg256#5,<out20=reg256#13
# asm 2: vpand <out20=%ymm12,<_2p30m1x4=%ymm4,<out20=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS18 = out20
# asm 1: vmovapd <out20=reg256#13,>stack_FVGS18=stack256#20
# asm 2: vmovapd <out20=%ymm12,>stack_FVGS18=736(%rsp)
vmovapd %ymm12,736(%rsp)

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: FVGS21 = stack_FVGS21
# asm 1: vmovapd <stack_FVGS21=stack256#23,>FVGS21=reg256#9
# asm 2: vmovapd <stack_FVGS21=832(%rsp),>FVGS21=%ymm8
vmovapd 832(%rsp),%ymm8

# qhasm: GSFV21 = FVGS21[1,0]
# asm 1: vpermq $0x4e,<FVGS21=reg256#9,>GSFV21=reg256#13
# asm 2: vpermq $0x4e,<FVGS21=%ymm8,>GSFV21=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: mod21 = stack_mod21
# asm 1: vmovapd <stack_mod21=stack256#58,>mod21=reg256#14
# asm 2: vmovapd <stack_mod21=1952(%rsp),>mod21=%ymm13
vmovapd 1952(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS20
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS20=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS20=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV20
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV20=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV20=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out21plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out21plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out21plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS21
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS21=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS21=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV21
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV21=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV21=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm: 4x out21 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out21=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out21=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x out21 += out21plus
# asm 1: vpaddq <out21=reg256#11,<out21plus=reg256#10,<out21=reg256#11
# asm 2: vpaddq <out21=%ymm10,<out21plus=%ymm9,<out21=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod21
# asm 1: vpmuldq <d0=reg256#12,<mod21=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod21=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x tb = int32 d1 * int32 mod20
# asm 1: vpmuldq <d1=reg256#2,<mod20=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod20=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out21plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out21plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out21plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out21plus2 += carryy
# asm 1: vpaddq <out21plus2=reg256#10,<carryy=reg256#4,<out21plus2=reg256#10
# asm 2: vpaddq <out21plus2=%ymm9,<carryy=%ymm3,<out21plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out21 += out21plus2
# asm 1: vpaddq <out21=reg256#11,<out21plus2=reg256#10,<out21=reg256#11
# asm 2: vpaddq <out21=%ymm10,<out21plus2=%ymm9,<out21=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out21 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out21=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out21=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: out21 &= _2p30m1x4
# asm 1: vpand <out21=reg256#11,<_2p30m1x4=reg256#5,<out21=reg256#11
# asm 2: vpand <out21=%ymm10,<_2p30m1x4=%ymm4,<out21=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS19 = out21
# asm 1: vmovapd <out21=reg256#11,>stack_FVGS19=stack256#21
# asm 2: vmovapd <out21=%ymm10,>stack_FVGS19=768(%rsp)
vmovapd %ymm10,768(%rsp)

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: FVGS22 = stack_FVGS22
# asm 1: vmovapd <stack_FVGS22=stack256#24,>FVGS22=reg256#10
# asm 2: vmovapd <stack_FVGS22=864(%rsp),>FVGS22=%ymm9
vmovapd 864(%rsp),%ymm9

# qhasm: GSFV22 = FVGS22[1,0]
# asm 1: vpermq $0x4e,<FVGS22=reg256#10,>GSFV22=reg256#11
# asm 2: vpermq $0x4e,<FVGS22=%ymm9,>GSFV22=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: mod22 = stack_mod22
# asm 1: vmovapd <stack_mod22=stack256#59,>mod22=reg256#15
# asm 2: vmovapd <stack_mod22=1984(%rsp),>mod22=%ymm14
vmovapd 1984(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS21
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS21=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS21=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV21
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV21=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV21=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out22plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out22plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out22plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS22
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS22=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS22=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV22
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV22=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV22=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out22 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out22=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out22=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm: 4x out22 += out22plus
# asm 1: vpaddq <out22=reg256#13,<out22plus=reg256#9,<out22=reg256#13
# asm 2: vpaddq <out22=%ymm12,<out22plus=%ymm8,<out22=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod22
# asm 1: vpmuldq <d0=reg256#12,<mod22=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod22=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x tb = int32 d1 * int32 mod21
# asm 1: vpmuldq <d1=reg256#2,<mod21=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod21=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm: 4x out22plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out22plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out22plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out22plus2 += carryy
# asm 1: vpaddq <out22plus2=reg256#9,<carryy=reg256#4,<out22plus2=reg256#9
# asm 2: vpaddq <out22plus2=%ymm8,<carryy=%ymm3,<out22plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out22 += out22plus2
# asm 1: vpaddq <out22=reg256#13,<out22plus2=reg256#9,<out22=reg256#13
# asm 2: vpaddq <out22=%ymm12,<out22plus2=%ymm8,<out22=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x carryy = out22 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out22=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out22=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: out22 &= _2p30m1x4
# asm 1: vpand <out22=reg256#13,<_2p30m1x4=reg256#5,<out22=reg256#13
# asm 2: vpand <out22=%ymm12,<_2p30m1x4=%ymm4,<out22=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS20 = out22
# asm 1: vmovapd <out22=reg256#13,>stack_FVGS20=stack256#22
# asm 2: vmovapd <out22=%ymm12,>stack_FVGS20=800(%rsp)
vmovapd %ymm12,800(%rsp)

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: FVGS23 = stack_FVGS23
# asm 1: vmovapd <stack_FVGS23=stack256#25,>FVGS23=reg256#9
# asm 2: vmovapd <stack_FVGS23=896(%rsp),>FVGS23=%ymm8
vmovapd 896(%rsp),%ymm8

# qhasm: GSFV23 = FVGS23[1,0]
# asm 1: vpermq $0x4e,<FVGS23=reg256#9,>GSFV23=reg256#13
# asm 2: vpermq $0x4e,<FVGS23=%ymm8,>GSFV23=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: mod23 = stack_mod23
# asm 1: vmovapd <stack_mod23=stack256#60,>mod23=reg256#14
# asm 2: vmovapd <stack_mod23=2016(%rsp),>mod23=%ymm13
vmovapd 2016(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS22
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS22=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS22=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV22
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV22=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV22=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out23plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out23plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out23plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x ta = int32 uuss0 * int32 FVGS23
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS23=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS23=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV23
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV23=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV23=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out23 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out23=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out23=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm: 4x out23 += out23plus
# asm 1: vpaddq <out23=reg256#11,<out23plus=reg256#10,<out23=reg256#11
# asm 2: vpaddq <out23=%ymm10,<out23plus=%ymm9,<out23=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x ta = int32 d0 * int32 mod23
# asm 1: vpmuldq <d0=reg256#12,<mod23=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod23=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod22
# asm 1: vpmuldq <d1=reg256#2,<mod22=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod22=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out23plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out23plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out23plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out23plus2 += carryy
# asm 1: vpaddq <out23plus2=reg256#10,<carryy=reg256#4,<out23plus2=reg256#10
# asm 2: vpaddq <out23plus2=%ymm9,<carryy=%ymm3,<out23plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm: 4x out23 += out23plus2
# asm 1: vpaddq <out23=reg256#11,<out23plus2=reg256#10,<out23=reg256#11
# asm 2: vpaddq <out23=%ymm10,<out23plus2=%ymm9,<out23=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x carryy = out23 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out23=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out23=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: out23 &= _2p30m1x4
# asm 1: vpand <out23=reg256#11,<_2p30m1x4=reg256#5,<out23=reg256#11
# asm 2: vpand <out23=%ymm10,<_2p30m1x4=%ymm4,<out23=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS21 = out23
# asm 1: vmovapd <out23=reg256#11,>stack_FVGS21=stack256#23
# asm 2: vmovapd <out23=%ymm10,>stack_FVGS21=832(%rsp)
vmovapd %ymm10,832(%rsp)

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: FVGS24 = stack_FVGS24
# asm 1: vmovapd <stack_FVGS24=stack256#26,>FVGS24=reg256#10
# asm 2: vmovapd <stack_FVGS24=928(%rsp),>FVGS24=%ymm9
vmovapd 928(%rsp),%ymm9

# qhasm: GSFV24 = FVGS24[1,0]
# asm 1: vpermq $0x4e,<FVGS24=reg256#10,>GSFV24=reg256#11
# asm 2: vpermq $0x4e,<FVGS24=%ymm9,>GSFV24=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: mod24 = stack_mod24
# asm 1: vmovapd <stack_mod24=stack256#61,>mod24=reg256#15
# asm 2: vmovapd <stack_mod24=2048(%rsp),>mod24=%ymm14
vmovapd 2048(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS23
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS23=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS23=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV23
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV23=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV23=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out24plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out24plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out24plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x ta = int32 uuss0 * int32 FVGS24
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS24=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS24=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV24
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV24=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV24=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out24 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out24=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out24=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm: 4x out24 += out24plus
# asm 1: vpaddq <out24=reg256#13,<out24plus=reg256#9,<out24=reg256#13
# asm 2: vpaddq <out24=%ymm12,<out24plus=%ymm8,<out24=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x ta = int32 d0 * int32 mod24
# asm 1: vpmuldq <d0=reg256#12,<mod24=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod24=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod23
# asm 1: vpmuldq <d1=reg256#2,<mod23=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod23=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out24plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out24plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out24plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out24plus2 += carryy
# asm 1: vpaddq <out24plus2=reg256#9,<carryy=reg256#4,<out24plus2=reg256#9
# asm 2: vpaddq <out24plus2=%ymm8,<carryy=%ymm3,<out24plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: 4x out24 += out24plus2
# asm 1: vpaddq <out24=reg256#13,<out24plus2=reg256#9,<out24=reg256#13
# asm 2: vpaddq <out24=%ymm12,<out24plus2=%ymm8,<out24=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out24 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out24=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out24=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out24 &= _2p30m1x4
# asm 1: vpand <out24=reg256#13,<_2p30m1x4=reg256#5,<out24=reg256#13
# asm 2: vpand <out24=%ymm12,<_2p30m1x4=%ymm4,<out24=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS22 = out24
# asm 1: vmovapd <out24=reg256#13,>stack_FVGS22=stack256#24
# asm 2: vmovapd <out24=%ymm12,>stack_FVGS22=864(%rsp)
vmovapd %ymm12,864(%rsp)

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: FVGS25 = stack_FVGS25
# asm 1: vmovapd <stack_FVGS25=stack256#27,>FVGS25=reg256#9
# asm 2: vmovapd <stack_FVGS25=960(%rsp),>FVGS25=%ymm8
vmovapd 960(%rsp),%ymm8

# qhasm: GSFV25 = FVGS25[1,0]
# asm 1: vpermq $0x4e,<FVGS25=reg256#9,>GSFV25=reg256#13
# asm 2: vpermq $0x4e,<FVGS25=%ymm8,>GSFV25=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: mod25 = stack_mod25
# asm 1: vmovapd <stack_mod25=stack256#62,>mod25=reg256#14
# asm 2: vmovapd <stack_mod25=2080(%rsp),>mod25=%ymm13
vmovapd 2080(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS24
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS24=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS24=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV24
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV24=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV24=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out25plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out25plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out25plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x ta = int32 uuss0 * int32 FVGS25
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS25=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS25=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV25
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV25=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV25=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out25 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out25=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out25=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm: 4x out25 += out25plus
# asm 1: vpaddq <out25=reg256#11,<out25plus=reg256#10,<out25=reg256#11
# asm 2: vpaddq <out25=%ymm10,<out25plus=%ymm9,<out25=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x ta = int32 d0 * int32 mod25
# asm 1: vpmuldq <d0=reg256#12,<mod25=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod25=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod24
# asm 1: vpmuldq <d1=reg256#2,<mod24=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod24=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x out25plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out25plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out25plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out25plus2 += carryy
# asm 1: vpaddq <out25plus2=reg256#10,<carryy=reg256#4,<out25plus2=reg256#10
# asm 2: vpaddq <out25plus2=%ymm9,<carryy=%ymm3,<out25plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out25 += out25plus2
# asm 1: vpaddq <out25=reg256#11,<out25plus2=reg256#10,<out25=reg256#11
# asm 2: vpaddq <out25=%ymm10,<out25plus2=%ymm9,<out25=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out25 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out25=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out25=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out25 &= _2p30m1x4
# asm 1: vpand <out25=reg256#11,<_2p30m1x4=reg256#5,<out25=reg256#11
# asm 2: vpand <out25=%ymm10,<_2p30m1x4=%ymm4,<out25=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: stack_FVGS23 = out25
# asm 1: vmovapd <out25=reg256#11,>stack_FVGS23=stack256#25
# asm 2: vmovapd <out25=%ymm10,>stack_FVGS23=896(%rsp)
vmovapd %ymm10,896(%rsp)

# qhasm: FVGS26 = stack_FVGS26
# asm 1: vmovapd <stack_FVGS26=stack256#28,>FVGS26=reg256#10
# asm 2: vmovapd <stack_FVGS26=992(%rsp),>FVGS26=%ymm9
vmovapd 992(%rsp),%ymm9

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: GSFV26 = FVGS26[1,0]
# asm 1: vpermq $0x4e,<FVGS26=reg256#10,>GSFV26=reg256#11
# asm 2: vpermq $0x4e,<FVGS26=%ymm9,>GSFV26=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod26 = stack_mod26
# asm 1: vmovapd <stack_mod26=stack256#63,>mod26=reg256#15
# asm 2: vmovapd <stack_mod26=2112(%rsp),>mod26=%ymm14
vmovapd 2112(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS25
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS25=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS25=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV25
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV25=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV25=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out26plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out26plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out26plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS26
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS26=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS26=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV26
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV26=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV26=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out26 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out26=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out26=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm: 4x out26 += out26plus
# asm 1: vpaddq <out26=reg256#13,<out26plus=reg256#9,<out26=reg256#13
# asm 2: vpaddq <out26=%ymm12,<out26plus=%ymm8,<out26=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x ta = int32 d0 * int32 mod26
# asm 1: vpmuldq <d0=reg256#12,<mod26=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod26=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod25
# asm 1: vpmuldq <d1=reg256#2,<mod25=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod25=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out26plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out26plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out26plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out26plus2 += carryy
# asm 1: vpaddq <out26plus2=reg256#9,<carryy=reg256#4,<out26plus2=reg256#9
# asm 2: vpaddq <out26plus2=%ymm8,<carryy=%ymm3,<out26plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out26 += out26plus2
# asm 1: vpaddq <out26=reg256#13,<out26plus2=reg256#9,<out26=reg256#13
# asm 2: vpaddq <out26=%ymm12,<out26plus2=%ymm8,<out26=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out26 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out26=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out26=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: out26 &= _2p30m1x4
# asm 1: vpand <out26=reg256#13,<_2p30m1x4=reg256#5,<out26=reg256#13
# asm 2: vpand <out26=%ymm12,<_2p30m1x4=%ymm4,<out26=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS24 = out26
# asm 1: vmovapd <out26=reg256#13,>stack_FVGS24=stack256#26
# asm 2: vmovapd <out26=%ymm12,>stack_FVGS24=928(%rsp)
vmovapd %ymm12,928(%rsp)

# qhasm: FVGS27 = stack_FVGS27
# asm 1: vmovapd <stack_FVGS27=stack256#29,>FVGS27=reg256#9
# asm 2: vmovapd <stack_FVGS27=1024(%rsp),>FVGS27=%ymm8
vmovapd 1024(%rsp),%ymm8

# qhasm: GSFV27 = FVGS27[1,0]
# asm 1: vpermq $0x4e,<FVGS27=reg256#9,>GSFV27=reg256#13
# asm 2: vpermq $0x4e,<FVGS27=%ymm8,>GSFV27=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: mod27 = stack_mod27
# asm 1: vmovapd <stack_mod27=stack256#64,>mod27=reg256#14
# asm 2: vmovapd <stack_mod27=2144(%rsp),>mod27=%ymm13
vmovapd 2144(%rsp),%ymm13

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x ta = int32 uuss1 * int32 FVGS26
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS26=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS26=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV26
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV26=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV26=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out27plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out27plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out27plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS27
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS27=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS27=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV27
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV27=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV27=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out27 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out27=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out27=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm: 4x out27 += out27plus
# asm 1: vpaddq <out27=reg256#11,<out27plus=reg256#10,<out27=reg256#11
# asm 2: vpaddq <out27=%ymm10,<out27plus=%ymm9,<out27=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x ta = int32 d0 * int32 mod27
# asm 1: vpmuldq <d0=reg256#12,<mod27=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod27=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm: 4x tb = int32 d1 * int32 mod26
# asm 1: vpmuldq <d1=reg256#2,<mod26=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod26=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out27plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out27plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out27plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm: 4x out27plus2 += carryy
# asm 1: vpaddq <out27plus2=reg256#10,<carryy=reg256#4,<out27plus2=reg256#10
# asm 2: vpaddq <out27plus2=%ymm9,<carryy=%ymm3,<out27plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out27 += out27plus2
# asm 1: vpaddq <out27=reg256#11,<out27plus2=reg256#10,<out27=reg256#11
# asm 2: vpaddq <out27=%ymm10,<out27plus2=%ymm9,<out27=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out27 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out27=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out27=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out27 &= _2p30m1x4
# asm 1: vpand <out27=reg256#11,<_2p30m1x4=reg256#5,<out27=reg256#11
# asm 2: vpand <out27=%ymm10,<_2p30m1x4=%ymm4,<out27=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: stack_FVGS25 = out27
# asm 1: vmovapd <out27=reg256#11,>stack_FVGS25=stack256#27
# asm 2: vmovapd <out27=%ymm10,>stack_FVGS25=960(%rsp)
vmovapd %ymm10,960(%rsp)

# qhasm: FVGS28 = stack_FVGS28
# asm 1: vmovapd <stack_FVGS28=stack256#30,>FVGS28=reg256#10
# asm 2: vmovapd <stack_FVGS28=1056(%rsp),>FVGS28=%ymm9
vmovapd 1056(%rsp),%ymm9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#7
# asm 2: movq <stack_m1=136(%rsp),>z=%rax
movq 136(%rsp),%rax

# qhasm: GSFV28 = FVGS28[1,0]
# asm 1: vpermq $0x4e,<FVGS28=reg256#10,>GSFV28=reg256#11
# asm 2: vpermq $0x4e,<FVGS28=%ymm9,>GSFV28=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod28 = stack_mod28
# asm 1: vmovapd <stack_mod28=stack256#65,>mod28=reg256#15
# asm 2: vmovapd <stack_mod28=2176(%rsp),>mod28=%ymm14
vmovapd 2176(%rsp),%ymm14

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x ta = int32 uuss1 * int32 FVGS27
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS27=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS27=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV27
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV27=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV27=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x out28plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out28plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out28plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS28
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS28=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS28=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV28
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV28=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV28=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out28 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out28=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out28=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x out28 += out28plus
# asm 1: vpaddq <out28=reg256#13,<out28plus=reg256#9,<out28=reg256#13
# asm 2: vpaddq <out28=%ymm12,<out28plus=%ymm8,<out28=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod28
# asm 1: vpmuldq <d0=reg256#12,<mod28=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod28=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod27
# asm 1: vpmuldq <d1=reg256#2,<mod27=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod27=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out28plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out28plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out28plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x out28plus2 += carryy
# asm 1: vpaddq <out28plus2=reg256#9,<carryy=reg256#4,<out28plus2=reg256#9
# asm 2: vpaddq <out28plus2=%ymm8,<carryy=%ymm3,<out28plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x out28 += out28plus2
# asm 1: vpaddq <out28=reg256#13,<out28plus2=reg256#9,<out28=reg256#13
# asm 2: vpaddq <out28=%ymm12,<out28plus2=%ymm8,<out28=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out28 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out28=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out28=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out28 &= _2p30m1x4
# asm 1: vpand <out28=reg256#13,<_2p30m1x4=reg256#5,<out28=reg256#13
# asm 2: vpand <out28=%ymm12,<_2p30m1x4=%ymm4,<out28=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: stack_FVGS26 = out28
# asm 1: vmovapd <out28=reg256#13,>stack_FVGS26=stack256#28
# asm 2: vmovapd <out28=%ymm12,>stack_FVGS26=992(%rsp)
vmovapd %ymm12,992(%rsp)

# qhasm: FVGS29 = stack_FVGS29
# asm 1: vmovapd <stack_FVGS29=stack256#31,>FVGS29=reg256#9
# asm 2: vmovapd <stack_FVGS29=1088(%rsp),>FVGS29=%ymm8
vmovapd 1088(%rsp),%ymm8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: GSFV29 = FVGS29[1,0]
# asm 1: vpermq $0x4e,<FVGS29=reg256#9,>GSFV29=reg256#13
# asm 2: vpermq $0x4e,<FVGS29=%ymm8,>GSFV29=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod29 = stack_mod29
# asm 1: vmovapd <stack_mod29=stack256#66,>mod29=reg256#14
# asm 2: vmovapd <stack_mod29=2208(%rsp),>mod29=%ymm13
vmovapd 2208(%rsp),%ymm13

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x ta = int32 uuss1 * int32 FVGS28
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS28=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS28=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV28
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV28=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV28=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x out29plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out29plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out29plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS29
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS29=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS29=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV29
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV29=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV29=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm: 4x out29 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out29=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out29=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x out29 += out29plus
# asm 1: vpaddq <out29=reg256#11,<out29plus=reg256#10,<out29=reg256#11
# asm 2: vpaddq <out29=%ymm10,<out29plus=%ymm9,<out29=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod29
# asm 1: vpmuldq <d0=reg256#12,<mod29=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod29=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x tb = int32 d1 * int32 mod28
# asm 1: vpmuldq <d1=reg256#2,<mod28=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod28=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out29plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out29plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out29plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x out29plus2 += carryy
# asm 1: vpaddq <out29plus2=reg256#10,<carryy=reg256#4,<out29plus2=reg256#10
# asm 2: vpaddq <out29plus2=%ymm9,<carryy=%ymm3,<out29plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm: 4x out29 += out29plus2
# asm 1: vpaddq <out29=reg256#11,<out29plus2=reg256#10,<out29=reg256#11
# asm 2: vpaddq <out29=%ymm10,<out29plus2=%ymm9,<out29=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x carryy = out29 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out29=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out29=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: out29 &= _2p30m1x4
# asm 1: vpand <out29=reg256#11,<_2p30m1x4=reg256#5,<out29=reg256#11
# asm 2: vpand <out29=%ymm10,<_2p30m1x4=%ymm4,<out29=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS27 = out29
# asm 1: vmovapd <out29=reg256#11,>stack_FVGS27=stack256#29
# asm 2: vmovapd <out29=%ymm10,>stack_FVGS27=1024(%rsp)
vmovapd %ymm10,1024(%rsp)

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: FVGS30 = stack_FVGS30
# asm 1: vmovapd <stack_FVGS30=stack256#32,>FVGS30=reg256#10
# asm 2: vmovapd <stack_FVGS30=1120(%rsp),>FVGS30=%ymm9
vmovapd 1120(%rsp),%ymm9

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: GSFV30 = FVGS30[1,0]
# asm 1: vpermq $0x4e,<FVGS30=reg256#10,>GSFV30=reg256#11
# asm 2: vpermq $0x4e,<FVGS30=%ymm9,>GSFV30=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm: mod30 = stack_mod30
# asm 1: vmovapd <stack_mod30=stack256#67,>mod30=reg256#15
# asm 2: vmovapd <stack_mod30=2240(%rsp),>mod30=%ymm14
vmovapd 2240(%rsp),%ymm14

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x ta = int32 uuss1 * int32 FVGS29
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS29=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS29=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV29
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV29=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV29=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: 4x out30plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out30plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out30plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS30
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS30=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS30=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV30
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV30=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV30=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out30 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out30=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out30=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: 4x out30 += out30plus
# asm 1: vpaddq <out30=reg256#13,<out30plus=reg256#9,<out30=reg256#13
# asm 2: vpaddq <out30=%ymm12,<out30plus=%ymm8,<out30=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod30
# asm 1: vpmuldq <d0=reg256#12,<mod30=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod30=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x tb = int32 d1 * int32 mod29
# asm 1: vpmuldq <d1=reg256#2,<mod29=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod29=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm: 4x out30plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out30plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out30plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x out30plus2 += carryy
# asm 1: vpaddq <out30plus2=reg256#9,<carryy=reg256#4,<out30plus2=reg256#9
# asm 2: vpaddq <out30plus2=%ymm8,<carryy=%ymm3,<out30plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out30 += out30plus2
# asm 1: vpaddq <out30=reg256#13,<out30plus2=reg256#9,<out30=reg256#13
# asm 2: vpaddq <out30=%ymm12,<out30plus2=%ymm8,<out30=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x carryy = out30 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out30=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out30=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: out30 &= _2p30m1x4
# asm 1: vpand <out30=reg256#13,<_2p30m1x4=reg256#5,<out30=reg256#13
# asm 2: vpand <out30=%ymm12,<_2p30m1x4=%ymm4,<out30=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS28 = out30
# asm 1: vmovapd <out30=reg256#13,>stack_FVGS28=stack256#30
# asm 2: vmovapd <out30=%ymm12,>stack_FVGS28=1056(%rsp)
vmovapd %ymm12,1056(%rsp)

# qhasm: FVGS31 = stack_FVGS31
# asm 1: vmovapd <stack_FVGS31=stack256#33,>FVGS31=reg256#9
# asm 2: vmovapd <stack_FVGS31=1152(%rsp),>FVGS31=%ymm8
vmovapd 1152(%rsp),%ymm8

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: GSFV31 = FVGS31[1,0]
# asm 1: vpermq $0x4e,<FVGS31=reg256#9,>GSFV31=reg256#13
# asm 2: vpermq $0x4e,<FVGS31=%ymm8,>GSFV31=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod31 = stack_mod31
# asm 1: vmovapd <stack_mod31=stack256#68,>mod31=reg256#14
# asm 2: vmovapd <stack_mod31=2272(%rsp),>mod31=%ymm13
vmovapd 2272(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS30
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS30=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS30=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV30
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV30=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV30=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: 4x out31plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out31plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out31plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm: 4x ta = int32 uuss0 * int32 FVGS31
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS31=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS31=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#7
# asm 2: mov  $-1,>z=%rax
mov  $-1,%rax

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV31
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV31=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV31=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm: 4x out31 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out31=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out31=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#9
# asm 2: mov  <grs=%r8,>oldg=%r11
mov  %r8,%r11

# qhasm: 4x out31 += out31plus
# asm 1: vpaddq <out31=reg256#11,<out31plus=reg256#10,<out31=reg256#11
# asm 2: vpaddq <out31=%ymm10,<out31plus=%ymm9,<out31=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod31
# asm 1: vpmuldq <d0=reg256#12,<mod31=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod31=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#3),>h=int64#10
# asm 2: lea  (<grs=%r8,<fuv=%rdx),>h=%r12
lea  (%r8,%rdx),%r12

# qhasm: 4x tb = int32 d1 * int32 mod30
# asm 1: vpmuldq <d1=reg256#2,<mod30=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod30=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out31plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out31plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out31plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm: 4x out31plus2 += carryy
# asm 1: vpaddq <out31plus2=reg256#10,<carryy=reg256#4,<out31plus2=reg256#10
# asm 2: vpaddq <out31plus2=%ymm9,<carryy=%ymm3,<out31plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm: 4x out31 += out31plus2
# asm 1: vpaddq <out31=reg256#11,<out31plus2=reg256#10,<out31=reg256#11
# asm 2: vpaddq <out31=%ymm10,<out31plus2=%ymm9,<out31=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#7
# asm 2: cmovne <m=%r9,<z=%rax
cmovne %r9,%rax

# qhasm: 4x carryy = out31 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out31=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out31=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#10
# asm 2: cmove <grs=%r8,<h=%r12
cmove %r8,%r12

# qhasm: out31 &= _2p30m1x4
# asm 1: vpand <out31=reg256#11,<_2p30m1x4=reg256#5,<out31=reg256#11
# asm 2: vpand <out31=%ymm10,<_2p30m1x4=%ymm4,<out31=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS29 = out31
# asm 1: vmovapd <out31=reg256#11,>stack_FVGS29=stack256#31
# asm 2: vmovapd <out31=%ymm10,>stack_FVGS29=1088(%rsp)
vmovapd %ymm10,1088(%rsp)

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#11
# asm 2: lea  1(<m=%r9),>mnew=%r13
lea  1(%r9),%r13

# qhasm: FVGS32 = stack_FVGS32
# asm 1: vmovapd <stack_FVGS32=stack256#34,>FVGS32=reg256#10
# asm 2: vmovapd <stack_FVGS32=1184(%rsp),>FVGS32=%ymm9
vmovapd 1184(%rsp),%ymm9

# qhasm: GSFV32 = FVGS32[1,0]
# asm 1: vpermq $0x4e,<FVGS32=reg256#10,>GSFV32=reg256#11
# asm 2: vpermq $0x4e,<FVGS32=%ymm9,>GSFV32=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#3,<grs=int64#5
# asm 2: sub  <fuv=%rdx,<grs=%r8
sub  %rdx,%r8

# qhasm: mod32 = stack_mod32
# asm 1: vmovapd <stack_mod32=stack256#69,>mod32=reg256#15
# asm 2: vmovapd <stack_mod32=2304(%rsp),>mod32=%ymm14
vmovapd 2304(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS31
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS31=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS31=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV31
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV31=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV31=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out32plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out32plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out32plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS32
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS32=reg256#10,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS32=%ymm9,>ta=%ymm12
vpmuldq %ymm5,%ymm9,%ymm12

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#10
# asm 2: sar  $1,<h=%r12
sar  $1,%r12

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV32
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV32=reg256#11,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV32=%ymm10,>tb=%ymm15
vpmuldq %ymm6,%ymm10,%ymm15

# qhasm: 4x out32 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#13,>out32=reg256#13
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm12,>out32=%ymm12
vpaddq %ymm15,%ymm12,%ymm12

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm: 4x out32 += out32plus
# asm 1: vpaddq <out32=reg256#13,<out32plus=reg256#9,<out32=reg256#13
# asm 2: vpaddq <out32=%ymm12,<out32plus=%ymm8,<out32=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x ta = int32 d0 * int32 mod32
# asm 1: vpmuldq <d0=reg256#12,<mod32=reg256#15,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod32=%ymm14,>ta=%ymm8
vpmuldq %ymm11,%ymm14,%ymm8

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#7
# asm 2: cmp  $0,<z=%rax
cmp  $0,%rax

# qhasm: 4x tb = int32 d1 * int32 mod31
# asm 1: vpmuldq <d1=reg256#2,<mod31=reg256#14,>tb=reg256#14
# asm 2: vpmuldq <d1=%ymm1,<mod31=%ymm13,>tb=%ymm13
vpmuldq %ymm1,%ymm13,%ymm13

# qhasm: 4x out32plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#14,<ta=reg256#9,>out32plus2=reg256#9
# asm 2: vpaddq <tb=%ymm13,<ta=%ymm8,>out32plus2=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#9,<fuv=int64#3
# asm 2: cmovge <oldg=%r11,<fuv=%rdx
cmovge %r11,%rdx

# qhasm: 4x out32plus2 += carryy
# asm 1: vpaddq <out32plus2=reg256#9,<carryy=reg256#4,<out32plus2=reg256#9
# asm 2: vpaddq <out32plus2=%ymm8,<carryy=%ymm3,<out32plus2=%ymm8
vpaddq %ymm8,%ymm3,%ymm8

# qhasm: 4x out32 += out32plus2
# asm 1: vpaddq <out32=reg256#13,<out32plus2=reg256#9,<out32=reg256#13
# asm 2: vpaddq <out32=%ymm12,<out32plus2=%ymm8,<out32=%ymm12
vpaddq %ymm12,%ymm8,%ymm12

# qhasm: 4x carryy = out32 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out32=reg256#13,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out32=%ymm12,>carryy=%ymm3
vpaddq %ymm7,%ymm12,%ymm3

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#10,<grs=int64#5
# asm 2: cmovl <h=%r12,<grs=%r8
cmovl %r12,%r8

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#11,<m=int64#6
# asm 2: cmovl <mnew=%r13,<m=%r9
cmovl %r13,%r9

# qhasm: out32 &= _2p30m1x4
# asm 1: vpand <out32=reg256#13,<_2p30m1x4=reg256#5,<out32=reg256#13
# asm 2: vpand <out32=%ymm12,<_2p30m1x4=%ymm4,<out32=%ymm12
vpand %ymm12,%ymm4,%ymm12

# qhasm: stack_FVGS30 = out32
# asm 1: vmovapd <out32=reg256#13,>stack_FVGS30=stack256#32
# asm 2: vmovapd <out32=%ymm12,>stack_FVGS30=1120(%rsp)
vmovapd %ymm12,1120(%rsp)

# qhasm: extract_init:
._extract_init:

# qhasm:   _2p20a2p41 = stack_2p20a2p41
# asm 1: movq <stack_2p20a2p41=stack64#14,>_2p20a2p41=int64#7
# asm 2: movq <stack_2p20a2p41=104(%rsp),>_2p20a2p41=%rax
movq 104(%rsp),%rax

# qhasm: FVGS33 = stack_FVGS33
# asm 1: vmovapd <stack_FVGS33=stack256#35,>FVGS33=reg256#9
# asm 2: vmovapd <stack_FVGS33=1216(%rsp),>FVGS33=%ymm8
vmovapd 1216(%rsp),%ymm8

# qhasm: GSFV33 = FVGS33[1,0]
# asm 1: vpermq $0x4e,<FVGS33=reg256#9,>GSFV33=reg256#13
# asm 2: vpermq $0x4e,<FVGS33=%ymm8,>GSFV33=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod33 = stack_mod33
# asm 1: vmovapd <stack_mod33=stack256#70,>mod33=reg256#14
# asm 2: vmovapd <stack_mod33=2336(%rsp),>mod33=%ymm13
vmovapd 2336(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS32
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS32=reg256#10,>ta=reg256#10
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS32=%ymm9,>ta=%ymm9
vpmuldq %ymm2,%ymm9,%ymm9

# qhasm:   s = grs + _2p20a2p41
# asm 1: lea  (<grs=int64#5,<_2p20a2p41=int64#7),>s=int64#9
# asm 2: lea  (<grs=%r8,<_2p20a2p41=%rax),>s=%r11
lea  (%r8,%rax),%r11

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV32
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV32=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV32=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out33plus = ta + tb
# asm 1: vpaddq <tb=reg256#11,<ta=reg256#10,>out33plus=reg256#10
# asm 2: vpaddq <tb=%ymm10,<ta=%ymm9,>out33plus=%ymm9
vpaddq %ymm10,%ymm9,%ymm9

# qhasm:   (int64) s >>= 42
# asm 1: sar  $42,<s=int64#9
# asm 2: sar  $42,<s=%r11
sar  $42,%r11

# qhasm: 4x ta = int32 uuss0 * int32 FVGS33
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS33=reg256#9,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS33=%ymm8,>ta=%ymm10
vpmuldq %ymm5,%ymm8,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV33
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV33=reg256#13,>tb=reg256#16
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV33=%ymm12,>tb=%ymm15
vpmuldq %ymm6,%ymm12,%ymm15

# qhasm: 4x out33 = ta + tb
# asm 1: vpaddq <tb=reg256#16,<ta=reg256#11,>out33=reg256#11
# asm 2: vpaddq <tb=%ymm15,<ta=%ymm10,>out33=%ymm10
vpaddq %ymm15,%ymm10,%ymm10

# qhasm:   t2 = g
# asm 1: mov  <g=int64#1,>t2=int64#10
# asm 2: mov  <g=%rdi,>t2=%r12
mov  %rdi,%r12

# qhasm: 4x out33 += out33plus
# asm 1: vpaddq <out33=reg256#11,<out33plus=reg256#10,<out33=reg256#11
# asm 2: vpaddq <out33=%ymm10,<out33plus=%ymm9,<out33=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod33
# asm 1: vpmuldq <d0=reg256#12,<mod33=reg256#14,>ta=reg256#10
# asm 2: vpmuldq <d0=%ymm11,<mod33=%ymm13,>ta=%ymm9
vpmuldq %ymm11,%ymm13,%ymm9

# qhasm:   g *= s  
# asm 1: imul  <s=int64#9,<g=int64#1
# asm 2: imul  <s=%r11,<g=%rdi
imul  %r11,%rdi

# qhasm: 4x tb = int32 d1 * int32 mod32
# asm 1: vpmuldq <d1=reg256#2,<mod32=reg256#15,>tb=reg256#15
# asm 2: vpmuldq <d1=%ymm1,<mod32=%ymm14,>tb=%ymm14
vpmuldq %ymm1,%ymm14,%ymm14

# qhasm: 4x out33plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#10,>out33plus2=reg256#10
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm9,>out33plus2=%ymm9
vpaddq %ymm14,%ymm9,%ymm9

# qhasm:   v = fuv + _2p20a2p41
# asm 1: lea  (<fuv=int64#3,<_2p20a2p41=int64#7),>v=int64#7
# asm 2: lea  (<fuv=%rdx,<_2p20a2p41=%rax),>v=%rax
lea  (%rdx,%rax),%rax

# qhasm: 4x out33plus2 += carryy
# asm 1: vpaddq <out33plus2=reg256#10,<carryy=reg256#4,<out33plus2=reg256#10
# asm 2: vpaddq <out33plus2=%ymm9,<carryy=%ymm3,<out33plus2=%ymm9
vpaddq %ymm9,%ymm3,%ymm9

# qhasm: 4x out33 += out33plus2
# asm 1: vpaddq <out33=reg256#11,<out33plus2=reg256#10,<out33=reg256#11
# asm 2: vpaddq <out33=%ymm10,<out33plus2=%ymm9,<out33=%ymm10
vpaddq %ymm10,%ymm9,%ymm10

# qhasm:   (int64) v >>= 42
# asm 1: sar  $42,<v=int64#7
# asm 2: sar  $42,<v=%rax
sar  $42,%rax

# qhasm: 4x carryy = out33 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out33=reg256#11,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out33=%ymm10,>carryy=%ymm3
vpaddq %ymm7,%ymm10,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   t2 *= v
# asm 1: imul  <v=int64#7,<t2=int64#10
# asm 2: imul  <v=%rax,<t2=%r12
imul  %rax,%r12

# qhasm: out33 &= _2p30m1x4
# asm 1: vpand <out33=reg256#11,<_2p30m1x4=reg256#5,<out33=reg256#11
# asm 2: vpand <out33=%ymm10,<_2p30m1x4=%ymm4,<out33=%ymm10
vpand %ymm10,%ymm4,%ymm10

# qhasm: stack_FVGS31 = out33
# asm 1: vmovapd <out33=reg256#11,>stack_FVGS31=stack256#33
# asm 2: vmovapd <out33=%ymm10,>stack_FVGS31=1152(%rsp)
vmovapd %ymm10,1152(%rsp)

# qhasm:   _2p20 = stack_2p20
# asm 1: movq <stack_2p20=stack64#11,>_2p20=int64#11
# asm 2: movq <stack_2p20=80(%rsp),>_2p20=%r13
movq 80(%rsp),%r13

# qhasm: FVGS34 = stack_FVGS34
# asm 1: vmovapd <stack_FVGS34=stack256#36,>FVGS34=reg256#10
# asm 2: vmovapd <stack_FVGS34=1248(%rsp),>FVGS34=%ymm9
vmovapd 1248(%rsp),%ymm9

# qhasm: GSFV34 = FVGS34[1,0]
# asm 1: vpermq $0x4e,<FVGS34=reg256#10,>GSFV34=reg256#11
# asm 2: vpermq $0x4e,<FVGS34=%ymm9,>GSFV34=%ymm10
vpermq $0x4e,%ymm9,%ymm10

# qhasm:   r = grs + _2p20
# asm 1: lea  (<grs=int64#5,<_2p20=int64#11),>r=int64#5
# asm 2: lea  (<grs=%r8,<_2p20=%r13),>r=%r8
lea  (%r8,%r13),%r8

# qhasm: mod34 = stack_mod34
# asm 1: vmovapd <stack_mod34=stack256#71,>mod34=reg256#15
# asm 2: vmovapd <stack_mod34=2368(%rsp),>mod34=%ymm14
vmovapd 2368(%rsp),%ymm14

# qhasm: 4x ta = int32 uuss1 * int32 FVGS33
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS33=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS33=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm:   r <<= 22
# asm 1: shl  $22,<r=int64#5
# asm 2: shl  $22,<r=%r8
shl  $22,%r8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV33
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV33=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV33=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out34plus = ta + tb
# asm 1: vpaddq <tb=reg256#13,<ta=reg256#9,>out34plus=reg256#9
# asm 2: vpaddq <tb=%ymm12,<ta=%ymm8,>out34plus=%ymm8
vpaddq %ymm12,%ymm8,%ymm8

# qhasm:   (int64) r >>= 43
# asm 1: sar  $43,<r=int64#5
# asm 2: sar  $43,<r=%r8
sar  $43,%r8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS34
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS34=reg256#10,>ta=reg256#6
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS34=%ymm9,>ta=%ymm5
vpmuldq %ymm5,%ymm9,%ymm5

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV34
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV34=reg256#11,>tb=reg256#7
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV34=%ymm10,>tb=%ymm6
vpmuldq %ymm6,%ymm10,%ymm6

# qhasm:       rax = f
# asm 1: mov  <f=int64#4,>rax=int64#12
# asm 2: mov  <f=%rcx,>rax=%r14
mov  %rcx,%r14

# qhasm: 4x out34 = ta + tb
# asm 1: vpaddq <tb=reg256#7,<ta=reg256#6,>out34=reg256#6
# asm 2: vpaddq <tb=%ymm6,<ta=%ymm5,>out34=%ymm5
vpaddq %ymm6,%ymm5,%ymm5

# qhasm: 4x out34 += out34plus
# asm 1: vpaddq <out34=reg256#6,<out34plus=reg256#9,<out34=reg256#6
# asm 2: vpaddq <out34=%ymm5,<out34plus=%ymm8,<out34=%ymm5
vpaddq %ymm5,%ymm8,%ymm5

# qhasm:       rax *= r
# asm 1: imul  <r=int64#5,<rax=int64#12
# asm 2: imul  <r=%r8,<rax=%r14
imul  %r8,%r14

# qhasm: 4x ta = int32 d0 * int32 mod34
# asm 1: vpmuldq <d0=reg256#12,<mod34=reg256#15,>ta=reg256#7
# asm 2: vpmuldq <d0=%ymm11,<mod34=%ymm14,>ta=%ymm6
vpmuldq %ymm11,%ymm14,%ymm6

# qhasm: 4x tb = int32 d1 * int32 mod33
# asm 1: vpmuldq <d1=reg256#2,<mod33=reg256#14,>tb=reg256#9
# asm 2: vpmuldq <d1=%ymm1,<mod33=%ymm13,>tb=%ymm8
vpmuldq %ymm1,%ymm13,%ymm8

# qhasm: 4x out34plus2 = ta + tb
# asm 1: vpaddq <tb=reg256#9,<ta=reg256#7,>out34plus2=reg256#7
# asm 2: vpaddq <tb=%ymm8,<ta=%ymm6,>out34plus2=%ymm6
vpaddq %ymm8,%ymm6,%ymm6

# qhasm:   u = fuv + _2p20
# asm 1: lea  (<fuv=int64#3,<_2p20=int64#11),>u=int64#3
# asm 2: lea  (<fuv=%rdx,<_2p20=%r13),>u=%rdx
lea  (%rdx,%r13),%rdx

# qhasm: 4x out34plus2 += carryy
# asm 1: vpaddq <out34plus2=reg256#7,<carryy=reg256#4,<out34plus2=reg256#7
# asm 2: vpaddq <out34plus2=%ymm6,<carryy=%ymm3,<out34plus2=%ymm6
vpaddq %ymm6,%ymm3,%ymm6

# qhasm: 4x out34 += out34plus2
# asm 1: vpaddq <out34=reg256#6,<out34plus2=reg256#7,<out34=reg256#6
# asm 2: vpaddq <out34=%ymm5,<out34plus2=%ymm6,<out34=%ymm5
vpaddq %ymm5,%ymm6,%ymm5

# qhasm:   u <<= 22
# asm 1: shl  $22,<u=int64#3
# asm 2: shl  $22,<u=%rdx
shl  $22,%rdx

# qhasm: 4x carryy = out34 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out34=reg256#6,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out34=%ymm5,>carryy=%ymm3
vpaddq %ymm7,%ymm5,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm:   (int64) u >>= 43
# asm 1: sar  $43,<u=int64#3
# asm 2: sar  $43,<u=%rdx
sar  $43,%rdx

# qhasm: out34 &= _2p30m1x4
# asm 1: vpand <out34=reg256#6,<_2p30m1x4=reg256#5,<out34=reg256#6
# asm 2: vpand <out34=%ymm5,<_2p30m1x4=%ymm4,<out34=%ymm5
vpand %ymm5,%ymm4,%ymm5

# qhasm: stack_FVGS32 = out34
# asm 1: vmovapd <out34=reg256#6,>stack_FVGS32=stack256#34
# asm 2: vmovapd <out34=%ymm5,>stack_FVGS32=1184(%rsp)
vmovapd %ymm5,1184(%rsp)

# qhasm:        f *= u
# asm 1: imul  <u=int64#3,<f=int64#4
# asm 2: imul  <u=%rdx,<f=%rcx
imul  %rdx,%rcx

# qhasm: _2p33x4 = stack_2p33x4
# asm 1: vmovapd <stack_2p33x4=stack256#73,>_2p33x4=reg256#6
# asm 2: vmovapd <stack_2p33x4=2432(%rsp),>_2p33x4=%ymm5
vmovapd 2432(%rsp),%ymm5

# qhasm: 4x ta = int32 uuss1 * int32 FVGS34
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS34=reg256#10,>ta=reg256#3
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS34=%ymm9,>ta=%ymm2
vpmuldq %ymm2,%ymm9,%ymm2

# qhasm:        f += t2
# asm 1: add  <t2=int64#10,<f=int64#4
# asm 2: add  <t2=%r12,<f=%rcx
add  %r12,%rcx

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV34
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV34=reg256#11,>tb=reg256#1
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV34=%ymm10,>tb=%ymm0
vpmuldq %ymm0,%ymm10,%ymm0

# qhasm: 4x out35plus = ta + tb
# asm 1: vpaddq <tb=reg256#1,<ta=reg256#3,>out35plus=reg256#1
# asm 2: vpaddq <tb=%ymm0,<ta=%ymm2,>out35plus=%ymm0
vpaddq %ymm0,%ymm2,%ymm0

# qhasm:        g += rax
# asm 1: add  <rax=int64#12,<g=int64#1
# asm 2: add  <rax=%r14,<g=%rdi
add  %r14,%rdi

# qhasm: 4x ta = int32 mod34 * int32 d1
# asm 1: vpmuldq <mod34=reg256#15,<d1=reg256#2,>ta=reg256#2
# asm 2: vpmuldq <mod34=%ymm14,<d1=%ymm1,>ta=%ymm1
vpmuldq %ymm14,%ymm1,%ymm1

# qhasm: 4x out35 = ta + carryy
# asm 1: vpaddq <carryy=reg256#4,<ta=reg256#2,>out35=reg256#2
# asm 2: vpaddq <carryy=%ymm3,<ta=%ymm1,>out35=%ymm1
vpaddq %ymm3,%ymm1,%ymm1

# qhasm:   (int64) f >>= 20
# asm 1: sar  $20,<f=int64#4
# asm 2: sar  $20,<f=%rcx
sar  $20,%rcx

# qhasm: 4x out35 += out35plus
# asm 1: vpaddq <out35=reg256#2,<out35plus=reg256#1,<out35=reg256#2
# asm 2: vpaddq <out35=%ymm1,<out35plus=%ymm0,<out35=%ymm1
vpaddq %ymm1,%ymm0,%ymm1

# qhasm: 4x out36 = out35 + _2p63m2p33x4
# asm 1: vpaddq <_2p63m2p33x4=reg256#8,<out35=reg256#2,>out36=reg256#1
# asm 2: vpaddq <_2p63m2p33x4=%ymm7,<out35=%ymm1,>out36=%ymm0
vpaddq %ymm7,%ymm1,%ymm0

# qhasm:   (int64) g >>= 20
# asm 1: sar  $20,<g=int64#1
# asm 2: sar  $20,<g=%rdi
sar  $20,%rdi

# qhasm: 4x out36 unsigned >>= 30
# asm 1: vpsrlq $30,<out36=reg256#1,<out36=reg256#1
# asm 2: vpsrlq $30,<out36=%ymm0,<out36=%ymm0
vpsrlq $30,%ymm0,%ymm0

# qhasm: 4x out36 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#6,<out36=reg256#1,<out36=reg256#1
# asm 2: vpsubq <_2p33x4=%ymm5,<out36=%ymm0,<out36=%ymm0
vpsubq %ymm5,%ymm0,%ymm0

# qhasm:   inplace stack_vvrr[0] = v
# asm 1: movq <v=int64#7,<stack_vvrr=stack256#78
# asm 2: movq <v=%rax,<stack_vvrr=2592(%rsp)
movq %rax,2592(%rsp)

# qhasm: out35 &= _2p30m1x4
# asm 1: vpand <out35=reg256#2,<_2p30m1x4=reg256#5,<out35=reg256#2
# asm 2: vpand <out35=%ymm1,<_2p30m1x4=%ymm4,<out35=%ymm1
vpand %ymm1,%ymm4,%ymm1

# qhasm: stack_FVGS33 = out35
# asm 1: vmovapd <out35=reg256#2,>stack_FVGS33=stack256#35
# asm 2: vmovapd <out35=%ymm1,>stack_FVGS33=1216(%rsp)
vmovapd %ymm1,1216(%rsp)

# qhasm:   inplace stack_uuss[0] = u
# asm 1: movq <u=int64#3,<stack_uuss=stack256#77
# asm 2: movq <u=%rdx,<stack_uuss=2560(%rsp)
movq %rdx,2560(%rsp)

# qhasm: stack_FVGS34 = out36
# asm 1: vmovapd <out36=reg256#1,>stack_FVGS34=stack256#36
# asm 2: vmovapd <out36=%ymm0,>stack_FVGS34=1248(%rsp)
vmovapd %ymm0,1248(%rsp)

# qhasm:   inplace stack_uuss[2] = s
# asm 1: movq <s=int64#9,<stack_uuss=stack256#77
# asm 2: movq <s=%r11,<stack_uuss=2576(%rsp)
movq %r11,2576(%rsp)

# qhasm:   inplace stack_vvrr[2] = r
# asm 1: movq <r=int64#5,<stack_vvrr=stack256#78
# asm 2: movq <r=%r8,<stack_vvrr=2608(%rsp)
movq %r8,2608(%rsp)

# qhasm:   loop = 2
# asm 1: mov  $2,>loop=int64#3
# asm 2: mov  $2,>loop=%rdx
mov  $2,%rdx

# qhasm: loop20:
._loop20:

# qhasm:   fuv = f & ~ _m2p20
# asm 1: andn  <f=int64#4,<_m2p20=int64#8,>fuv=int64#7
# asm 2: andn  <f=%rcx,<_m2p20=%r10,>fuv=%rax
andn  %rcx,%r10,%rax

# qhasm:   grs = g & ~ _m2p20
# asm 1: andn  <g=int64#1,<_m2p20=int64#8,>grs=int64#5
# asm 2: andn  <g=%rdi,<_m2p20=%r10,>grs=%r8
andn  %rdi,%r10,%r8

# qhasm:   fuv += stack_m2p41
# asm 1: addq <stack_m2p41=stack64#12,<fuv=int64#7
# asm 2: addq <stack_m2p41=88(%rsp),<fuv=%rax
addq 88(%rsp),%rax

# qhasm:   grs += stack_m2p62
# asm 1: addq <stack_m2p62=stack64#13,<grs=int64#5
# asm 2: addq <stack_m2p62=96(%rsp),<grs=%r8
addq 96(%rsp),%r8

# qhasm: j = 4
# asm 1: mov  $4,>j=int64#9
# asm 2: mov  $4,>j=%r11
mov  $4,%r11

# qhasm: loop2:
._loop2:

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#10
# asm 2: movq <stack_m1=136(%rsp),>z=%r12
movq 136(%rsp),%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#10
# asm 2: movq <stack_m1=136(%rsp),>z=%r12
movq 136(%rsp),%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#10
# asm 2: movq <stack_m1=136(%rsp),>z=%r12
movq 136(%rsp),%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:   z = stack_m1[1]
# asm 1: movq <stack_m1=stack256#1,>z=int64#10
# asm 2: movq <stack_m1=136(%rsp),>z=%r12
movq 136(%rsp),%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:   z = -1
# asm 1: mov  $-1,>z=int64#10
# asm 2: mov  $-1,>z=%r12
mov  $-1,%r12

# qhasm:   oldg = grs
# asm 1: mov  <grs=int64#5,>oldg=int64#11
# asm 2: mov  <grs=%r8,>oldg=%r13
mov  %r8,%r13

# qhasm:   h = grs + fuv
# asm 1: lea  (<grs=int64#5,<fuv=int64#7),>h=int64#12
# asm 2: lea  (<grs=%r8,<fuv=%rax),>h=%r14
lea  (%r8,%rax),%r14

# qhasm:               =? grs & 1
# asm 1: test  $1,<grs=int64#5
# asm 2: test  $1,<grs=%r8
test  $1,%r8

# qhasm:   z = m   if !=
# asm 1: cmovne <m=int64#6,<z=int64#10
# asm 2: cmovne <m=%r9,<z=%r12
cmovne %r9,%r12

# qhasm:   h = grs if  =
# asm 1: cmove <grs=int64#5,<h=int64#12
# asm 2: cmove <grs=%r8,<h=%r14
cmove %r8,%r14

# qhasm:   mnew = m + 1
# asm 1: lea  1(<m=int64#6),>mnew=int64#13
# asm 2: lea  1(<m=%r9),>mnew=%r15
lea  1(%r9),%r15

# qhasm:   grs -= fuv
# asm 1: sub  <fuv=int64#7,<grs=int64#5
# asm 2: sub  <fuv=%rax,<grs=%r8
sub  %rax,%r8

# qhasm:   (int64) grs >>= 1
# asm 1: sar  $1,<grs=int64#5
# asm 2: sar  $1,<grs=%r8
sar  $1,%r8

# qhasm:   (int64) h >>= 1
# asm 1: sar  $1,<h=int64#12
# asm 2: sar  $1,<h=%r14
sar  $1,%r14

# qhasm:   m = -m
# asm 1: neg  <m=int64#6
# asm 2: neg  <m=%r9
neg  %r9

# qhasm:                  signed<? z - 0
# asm 1: cmp  $0,<z=int64#10
# asm 2: cmp  $0,<z=%r12
cmp  $0,%r12

# qhasm:   fuv = oldg if !signed<
# asm 1: cmovge <oldg=int64#11,<fuv=int64#7
# asm 2: cmovge <oldg=%r13,<fuv=%rax
cmovge %r13,%rax

# qhasm:   grs = h    if  signed<
# asm 1: cmovl <h=int64#12,<grs=int64#5
# asm 2: cmovl <h=%r14,<grs=%r8
cmovl %r14,%r8

# qhasm:   m = mnew   if  signed<
# asm 1: cmovl <mnew=int64#13,<m=int64#6
# asm 2: cmovl <mnew=%r15,<m=%r9
cmovl %r15,%r9

# qhasm:  =? j -= 1
# asm 1: dec <j=int64#9
# asm 2: dec <j=%r11
dec %r11
# comment:fp stack unchanged by jump

# qhasm: goto loop2 if !=
jne ._loop2

# qhasm:   =? loop -= 1		
# asm 1: dec <loop=int64#3
# asm 2: dec <loop=%rdx
dec %rdx
# comment:fp stack unchanged by jump

# qhasm: goto lastloop if =
je ._lastloop

# qhasm: extract:
._extract:

# qhasm:   _2p20a2p41 = stack_2p20a2p41
# asm 1: movq <stack_2p20a2p41=stack64#14,>_2p20a2p41=int64#9
# asm 2: movq <stack_2p20a2p41=104(%rsp),>_2p20a2p41=%r11
movq 104(%rsp),%r11

# qhasm:   s = grs + _2p20a2p41
# asm 1: lea  (<grs=int64#5,<_2p20a2p41=int64#9),>s=int64#10
# asm 2: lea  (<grs=%r8,<_2p20a2p41=%r11),>s=%r12
lea  (%r8,%r11),%r12

# qhasm:   (int64) s >>= 42
# asm 1: sar  $42,<s=int64#10
# asm 2: sar  $42,<s=%r12
sar  $42,%r12

# qhasm:   t2 = g
# asm 1: mov  <g=int64#1,>t2=int64#11
# asm 2: mov  <g=%rdi,>t2=%r13
mov  %rdi,%r13

# qhasm:   g *= s  
# asm 1: imul  <s=int64#10,<g=int64#1
# asm 2: imul  <s=%r12,<g=%rdi
imul  %r12,%rdi

# qhasm:   v = fuv + _2p20a2p41
# asm 1: lea  (<fuv=int64#7,<_2p20a2p41=int64#9),>v=int64#9
# asm 2: lea  (<fuv=%rax,<_2p20a2p41=%r11),>v=%r11
lea  (%rax,%r11),%r11

# qhasm:   (int64) v >>= 42
# asm 1: sar  $42,<v=int64#9
# asm 2: sar  $42,<v=%r11
sar  $42,%r11

# qhasm:   t2 *= v
# asm 1: imul  <v=int64#9,<t2=int64#11
# asm 2: imul  <v=%r11,<t2=%r13
imul  %r11,%r13

# qhasm:   _2p20 = stack_2p20
# asm 1: movq <stack_2p20=stack64#11,>_2p20=int64#12
# asm 2: movq <stack_2p20=80(%rsp),>_2p20=%r14
movq 80(%rsp),%r14

# qhasm:   r = grs + _2p20
# asm 1: lea  (<grs=int64#5,<_2p20=int64#12),>r=int64#5
# asm 2: lea  (<grs=%r8,<_2p20=%r14),>r=%r8
lea  (%r8,%r14),%r8

# qhasm:   r <<= 22
# asm 1: shl  $22,<r=int64#5
# asm 2: shl  $22,<r=%r8
shl  $22,%r8

# qhasm:   (int64) r >>= 43
# asm 1: sar  $43,<r=int64#5
# asm 2: sar  $43,<r=%r8
sar  $43,%r8

# qhasm:       rax = f
# asm 1: mov  <f=int64#4,>rax=int64#13
# asm 2: mov  <f=%rcx,>rax=%r15
mov  %rcx,%r15

# qhasm:       rax *= r
# asm 1: imul  <r=int64#5,<rax=int64#13
# asm 2: imul  <r=%r8,<rax=%r15
imul  %r8,%r15

# qhasm:   u = fuv + _2p20
# asm 1: lea  (<fuv=int64#7,<_2p20=int64#12),>u=int64#7
# asm 2: lea  (<fuv=%rax,<_2p20=%r14),>u=%rax
lea  (%rax,%r14),%rax

# qhasm:   u <<= 22
# asm 1: shl  $22,<u=int64#7
# asm 2: shl  $22,<u=%rax
shl  $22,%rax

# qhasm:   (int64) u >>= 43
# asm 1: sar  $43,<u=int64#7
# asm 2: sar  $43,<u=%rax
sar  $43,%rax

# qhasm:        f *= u
# asm 1: imul  <u=int64#7,<f=int64#4
# asm 2: imul  <u=%rax,<f=%rcx
imul  %rax,%rcx

# qhasm:        f += t2
# asm 1: add  <t2=int64#11,<f=int64#4
# asm 2: add  <t2=%r13,<f=%rcx
add  %r13,%rcx

# qhasm:        g += rax
# asm 1: add  <rax=int64#13,<g=int64#1
# asm 2: add  <rax=%r15,<g=%rdi
add  %r15,%rdi

# qhasm:   (int64) f >>= 20
# asm 1: sar  $20,<f=int64#4
# asm 2: sar  $20,<f=%rcx
sar  $20,%rcx

# qhasm:   (int64) g >>= 20
# asm 1: sar  $20,<g=int64#1
# asm 2: sar  $20,<g=%rdi
sar  $20,%rdi

# qhasm:   t0 = stack_uuss[0]
# asm 1: movq <stack_uuss=stack256#77,>t0=int64#11
# asm 2: movq <stack_uuss=2560(%rsp),>t0=%r13
movq 2560(%rsp),%r13

# qhasm:   t0 *= u
# asm 1: imul  <u=int64#7,<t0=int64#11
# asm 2: imul  <u=%rax,<t0=%r13
imul  %rax,%r13

# qhasm:   t1 = stack_vvrr[2]
# asm 1: movq <stack_vvrr=stack256#78,>t1=int64#12
# asm 2: movq <stack_vvrr=2608(%rsp),>t1=%r14
movq 2608(%rsp),%r14

# qhasm:   t1 *= v
# asm 1: imul  <v=int64#9,<t1=int64#12
# asm 2: imul  <v=%r11,<t1=%r14
imul  %r11,%r14

# qhasm:   rtimesoldv = stack_vvrr[0]
# asm 1: movq <stack_vvrr=stack256#78,>rtimesoldv=int64#13
# asm 2: movq <stack_vvrr=2592(%rsp),>rtimesoldv=%r15
movq 2592(%rsp),%r15

# qhasm:   u *= rtimesoldv
# asm 1: imul  <rtimesoldv=int64#13,<u=int64#7
# asm 2: imul  <rtimesoldv=%r15,<u=%rax
imul  %r15,%rax

# qhasm:   stimesolds = stack_uuss[2]
# asm 1: movq <stack_uuss=stack256#77,>stimesolds=int64#14
# asm 2: movq <stack_uuss=2576(%rsp),>stimesolds=%rbx
movq 2576(%rsp),%rbx

# qhasm:   v *= stimesolds
# asm 1: imul  <stimesolds=int64#14,<v=int64#9
# asm 2: imul  <stimesolds=%rbx,<v=%r11
imul  %rbx,%r11

# qhasm:   rtimesoldv *= r
# asm 1: imul  <r=int64#5,<rtimesoldv=int64#13
# asm 2: imul  <r=%r8,<rtimesoldv=%r15
imul  %r8,%r15

# qhasm:   stimesolds *= s
# asm 1: imul  <s=int64#10,<stimesolds=int64#14
# asm 2: imul  <s=%r12,<stimesolds=%rbx
imul  %r12,%rbx

# qhasm:   r *= stack_uuss[0]
# asm 1: imulq <stack_uuss=stack256#77,<r=int64#5
# asm 2: imulq <stack_uuss=2560(%rsp),<r=%r8
imulq 2560(%rsp),%r8

# qhasm:   s *= stack_vvrr[2]
# asm 1: imulq <stack_vvrr=stack256#78,<s=int64#10
# asm 2: imulq <stack_vvrr=2608(%rsp),<s=%r12
imulq 2608(%rsp),%r12

# qhasm:   v += u
# asm 1: add  <u=int64#7,<v=int64#9
# asm 2: add  <u=%rax,<v=%r11
add  %rax,%r11

# qhasm:   u = t0 + t1
# asm 1: lea  (<t0=int64#11,<t1=int64#12),>u=int64#7
# asm 2: lea  (<t0=%r13,<t1=%r14),>u=%rax
lea  (%r13,%r14),%rax

# qhasm:   r += s
# asm 1: add  <s=int64#10,<r=int64#5
# asm 2: add  <s=%r12,<r=%r8
add  %r12,%r8

# qhasm:   s = rtimesoldv + stimesolds
# asm 1: lea  (<rtimesoldv=int64#13,<stimesolds=int64#14),>s=int64#10
# asm 2: lea  (<rtimesoldv=%r15,<stimesolds=%rbx),>s=%r12
lea  (%r15,%rbx),%r12

# qhasm: first_loop:
._first_loop:

# qhasm:   inplace stack_vvrr[0] = v
# asm 1: movq <v=int64#9,<stack_vvrr=stack256#78
# asm 2: movq <v=%r11,<stack_vvrr=2592(%rsp)
movq %r11,2592(%rsp)

# qhasm:   inplace stack_uuss[0] = u
# asm 1: movq <u=int64#7,<stack_uuss=stack256#77
# asm 2: movq <u=%rax,<stack_uuss=2560(%rsp)
movq %rax,2560(%rsp)

# qhasm:   inplace stack_uuss[2] = s
# asm 1: movq <s=int64#10,<stack_uuss=stack256#77
# asm 2: movq <s=%r12,<stack_uuss=2576(%rsp)
movq %r12,2576(%rsp)

# qhasm:   inplace stack_vvrr[2] = r
# asm 1: movq <r=int64#5,<stack_vvrr=stack256#78
# asm 2: movq <r=%r8,<stack_vvrr=2608(%rsp)
movq %r8,2608(%rsp)
# comment:fp stack unchanged by jump

# qhasm: goto loop20 
jmp ._loop20

# qhasm: lastloop:
._lastloop:

# qhasm:   _2p20a2p41 = stack_2p20a2p41
# asm 1: movq <stack_2p20a2p41=stack64#14,>_2p20a2p41=int64#1
# asm 2: movq <stack_2p20a2p41=104(%rsp),>_2p20a2p41=%rdi
movq 104(%rsp),%rdi

# qhasm:   s = grs + _2p20a2p41
# asm 1: lea  (<grs=int64#5,<_2p20a2p41=int64#1),>s=int64#3
# asm 2: lea  (<grs=%r8,<_2p20a2p41=%rdi),>s=%rdx
lea  (%r8,%rdi),%rdx

# qhasm:   (int64) s >>= 42
# asm 1: sar  $42,<s=int64#3
# asm 2: sar  $42,<s=%rdx
sar  $42,%rdx

# qhasm:   v = fuv + _2p20a2p41
# asm 1: lea  (<fuv=int64#7,<_2p20a2p41=int64#1),>v=int64#10
# asm 2: lea  (<fuv=%rax,<_2p20a2p41=%rdi),>v=%r12
lea  (%rax,%rdi),%r12

# qhasm:   (int64) v >>= 42
# asm 1: sar  $42,<v=int64#10
# asm 2: sar  $42,<v=%r12
sar  $42,%r12

# qhasm:   t1 = stack_vvrr[2]
# asm 1: movq <stack_vvrr=stack256#78,>t1=int64#1
# asm 2: movq <stack_vvrr=2608(%rsp),>t1=%rdi
movq 2608(%rsp),%rdi

# qhasm:   t1 *= v
# asm 1: imul  <v=int64#10,<t1=int64#1
# asm 2: imul  <v=%r12,<t1=%rdi
imul  %r12,%rdi

# qhasm:   stimesolds = stack_uuss[2]
# asm 1: movq <stack_uuss=stack256#77,>stimesolds=int64#4
# asm 2: movq <stack_uuss=2576(%rsp),>stimesolds=%rcx
movq 2576(%rsp),%rcx

# qhasm:   v *= stimesolds
# asm 1: imul  <stimesolds=int64#4,<v=int64#10
# asm 2: imul  <stimesolds=%rcx,<v=%r12
imul  %rcx,%r12

# qhasm:   stimesolds *= s
# asm 1: imul  <s=int64#3,<stimesolds=int64#4
# asm 2: imul  <s=%rdx,<stimesolds=%rcx
imul  %rdx,%rcx

# qhasm:   _2p20 = stack_2p20
# asm 1: movq <stack_2p20=stack64#11,>_2p20=int64#9
# asm 2: movq <stack_2p20=80(%rsp),>_2p20=%r11
movq 80(%rsp),%r11

# qhasm:   r = grs + _2p20
# asm 1: lea  (<grs=int64#5,<_2p20=int64#9),>r=int64#12
# asm 2: lea  (<grs=%r8,<_2p20=%r11),>r=%r14
lea  (%r8,%r11),%r14

# qhasm:   r <<= 22
# asm 1: shl  $22,<r=int64#12
# asm 2: shl  $22,<r=%r14
shl  $22,%r14

# qhasm:   (int64) r >>= 43
# asm 1: sar  $43,<r=int64#12
# asm 2: sar  $43,<r=%r14
sar  $43,%r14

# qhasm:   u = fuv + _2p20
# asm 1: lea  (<fuv=int64#7,<_2p20=int64#9),>u=int64#5
# asm 2: lea  (<fuv=%rax,<_2p20=%r11),>u=%r8
lea  (%rax,%r11),%r8

# qhasm:   u <<= 22
# asm 1: shl  $22,<u=int64#5
# asm 2: shl  $22,<u=%r8
shl  $22,%r8

# qhasm:   (int64) u >>= 43
# asm 1: sar  $43,<u=int64#5
# asm 2: sar  $43,<u=%r8
sar  $43,%r8

# qhasm:   t0 = stack_uuss[0]
# asm 1: movq <stack_uuss=stack256#77,>t0=int64#9
# asm 2: movq <stack_uuss=2560(%rsp),>t0=%r11
movq 2560(%rsp),%r11

# qhasm:   t0 *= u
# asm 1: imul  <u=int64#5,<t0=int64#9
# asm 2: imul  <u=%r8,<t0=%r11
imul  %r8,%r11

# qhasm:   rtimesoldv = stack_vvrr[0]
# asm 1: movq <stack_vvrr=stack256#78,>rtimesoldv=int64#11
# asm 2: movq <stack_vvrr=2592(%rsp),>rtimesoldv=%r13
movq 2592(%rsp),%r13

# qhasm:   u *= rtimesoldv
# asm 1: imul  <rtimesoldv=int64#11,<u=int64#5
# asm 2: imul  <rtimesoldv=%r13,<u=%r8
imul  %r13,%r8

# qhasm:   rtimesoldv *= r
# asm 1: imul  <r=int64#12,<rtimesoldv=int64#11
# asm 2: imul  <r=%r14,<rtimesoldv=%r13
imul  %r14,%r13

# qhasm:   s *= stack_vvrr[2]
# asm 1: imulq <stack_vvrr=stack256#78,<s=int64#3
# asm 2: imulq <stack_vvrr=2608(%rsp),<s=%rdx
imulq 2608(%rsp),%rdx

# qhasm:   r *= stack_uuss[0]
# asm 1: imulq <stack_uuss=stack256#77,<r=int64#12
# asm 2: imulq <stack_uuss=2560(%rsp),<r=%r14
imulq 2560(%rsp),%r14

# qhasm:   v += u
# asm 1: add  <u=int64#5,<v=int64#10
# asm 2: add  <u=%r8,<v=%r12
add  %r8,%r12

# qhasm:   u = t0 + t1
# asm 1: lea  (<t0=int64#9,<t1=int64#1),>u=int64#9
# asm 2: lea  (<t0=%r11,<t1=%rdi),>u=%r11
lea  (%r11,%rdi),%r11

# qhasm:   r += s
# asm 1: add  <s=int64#3,<r=int64#12
# asm 2: add  <s=%rdx,<r=%r14
add  %rdx,%r14

# qhasm:   s = rtimesoldv + stimesolds
# asm 1: lea  (<rtimesoldv=int64#11,<stimesolds=int64#4),>s=int64#11
# asm 2: lea  (<rtimesoldv=%r13,<stimesolds=%rcx),>s=%r13
lea  (%r13,%rcx),%r13

# qhasm:   t0 = stack_FVGS0[0]
# asm 1: movq <stack_FVGS0=stack256#2,>t0=int64#1
# asm 2: movq <stack_FVGS0=160(%rsp),>t0=%rdi
movq 160(%rsp),%rdi

# qhasm:   t1 = stack_FVGS1[0]
# asm 1: movq <stack_FVGS1=stack256#3,>t1=int64#3
# asm 2: movq <stack_FVGS1=192(%rsp),>t1=%rdx
movq 192(%rsp),%rdx

# qhasm:   t1 <<= 30
# asm 1: shl  $30,<t1=int64#3
# asm 2: shl  $30,<t1=%rdx
shl  $30,%rdx

# qhasm:   f = t0 + t1
# asm 1: lea  (<t0=int64#1,<t1=int64#3),>f=int64#4
# asm 2: lea  (<t0=%rdi,<t1=%rdx),>f=%rcx
lea  (%rdi,%rdx),%rcx

# qhasm:   t0 = stack_FVGS0[2]
# asm 1: movq <stack_FVGS0=stack256#2,>t0=int64#1
# asm 2: movq <stack_FVGS0=176(%rsp),>t0=%rdi
movq 176(%rsp),%rdi

# qhasm:   t1 = stack_FVGS1[2]
# asm 1: movq <stack_FVGS1=stack256#3,>t1=int64#3
# asm 2: movq <stack_FVGS1=208(%rsp),>t1=%rdx
movq 208(%rsp),%rdx

# qhasm:   t1 <<= 30
# asm 1: shl  $30,<t1=int64#3
# asm 2: shl  $30,<t1=%rdx
shl  $30,%rdx

# qhasm:   g = t0 + t1
# asm 1: lea  (<t0=int64#1,<t1=int64#3),>g=int64#1
# asm 2: lea  (<t0=%rdi,<t1=%rdx),>g=%rdi
lea  (%rdi,%rdx),%rdi

# qhasm:   t0 = stack_FVGS2[0]
# asm 1: movq <stack_FVGS2=stack256#4,>t0=int64#3
# asm 2: movq <stack_FVGS2=224(%rsp),>t0=%rdx
movq 224(%rsp),%rdx

# qhasm:   t1 = stack_FVGS3[0]
# asm 1: movq <stack_FVGS3=stack256#5,>t1=int64#5
# asm 2: movq <stack_FVGS3=256(%rsp),>t1=%r8
movq 256(%rsp),%r8

# qhasm:   t1 <<= 30
# asm 1: shl  $30,<t1=int64#5
# asm 2: shl  $30,<t1=%r8
shl  $30,%r8

# qhasm:   f0 = t0 + t1
# asm 1: lea  (<t0=int64#3,<t1=int64#5),>f0=int64#5
# asm 2: lea  (<t0=%rdx,<t1=%r8),>f0=%r8
lea  (%rdx,%r8),%r8

# qhasm:   t0 = stack_FVGS2[2]
# asm 1: movq <stack_FVGS2=stack256#4,>t0=int64#3
# asm 2: movq <stack_FVGS2=240(%rsp),>t0=%rdx
movq 240(%rsp),%rdx

# qhasm:   t1 = stack_FVGS3[2]
# asm 1: movq <stack_FVGS3=stack256#5,>t1=int64#13
# asm 2: movq <stack_FVGS3=272(%rsp),>t1=%r15
movq 272(%rsp),%r15

# qhasm:   t1 <<= 30
# asm 1: shl  $30,<t1=int64#13
# asm 2: shl  $30,<t1=%r15
shl  $30,%r15

# qhasm:   g0 = t0 + t1
# asm 1: lea  (<t0=int64#3,<t1=int64#13),>g0=int64#13
# asm 2: lea  (<t0=%rdx,<t1=%r15),>g0=%r15
lea  (%rdx,%r15),%r15

# qhasm: =? i -= 1
# asm 1: dec <i=int64#2
# asm 2: dec <i=%rsi
dec %rsi
# comment:fp stack unchanged by jump

# qhasm: goto bigloop if !=
jne ._bigloop

# qhasm: last_transition:
._last_transition:

# qhasm: fuv &= 2
# asm 1: and  $2,<fuv=int64#7
# asm 2: and  $2,<fuv=%rax
and  $2,%rax

# qhasm: t0 = fuv - 1
# asm 1: lea  -1(<fuv=int64#7),>t0=int64#1
# asm 2: lea  -1(<fuv=%rax),>t0=%rdi
lea  -1(%rax),%rdi

# qhasm: u *= t0
# asm 1: imul  <t0=int64#1,<u=int64#9
# asm 2: imul  <t0=%rdi,<u=%r11
imul  %rdi,%r11

# qhasm: v *= t0
# asm 1: imul  <t0=int64#1,<v=int64#10
# asm 2: imul  <t0=%rdi,<v=%r12
imul  %rdi,%r12

# qhasm: new vvrr

# qhasm: vvrr = v,vvrr[1],0,0
# asm 1: vpinsrq $0x0,<v=int64#10,<vvrr=reg256#1%128,<vvrr=reg256#1%128
# asm 2: vpinsrq $0x0,<v=%r12,<vvrr=%xmm0,<vvrr=%xmm0
vpinsrq $0x0,%r12,%xmm0,%xmm0

# qhasm: vvrr = vvrr[0],r,0,0
# asm 1: vpinsrq $0x1,<r=int64#12,<vvrr=reg256#1%128,<vvrr=reg256#1%128
# asm 2: vpinsrq $0x1,<r=%r14,<vvrr=%xmm0,<vvrr=%xmm0
vpinsrq $0x1,%r14,%xmm0,%xmm0

# qhasm: FVGS0 = stack_FVGS0
# asm 1: vmovapd <stack_FVGS0=stack256#2,>FVGS0=reg256#2
# asm 2: vmovapd <stack_FVGS0=160(%rsp),>FVGS0=%ymm1
vmovapd 160(%rsp),%ymm1

# qhasm: new uuss

# qhasm: uuss = u,uuss[1],0,0
# asm 1: vpinsrq $0x0,<u=int64#9,<uuss=reg256#3%128,<uuss=reg256#3%128
# asm 2: vpinsrq $0x0,<u=%r11,<uuss=%xmm2,<uuss=%xmm2
vpinsrq $0x0,%r11,%xmm2,%xmm2

# qhasm: uuss = uuss[0],s,0,0
# asm 1: vpinsrq $0x1,<s=int64#11,<uuss=reg256#3%128,<uuss=reg256#3%128
# asm 2: vpinsrq $0x1,<s=%r13,<uuss=%xmm2,<uuss=%xmm2
vpinsrq $0x1,%r13,%xmm2,%xmm2

# qhasm: GSFV0 = FVGS0[1,0]
# asm 1: vpermq $0x4e,<FVGS0=reg256#2,>GSFV0=reg256#4
# asm 2: vpermq $0x4e,<FVGS0=%ymm1,>GSFV0=%ymm3
vpermq $0x4e,%ymm1,%ymm3

# qhasm: uuss = uuss[0,0,1,1]
# asm 1: vpermq $0x50,<uuss=reg256#3,>uuss=reg256#3
# asm 2: vpermq $0x50,<uuss=%ymm2,>uuss=%ymm2
vpermq $0x50,%ymm2,%ymm2

# qhasm: vvrr = vvrr[0,0,1,1]
# asm 1: vpermq $0x50,<vvrr=reg256#1,>vvrr=reg256#1
# asm 2: vpermq $0x50,<vvrr=%ymm0,>vvrr=%ymm0
vpermq $0x50,%ymm0,%ymm0

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: uuss0 = uuss & _2p30m1x4
# asm 1: vpand <uuss=reg256#3,<_2p30m1x4=reg256#5,>uuss0=reg256#6
# asm 2: vpand <uuss=%ymm2,<_2p30m1x4=%ymm4,>uuss0=%ymm5
vpand %ymm2,%ymm4,%ymm5

# qhasm: vvrr0 = vvrr & _2p30m1x4 
# asm 1: vpand <vvrr=reg256#1,<_2p30m1x4=reg256#5,>vvrr0=reg256#7
# asm 2: vpand <vvrr=%ymm0,<_2p30m1x4=%ymm4,>vvrr0=%ymm6
vpand %ymm0,%ymm4,%ymm6

# qhasm: _2p63x4 = stack_2p63x4
# asm 1: vmovapd <stack_2p63x4=stack256#74,>_2p63x4=reg256#8
# asm 2: vmovapd <stack_2p63x4=2464(%rsp),>_2p63x4=%ymm7
vmovapd 2464(%rsp),%ymm7

# qhasm: uuss1 = uuss ^ _2p63x4
# asm 1: vpxor <uuss=reg256#3,<_2p63x4=reg256#8,>uuss1=reg256#3
# asm 2: vpxor <uuss=%ymm2,<_2p63x4=%ymm7,>uuss1=%ymm2
vpxor %ymm2,%ymm7,%ymm2

# qhasm: vvrr1 = vvrr ^ _2p63x4
# asm 1: vpxor <vvrr=reg256#1,<_2p63x4=reg256#8,>vvrr1=reg256#1
# asm 2: vpxor <vvrr=%ymm0,<_2p63x4=%ymm7,>vvrr1=%ymm0
vpxor %ymm0,%ymm7,%ymm0

# qhasm: 4x uuss1 unsigned>>= 30
# asm 1: vpsrlq $30,<uuss1=reg256#3,<uuss1=reg256#3
# asm 2: vpsrlq $30,<uuss1=%ymm2,<uuss1=%ymm2
vpsrlq $30,%ymm2,%ymm2

# qhasm: 4x vvrr1 unsigned>>= 30
# asm 1: vpsrlq $30,<vvrr1=reg256#1,<vvrr1=reg256#1
# asm 2: vpsrlq $30,<vvrr1=%ymm0,<vvrr1=%ymm0
vpsrlq $30,%ymm0,%ymm0

# qhasm: _2p33x4 = stack_2p33x4
# asm 1: vmovapd <stack_2p33x4=stack256#73,>_2p33x4=reg256#9
# asm 2: vmovapd <stack_2p33x4=2432(%rsp),>_2p33x4=%ymm8
vmovapd 2432(%rsp),%ymm8

# qhasm: 4x uuss1 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#9,<uuss1=reg256#3,<uuss1=reg256#3
# asm 2: vpsubq <_2p33x4=%ymm8,<uuss1=%ymm2,<uuss1=%ymm2
vpsubq %ymm8,%ymm2,%ymm2

# qhasm: 4x vvrr1 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#9,<vvrr1=reg256#1,<vvrr1=reg256#1
# asm 2: vpsubq <_2p33x4=%ymm8,<vvrr1=%ymm0,<vvrr1=%ymm0
vpsubq %ymm8,%ymm0,%ymm0

# qhasm: 4x ta = int32 uuss0 * int32 FVGS0
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS0=reg256#2,>ta=reg256#9
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS0=%ymm1,>ta=%ymm8
vpmuldq %ymm5,%ymm1,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV0
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV0=reg256#4,>tb=reg256#10
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV0=%ymm3,>tb=%ymm9
vpmuldq %ymm6,%ymm3,%ymm9

# qhasm: 4x out0 = ta + tb
# asm 1: vpaddq <tb=reg256#10,<ta=reg256#9,>out0=reg256#9
# asm 2: vpaddq <tb=%ymm9,<ta=%ymm8,>out0=%ymm8
vpaddq %ymm9,%ymm8,%ymm8

# qhasm: minvx4 = 4x stack_minv
# asm 1: vpbroadcastq <stack_minv=stack64#9,>minvx4=reg256#10
# asm 2: vpbroadcastq <stack_minv=64(%rsp),>minvx4=%ymm9
vpbroadcastq 64(%rsp),%ymm9

# qhasm: mod0 = stack_mod0
# asm 1: vmovapd <stack_mod0=stack256#37,>mod0=reg256#11
# asm 2: vmovapd <stack_mod0=1280(%rsp),>mod0=%ymm10
vmovapd 1280(%rsp),%ymm10

# qhasm: 4x d0 = int32 minvx4 * int32 out0
# asm 1: vpmuldq <minvx4=reg256#10,<out0=reg256#9,>d0=reg256#12
# asm 2: vpmuldq <minvx4=%ymm9,<out0=%ymm8,>d0=%ymm11
vpmuldq %ymm9,%ymm8,%ymm11

# qhasm: d0 &= _2p30m1x4
# asm 1: vpand <d0=reg256#12,<_2p30m1x4=reg256#5,<d0=reg256#12
# asm 2: vpand <d0=%ymm11,<_2p30m1x4=%ymm4,<d0=%ymm11
vpand %ymm11,%ymm4,%ymm11

# qhasm: 4x ta = int32 mod0 * int32 d0
# asm 1: vpmuldq <mod0=reg256#11,<d0=reg256#12,>ta=reg256#13
# asm 2: vpmuldq <mod0=%ymm10,<d0=%ymm11,>ta=%ymm12
vpmuldq %ymm10,%ymm11,%ymm12

# qhasm: 4x out0 += ta
# asm 1: vpaddq <out0=reg256#9,<ta=reg256#13,<out0=reg256#9
# asm 2: vpaddq <out0=%ymm8,<ta=%ymm12,<out0=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x carryy = out0 +_2p63x4
# asm 1: vpaddq <_2p63x4=reg256#8,<out0=reg256#9,>carryy=reg256#8
# asm 2: vpaddq <_2p63x4=%ymm7,<out0=%ymm8,>carryy=%ymm7
vpaddq %ymm7,%ymm8,%ymm7

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#8,<carryy=reg256#8
# asm 2: vpsrlq $30,<carryy=%ymm7,<carryy=%ymm7
vpsrlq $30,%ymm7,%ymm7

# qhasm: FVGS1 = stack_FVGS1
# asm 1: vmovapd <stack_FVGS1=stack256#3,>FVGS1=reg256#9
# asm 2: vmovapd <stack_FVGS1=192(%rsp),>FVGS1=%ymm8
vmovapd 192(%rsp),%ymm8

# qhasm: GSFV1 = FVGS1[1,0]
# asm 1: vpermq $0x4e,<FVGS1=reg256#9,>GSFV1=reg256#13
# asm 2: vpermq $0x4e,<FVGS1=%ymm8,>GSFV1=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: mod1 = stack_mod1
# asm 1: vmovapd <stack_mod1=stack256#38,>mod1=reg256#14
# asm 2: vmovapd <stack_mod1=1312(%rsp),>mod1=%ymm13
vmovapd 1312(%rsp),%ymm13

# qhasm: 4x ta = int32 uuss1 * int32 FVGS0
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS0=reg256#2,>ta=reg256#2
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS0=%ymm1,>ta=%ymm1
vpmuldq %ymm2,%ymm1,%ymm1

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV0
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV0=reg256#4,>tb=reg256#4
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV0=%ymm3,>tb=%ymm3
vpmuldq %ymm0,%ymm3,%ymm3

# qhasm: 4x out1plus = ta + tb
# asm 1: vpaddq <tb=reg256#4,<ta=reg256#2,>out1plus=reg256#2
# asm 2: vpaddq <tb=%ymm3,<ta=%ymm1,>out1plus=%ymm1
vpaddq %ymm3,%ymm1,%ymm1

# qhasm: 4x ta = int32 uuss0 * int32 FVGS1
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS1=reg256#9,>ta=reg256#4
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS1=%ymm8,>ta=%ymm3
vpmuldq %ymm5,%ymm8,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV1
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV1=reg256#13,>tb=reg256#15
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV1=%ymm12,>tb=%ymm14
vpmuldq %ymm6,%ymm12,%ymm14

# qhasm: 4x out1 = ta + tb
# asm 1: vpaddq <tb=reg256#15,<ta=reg256#4,>out1=reg256#4
# asm 2: vpaddq <tb=%ymm14,<ta=%ymm3,>out1=%ymm3
vpaddq %ymm14,%ymm3,%ymm3

# qhasm: 4x out1 += out1plus
# asm 1: vpaddq <out1=reg256#4,<out1plus=reg256#2,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<out1plus=%ymm1,<out1=%ymm3
vpaddq %ymm3,%ymm1,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod1
# asm 1: vpmuldq <d0=reg256#12,<mod1=reg256#14,>ta=reg256#2
# asm 2: vpmuldq <d0=%ymm11,<mod1=%ymm13,>ta=%ymm1
vpmuldq %ymm11,%ymm13,%ymm1

# qhasm: 4x ta += carryy
# asm 1: vpaddq <ta=reg256#2,<carryy=reg256#8,<ta=reg256#2
# asm 2: vpaddq <ta=%ymm1,<carryy=%ymm7,<ta=%ymm1
vpaddq %ymm1,%ymm7,%ymm1

# qhasm: 4x out1 += ta
# asm 1: vpaddq <out1=reg256#4,<ta=reg256#2,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<ta=%ymm1,<out1=%ymm3
vpaddq %ymm3,%ymm1,%ymm3

# qhasm: 4x d1 = int32 minvx4 * int32 out1
# asm 1: vpmuldq <minvx4=reg256#10,<out1=reg256#4,>d1=reg256#2
# asm 2: vpmuldq <minvx4=%ymm9,<out1=%ymm3,>d1=%ymm1
vpmuldq %ymm9,%ymm3,%ymm1

# qhasm: d1 &= _2p30m1x4
# asm 1: vpand <d1=reg256#2,<_2p30m1x4=reg256#5,<d1=reg256#2
# asm 2: vpand <d1=%ymm1,<_2p30m1x4=%ymm4,<d1=%ymm1
vpand %ymm1,%ymm4,%ymm1

# qhasm: 4x ta = int32 mod0 * int32 d1
# asm 1: vpmuldq <mod0=reg256#11,<d1=reg256#2,>ta=reg256#5
# asm 2: vpmuldq <mod0=%ymm10,<d1=%ymm1,>ta=%ymm4
vpmuldq %ymm10,%ymm1,%ymm4

# qhasm: 4x out1 += ta
# asm 1: vpaddq <out1=reg256#4,<ta=reg256#5,<out1=reg256#4
# asm 2: vpaddq <out1=%ymm3,<ta=%ymm4,<out1=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#5
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm4
vmovapd 2496(%rsp),%ymm4

# qhasm: 4x carryy = out1 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#5,<out1=reg256#4,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm4,<out1=%ymm3,>carryy=%ymm3
vpaddq %ymm4,%ymm3,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: FVGS2 = stack_FVGS2
# asm 1: vmovapd <stack_FVGS2=stack256#4,>FVGS2=reg256#5
# asm 2: vmovapd <stack_FVGS2=224(%rsp),>FVGS2=%ymm4
vmovapd 224(%rsp),%ymm4

# qhasm: GSFV2 = FVGS2[1,0]
# asm 1: vpermq $0x4e,<FVGS2=reg256#5,>GSFV2=reg256#8
# asm 2: vpermq $0x4e,<FVGS2=%ymm4,>GSFV2=%ymm7
vpermq $0x4e,%ymm4,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS1
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS1=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS1=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out2 = ta + carryy
# asm 1: vpaddq <carryy=reg256#4,<ta=reg256#9,>out2=reg256#4
# asm 2: vpaddq <carryy=%ymm3,<ta=%ymm8,>out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV1
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV1=reg256#13,>tb=reg256#9
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV1=%ymm12,>tb=%ymm8
vpmuldq %ymm0,%ymm12,%ymm8

# qhasm: 4x out2 += tb
# asm 1: vpaddq <out2=reg256#4,<tb=reg256#9,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<tb=%ymm8,<out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS2
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS2=reg256#5,>ta=reg256#9
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS2=%ymm4,>ta=%ymm8
vpmuldq %ymm5,%ymm4,%ymm8

# qhasm: 4x out2 += ta
# asm 1: vpaddq <out2=reg256#4,<ta=reg256#9,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<ta=%ymm8,<out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV2
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV2=reg256#8,>tb=reg256#9
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV2=%ymm7,>tb=%ymm8
vpmuldq %ymm6,%ymm7,%ymm8

# qhasm: 4x out2 += tb
# asm 1: vpaddq <out2=reg256#4,<tb=reg256#9,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<tb=%ymm8,<out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod1
# asm 1: vpmuldq <d1=reg256#2,<mod1=reg256#14,>tb=reg256#9
# asm 2: vpmuldq <d1=%ymm1,<mod1=%ymm13,>tb=%ymm8
vpmuldq %ymm1,%ymm13,%ymm8

# qhasm: 4x out2 += tb
# asm 1: vpaddq <out2=reg256#4,<tb=reg256#9,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<tb=%ymm8,<out2=%ymm3
vpaddq %ymm3,%ymm8,%ymm3

# qhasm: mod2 = stack_mod2
# asm 1: vmovapd <stack_mod2=stack256#39,>mod2=reg256#9
# asm 2: vmovapd <stack_mod2=1344(%rsp),>mod2=%ymm8
vmovapd 1344(%rsp),%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod2
# asm 1: vpmuldq <d0=reg256#12,<mod2=reg256#9,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod2=%ymm8,>ta=%ymm12
vpmuldq %ymm11,%ymm8,%ymm12

# qhasm: 4x out2 += ta
# asm 1: vpaddq <out2=reg256#4,<ta=reg256#13,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<ta=%ymm12,<out2=%ymm3
vpaddq %ymm3,%ymm12,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm12
vmovapd 2400(%rsp),%ymm12

# qhasm: _2p29x4 = stack_2p29x4
# asm 1: vmovapd <stack_2p29x4=stack256#76,>_2p29x4=reg256#15
# asm 2: vmovapd <stack_2p29x4=2528(%rsp),>_2p29x4=%ymm14
vmovapd 2528(%rsp),%ymm14

# qhasm: 4x d2 = int32 minvx4 * int32 out2
# asm 1: vpmuldq <minvx4=reg256#10,<out2=reg256#4,>d2=reg256#10
# asm 2: vpmuldq <minvx4=%ymm9,<out2=%ymm3,>d2=%ymm9
vpmuldq %ymm9,%ymm3,%ymm9

# qhasm: d2 &= _2p30m1x4
# asm 1: vpand <d2=reg256#10,<_2p30m1x4=reg256#13,<d2=reg256#10
# asm 2: vpand <d2=%ymm9,<_2p30m1x4=%ymm12,<d2=%ymm9
vpand %ymm9,%ymm12,%ymm9

# qhasm: d2 ^= _2p29x4
# asm 1: vpxor <d2=reg256#10,<_2p29x4=reg256#15,<d2=reg256#10
# asm 2: vpxor <d2=%ymm9,<_2p29x4=%ymm14,<d2=%ymm9
vpxor %ymm9,%ymm14,%ymm9

# qhasm: 4x d2 -=  _2p29x4
# asm 1: vpsubq <_2p29x4=reg256#15,<d2=reg256#10,<d2=reg256#10
# asm 2: vpsubq <_2p29x4=%ymm14,<d2=%ymm9,<d2=%ymm9
vpsubq %ymm14,%ymm9,%ymm9

# qhasm: 4x ta = int32 mod0 * int32 d2
# asm 1: vpmuldq <mod0=reg256#11,<d2=reg256#10,>ta=reg256#11
# asm 2: vpmuldq <mod0=%ymm10,<d2=%ymm9,>ta=%ymm10
vpmuldq %ymm10,%ymm9,%ymm10

# qhasm: 4x out2 += ta
# asm 1: vpaddq <out2=reg256#4,<ta=reg256#11,<out2=reg256#4
# asm 2: vpaddq <out2=%ymm3,<ta=%ymm10,<out2=%ymm3
vpaddq %ymm3,%ymm10,%ymm3

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#11
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm10
vmovapd 2496(%rsp),%ymm10

# qhasm: 4x carryy = out2 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#11,<out2=reg256#4,>carryy=reg256#4
# asm 2: vpaddq <_2p63m2p33x4=%ymm10,<out2=%ymm3,>carryy=%ymm3
vpaddq %ymm10,%ymm3,%ymm3

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#4,<carryy=reg256#4
# asm 2: vpsrlq $30,<carryy=%ymm3,<carryy=%ymm3
vpsrlq $30,%ymm3,%ymm3

# qhasm: FVGS3 = stack_FVGS3
# asm 1: vmovapd <stack_FVGS3=stack256#5,>FVGS3=reg256#11
# asm 2: vmovapd <stack_FVGS3=256(%rsp),>FVGS3=%ymm10
vmovapd 256(%rsp),%ymm10

# qhasm: GSFV3 = FVGS3[1,0]
# asm 1: vpermq $0x4e,<FVGS3=reg256#11,>GSFV3=reg256#13
# asm 2: vpermq $0x4e,<FVGS3=%ymm10,>GSFV3=%ymm12
vpermq $0x4e,%ymm10,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS2
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS2=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS2=%ymm4,>ta=%ymm4
vpmuldq %ymm2,%ymm4,%ymm4

# qhasm: 4x out3 = ta + carryy
# asm 1: vpaddq <carryy=reg256#4,<ta=reg256#5,>out3=reg256#4
# asm 2: vpaddq <carryy=%ymm3,<ta=%ymm4,>out3=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV2
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV2=reg256#8,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV2=%ymm7,>tb=%ymm4
vpmuldq %ymm0,%ymm7,%ymm4

# qhasm: 4x out3 += tb
# asm 1: vpaddq <out3=reg256#4,<tb=reg256#5,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<tb=%ymm4,<out3=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS3
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS3=reg256#11,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS3=%ymm10,>ta=%ymm4
vpmuldq %ymm5,%ymm10,%ymm4

# qhasm: 4x out3 += ta
# asm 1: vpaddq <out3=reg256#4,<ta=reg256#5,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<ta=%ymm4,<out3=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV3
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV3=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV3=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out3 += tb
# asm 1: vpaddq <out3=reg256#4,<tb=reg256#5,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<tb=%ymm4,<out3=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod3 = stack_mod3
# asm 1: vmovapd <stack_mod3=stack256#40,>mod3=reg256#5
# asm 2: vmovapd <stack_mod3=1376(%rsp),>mod3=%ymm4
vmovapd 1376(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod1
# asm 1: vpmuldq <d2=reg256#10,<mod1=reg256#14,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod1=%ymm13,>ta=%ymm7
vpmuldq %ymm9,%ymm13,%ymm7

# qhasm: 4x out3 += ta
# asm 1: vpaddq <out3=reg256#4,<ta=reg256#8,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<ta=%ymm7,<out3=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod2
# asm 1: vpmuldq <d1=reg256#2,<mod2=reg256#9,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod2=%ymm8,>tb=%ymm7
vpmuldq %ymm1,%ymm8,%ymm7

# qhasm: 4x out3 += tb
# asm 1: vpaddq <out3=reg256#4,<tb=reg256#8,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<tb=%ymm7,<out3=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod3
# asm 1: vpmuldq <d0=reg256#12,<mod3=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod3=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out3 += ta
# asm 1: vpaddq <out3=reg256#4,<ta=reg256#8,<out3=reg256#4
# asm 2: vpaddq <out3=%ymm3,<ta=%ymm7,<out3=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm7
vmovapd 2400(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out3 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out3=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out3=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out3 &= _2p30m1x4
# asm 1: vpand <out3=reg256#4,<_2p30m1x4=reg256#8,<out3=reg256#4
# asm 2: vpand <out3=%ymm3,<_2p30m1x4=%ymm7,<out3=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS0 = out3
# asm 1: vmovapd <out3=reg256#4,>stack_FVGS0=stack256#1
# asm 2: vmovapd <out3=%ymm3,>stack_FVGS0=128(%rsp)
vmovapd %ymm3,128(%rsp)

# qhasm: FVGS4 = stack_FVGS4
# asm 1: vmovapd <stack_FVGS4=stack256#6,>FVGS4=reg256#4
# asm 2: vmovapd <stack_FVGS4=288(%rsp),>FVGS4=%ymm3
vmovapd 288(%rsp),%ymm3

# qhasm: GSFV4 = FVGS4[1,0]
# asm 1: vpermq $0x4e,<FVGS4=reg256#4,>GSFV4=reg256#8
# asm 2: vpermq $0x4e,<FVGS4=%ymm3,>GSFV4=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS3
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS3=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS3=%ymm10,>ta=%ymm10
vpmuldq %ymm2,%ymm10,%ymm10

# qhasm: 4x out4 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#11,>out4=reg256#11
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm10,>out4=%ymm10
vpaddq %ymm13,%ymm10,%ymm10

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV3
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV3=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV3=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out4 += tb
# asm 1: vpaddq <out4=reg256#11,<tb=reg256#13,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<tb=%ymm12,<out4=%ymm10
vpaddq %ymm10,%ymm12,%ymm10

# qhasm: 4x ta = int32 uuss0 * int32 FVGS4
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS4=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS4=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out4 += ta
# asm 1: vpaddq <out4=reg256#11,<ta=reg256#13,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<ta=%ymm12,<out4=%ymm10
vpaddq %ymm10,%ymm12,%ymm10

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV4
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV4=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV4=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out4 += tb
# asm 1: vpaddq <out4=reg256#11,<tb=reg256#13,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<tb=%ymm12,<out4=%ymm10
vpaddq %ymm10,%ymm12,%ymm10

# qhasm: mod4 = stack_mod4
# asm 1: vmovapd <stack_mod4=stack256#41,>mod4=reg256#13
# asm 2: vmovapd <stack_mod4=1408(%rsp),>mod4=%ymm12
vmovapd 1408(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod2
# asm 1: vpmuldq <d2=reg256#10,<mod2=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <d2=%ymm9,<mod2=%ymm8,>ta=%ymm8
vpmuldq %ymm9,%ymm8,%ymm8

# qhasm: 4x out4 += ta
# asm 1: vpaddq <out4=reg256#11,<ta=reg256#9,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<ta=%ymm8,<out4=%ymm10
vpaddq %ymm10,%ymm8,%ymm10

# qhasm: 4x tb = int32 d1 * int32 mod3
# asm 1: vpmuldq <d1=reg256#2,<mod3=reg256#5,>tb=reg256#9
# asm 2: vpmuldq <d1=%ymm1,<mod3=%ymm4,>tb=%ymm8
vpmuldq %ymm1,%ymm4,%ymm8

# qhasm: 4x out4 += tb
# asm 1: vpaddq <out4=reg256#11,<tb=reg256#9,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<tb=%ymm8,<out4=%ymm10
vpaddq %ymm10,%ymm8,%ymm10

# qhasm: 4x ta = int32 d0 * int32 mod4
# asm 1: vpmuldq <d0=reg256#12,<mod4=reg256#13,>ta=reg256#9
# asm 2: vpmuldq <d0=%ymm11,<mod4=%ymm12,>ta=%ymm8
vpmuldq %ymm11,%ymm12,%ymm8

# qhasm: 4x out4 += ta
# asm 1: vpaddq <out4=reg256#11,<ta=reg256#9,<out4=reg256#11
# asm 2: vpaddq <out4=%ymm10,<ta=%ymm8,<out4=%ymm10
vpaddq %ymm10,%ymm8,%ymm10

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#9
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm8
vmovapd 2400(%rsp),%ymm8

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out4 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out4=reg256#11,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out4=%ymm10,>carryy=%ymm13
vpaddq %ymm13,%ymm10,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out4 &= _2p30m1x4
# asm 1: vpand <out4=reg256#11,<_2p30m1x4=reg256#9,<out4=reg256#11
# asm 2: vpand <out4=%ymm10,<_2p30m1x4=%ymm8,<out4=%ymm10
vpand %ymm10,%ymm8,%ymm10

# qhasm: stack_FVGS1 = out4
# asm 1: vmovapd <out4=reg256#11,>stack_FVGS1=stack256#2
# asm 2: vmovapd <out4=%ymm10,>stack_FVGS1=160(%rsp)
vmovapd %ymm10,160(%rsp)

# qhasm: FVGS5 = stack_FVGS5
# asm 1: vmovapd <stack_FVGS5=stack256#7,>FVGS5=reg256#9
# asm 2: vmovapd <stack_FVGS5=320(%rsp),>FVGS5=%ymm8
vmovapd 320(%rsp),%ymm8

# qhasm: GSFV5 = FVGS5[1,0]
# asm 1: vpermq $0x4e,<FVGS5=reg256#9,>GSFV5=reg256#11
# asm 2: vpermq $0x4e,<FVGS5=%ymm8,>GSFV5=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS4
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS4=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS4=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out5 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out5=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out5=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV4
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV4=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV4=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out5 += tb
# asm 1: vpaddq <out5=reg256#4,<tb=reg256#8,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<tb=%ymm7,<out5=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS5
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS5=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS5=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out5 += ta
# asm 1: vpaddq <out5=reg256#4,<ta=reg256#8,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<ta=%ymm7,<out5=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV5
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV5=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV5=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out5 += tb
# asm 1: vpaddq <out5=reg256#4,<tb=reg256#8,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<tb=%ymm7,<out5=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod5 = stack_mod5
# asm 1: vmovapd <stack_mod5=stack256#42,>mod5=reg256#8
# asm 2: vmovapd <stack_mod5=1440(%rsp),>mod5=%ymm7
vmovapd 1440(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod3
# asm 1: vpmuldq <d2=reg256#10,<mod3=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod3=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out5 += ta
# asm 1: vpaddq <out5=reg256#4,<ta=reg256#5,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<ta=%ymm4,<out5=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod4
# asm 1: vpmuldq <d1=reg256#2,<mod4=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod4=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out5 += tb
# asm 1: vpaddq <out5=reg256#4,<tb=reg256#5,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<tb=%ymm4,<out5=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod5
# asm 1: vpmuldq <d0=reg256#12,<mod5=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod5=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out5 += ta
# asm 1: vpaddq <out5=reg256#4,<ta=reg256#5,<out5=reg256#4
# asm 2: vpaddq <out5=%ymm3,<ta=%ymm4,<out5=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out5 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out5=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out5=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out5 &= _2p30m1x4
# asm 1: vpand <out5=reg256#4,<_2p30m1x4=reg256#5,<out5=reg256#4
# asm 2: vpand <out5=%ymm3,<_2p30m1x4=%ymm4,<out5=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS2 = out5
# asm 1: vmovapd <out5=reg256#4,>stack_FVGS2=stack256#3
# asm 2: vmovapd <out5=%ymm3,>stack_FVGS2=192(%rsp)
vmovapd %ymm3,192(%rsp)

# qhasm: FVGS6 = stack_FVGS6
# asm 1: vmovapd <stack_FVGS6=stack256#8,>FVGS6=reg256#4
# asm 2: vmovapd <stack_FVGS6=352(%rsp),>FVGS6=%ymm3
vmovapd 352(%rsp),%ymm3

# qhasm: GSFV6 = FVGS6[1,0]
# asm 1: vpermq $0x4e,<FVGS6=reg256#4,>GSFV6=reg256#5
# asm 2: vpermq $0x4e,<FVGS6=%ymm3,>GSFV6=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS5
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS5=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS5=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out6 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out6=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out6=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV5
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV5=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV5=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out6 += tb
# asm 1: vpaddq <out6=reg256#9,<tb=reg256#11,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<tb=%ymm10,<out6=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS6
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS6=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS6=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out6 += ta
# asm 1: vpaddq <out6=reg256#9,<ta=reg256#11,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<ta=%ymm10,<out6=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV6
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV6=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV6=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out6 += tb
# asm 1: vpaddq <out6=reg256#9,<tb=reg256#11,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<tb=%ymm10,<out6=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod6 = stack_mod6
# asm 1: vmovapd <stack_mod6=stack256#43,>mod6=reg256#11
# asm 2: vmovapd <stack_mod6=1472(%rsp),>mod6=%ymm10
vmovapd 1472(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod4
# asm 1: vpmuldq <d2=reg256#10,<mod4=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod4=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out6 += ta
# asm 1: vpaddq <out6=reg256#9,<ta=reg256#13,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<ta=%ymm12,<out6=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod5
# asm 1: vpmuldq <d1=reg256#2,<mod5=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod5=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out6 += tb
# asm 1: vpaddq <out6=reg256#9,<tb=reg256#13,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<tb=%ymm12,<out6=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod6
# asm 1: vpmuldq <d0=reg256#12,<mod6=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod6=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out6 += ta
# asm 1: vpaddq <out6=reg256#9,<ta=reg256#13,<out6=reg256#9
# asm 2: vpaddq <out6=%ymm8,<ta=%ymm12,<out6=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm12
vmovapd 2400(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out6 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out6=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out6=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out6 &= _2p30m1x4
# asm 1: vpand <out6=reg256#9,<_2p30m1x4=reg256#13,<out6=reg256#9
# asm 2: vpand <out6=%ymm8,<_2p30m1x4=%ymm12,<out6=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS3 = out6
# asm 1: vmovapd <out6=reg256#9,>stack_FVGS3=stack256#4
# asm 2: vmovapd <out6=%ymm8,>stack_FVGS3=224(%rsp)
vmovapd %ymm8,224(%rsp)

# qhasm: FVGS7 = stack_FVGS7
# asm 1: vmovapd <stack_FVGS7=stack256#9,>FVGS7=reg256#9
# asm 2: vmovapd <stack_FVGS7=384(%rsp),>FVGS7=%ymm8
vmovapd 384(%rsp),%ymm8

# qhasm: GSFV7 = FVGS7[1,0]
# asm 1: vpermq $0x4e,<FVGS7=reg256#9,>GSFV7=reg256#13
# asm 2: vpermq $0x4e,<FVGS7=%ymm8,>GSFV7=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS6
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS6=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS6=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out7 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out7=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out7=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV6
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV6=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV6=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out7 += tb
# asm 1: vpaddq <out7=reg256#4,<tb=reg256#5,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<tb=%ymm4,<out7=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS7
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS7=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS7=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out7 += ta
# asm 1: vpaddq <out7=reg256#4,<ta=reg256#5,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<ta=%ymm4,<out7=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV7
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV7=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV7=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out7 += tb
# asm 1: vpaddq <out7=reg256#4,<tb=reg256#5,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<tb=%ymm4,<out7=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod7 = stack_mod7
# asm 1: vmovapd <stack_mod7=stack256#44,>mod7=reg256#5
# asm 2: vmovapd <stack_mod7=1504(%rsp),>mod7=%ymm4
vmovapd 1504(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod5
# asm 1: vpmuldq <d2=reg256#10,<mod5=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod5=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out7 += ta
# asm 1: vpaddq <out7=reg256#4,<ta=reg256#8,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<ta=%ymm7,<out7=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod6
# asm 1: vpmuldq <d1=reg256#2,<mod6=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod6=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out7 += tb
# asm 1: vpaddq <out7=reg256#4,<tb=reg256#8,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<tb=%ymm7,<out7=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod7
# asm 1: vpmuldq <d0=reg256#12,<mod7=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod7=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out7 += ta
# asm 1: vpaddq <out7=reg256#4,<ta=reg256#8,<out7=reg256#4
# asm 2: vpaddq <out7=%ymm3,<ta=%ymm7,<out7=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm7
vmovapd 2400(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out7 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out7=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out7=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out7 &= _2p30m1x4
# asm 1: vpand <out7=reg256#4,<_2p30m1x4=reg256#8,<out7=reg256#4
# asm 2: vpand <out7=%ymm3,<_2p30m1x4=%ymm7,<out7=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS4 = out7
# asm 1: vmovapd <out7=reg256#4,>stack_FVGS4=stack256#5
# asm 2: vmovapd <out7=%ymm3,>stack_FVGS4=256(%rsp)
vmovapd %ymm3,256(%rsp)

# qhasm: FVGS8 = stack_FVGS8
# asm 1: vmovapd <stack_FVGS8=stack256#10,>FVGS8=reg256#4
# asm 2: vmovapd <stack_FVGS8=416(%rsp),>FVGS8=%ymm3
vmovapd 416(%rsp),%ymm3

# qhasm: GSFV8 = FVGS8[1,0]
# asm 1: vpermq $0x4e,<FVGS8=reg256#4,>GSFV8=reg256#8
# asm 2: vpermq $0x4e,<FVGS8=%ymm3,>GSFV8=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS7
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS7=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS7=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out8 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out8=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out8=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV7
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV7=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV7=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out8 += tb
# asm 1: vpaddq <out8=reg256#9,<tb=reg256#13,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<tb=%ymm12,<out8=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS8
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS8=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS8=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out8 += ta
# asm 1: vpaddq <out8=reg256#9,<ta=reg256#13,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<ta=%ymm12,<out8=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV8
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV8=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV8=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out8 += tb
# asm 1: vpaddq <out8=reg256#9,<tb=reg256#13,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<tb=%ymm12,<out8=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod8 = stack_mod8
# asm 1: vmovapd <stack_mod8=stack256#45,>mod8=reg256#13
# asm 2: vmovapd <stack_mod8=1536(%rsp),>mod8=%ymm12
vmovapd 1536(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod6
# asm 1: vpmuldq <d2=reg256#10,<mod6=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod6=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out8 += ta
# asm 1: vpaddq <out8=reg256#9,<ta=reg256#11,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<ta=%ymm10,<out8=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod7
# asm 1: vpmuldq <d1=reg256#2,<mod7=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod7=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out8 += tb
# asm 1: vpaddq <out8=reg256#9,<tb=reg256#11,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<tb=%ymm10,<out8=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod8
# asm 1: vpmuldq <d0=reg256#12,<mod8=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod8=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out8 += ta
# asm 1: vpaddq <out8=reg256#9,<ta=reg256#11,<out8=reg256#9
# asm 2: vpaddq <out8=%ymm8,<ta=%ymm10,<out8=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm10
vmovapd 2400(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out8 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out8=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out8=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out8 &= _2p30m1x4
# asm 1: vpand <out8=reg256#9,<_2p30m1x4=reg256#11,<out8=reg256#9
# asm 2: vpand <out8=%ymm8,<_2p30m1x4=%ymm10,<out8=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS5 = out8
# asm 1: vmovapd <out8=reg256#9,>stack_FVGS5=stack256#6
# asm 2: vmovapd <out8=%ymm8,>stack_FVGS5=288(%rsp)
vmovapd %ymm8,288(%rsp)

# qhasm: FVGS9 = stack_FVGS9
# asm 1: vmovapd <stack_FVGS9=stack256#11,>FVGS9=reg256#9
# asm 2: vmovapd <stack_FVGS9=448(%rsp),>FVGS9=%ymm8
vmovapd 448(%rsp),%ymm8

# qhasm: GSFV9 = FVGS9[1,0]
# asm 1: vpermq $0x4e,<FVGS9=reg256#9,>GSFV9=reg256#11
# asm 2: vpermq $0x4e,<FVGS9=%ymm8,>GSFV9=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS8
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS8=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS8=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out9 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out9=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out9=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV8
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV8=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV8=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out9 += tb
# asm 1: vpaddq <out9=reg256#4,<tb=reg256#8,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<tb=%ymm7,<out9=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS9
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS9=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS9=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out9 += ta
# asm 1: vpaddq <out9=reg256#4,<ta=reg256#8,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<ta=%ymm7,<out9=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV9
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV9=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV9=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out9 += tb
# asm 1: vpaddq <out9=reg256#4,<tb=reg256#8,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<tb=%ymm7,<out9=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod9 = stack_mod9
# asm 1: vmovapd <stack_mod9=stack256#46,>mod9=reg256#8
# asm 2: vmovapd <stack_mod9=1568(%rsp),>mod9=%ymm7
vmovapd 1568(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod7
# asm 1: vpmuldq <d2=reg256#10,<mod7=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod7=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out9 += ta
# asm 1: vpaddq <out9=reg256#4,<ta=reg256#5,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<ta=%ymm4,<out9=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod8
# asm 1: vpmuldq <d1=reg256#2,<mod8=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod8=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out9 += tb
# asm 1: vpaddq <out9=reg256#4,<tb=reg256#5,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<tb=%ymm4,<out9=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod9
# asm 1: vpmuldq <d0=reg256#12,<mod9=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod9=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out9 += ta
# asm 1: vpaddq <out9=reg256#4,<ta=reg256#5,<out9=reg256#4
# asm 2: vpaddq <out9=%ymm3,<ta=%ymm4,<out9=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out9 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out9=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out9=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out9 &= _2p30m1x4
# asm 1: vpand <out9=reg256#4,<_2p30m1x4=reg256#5,<out9=reg256#4
# asm 2: vpand <out9=%ymm3,<_2p30m1x4=%ymm4,<out9=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS6 = out9
# asm 1: vmovapd <out9=reg256#4,>stack_FVGS6=stack256#7
# asm 2: vmovapd <out9=%ymm3,>stack_FVGS6=320(%rsp)
vmovapd %ymm3,320(%rsp)

# qhasm: FVGS10 = stack_FVGS10
# asm 1: vmovapd <stack_FVGS10=stack256#12,>FVGS10=reg256#4
# asm 2: vmovapd <stack_FVGS10=480(%rsp),>FVGS10=%ymm3
vmovapd 480(%rsp),%ymm3

# qhasm: GSFV10 = FVGS10[1,0]
# asm 1: vpermq $0x4e,<FVGS10=reg256#4,>GSFV10=reg256#5
# asm 2: vpermq $0x4e,<FVGS10=%ymm3,>GSFV10=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS9
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS9=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS9=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out10 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out10=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out10=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV9
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV9=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV9=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out10 += tb
# asm 1: vpaddq <out10=reg256#9,<tb=reg256#11,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<tb=%ymm10,<out10=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS10
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS10=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS10=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out10 += ta
# asm 1: vpaddq <out10=reg256#9,<ta=reg256#11,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<ta=%ymm10,<out10=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV10
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV10=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV10=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out10 += tb
# asm 1: vpaddq <out10=reg256#9,<tb=reg256#11,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<tb=%ymm10,<out10=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod10 = stack_mod10
# asm 1: vmovapd <stack_mod10=stack256#47,>mod10=reg256#11
# asm 2: vmovapd <stack_mod10=1600(%rsp),>mod10=%ymm10
vmovapd 1600(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod8
# asm 1: vpmuldq <d2=reg256#10,<mod8=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod8=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out10 += ta
# asm 1: vpaddq <out10=reg256#9,<ta=reg256#13,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<ta=%ymm12,<out10=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod9
# asm 1: vpmuldq <d1=reg256#2,<mod9=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod9=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out10 += tb
# asm 1: vpaddq <out10=reg256#9,<tb=reg256#13,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<tb=%ymm12,<out10=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod10
# asm 1: vpmuldq <d0=reg256#12,<mod10=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod10=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out10 += ta
# asm 1: vpaddq <out10=reg256#9,<ta=reg256#13,<out10=reg256#9
# asm 2: vpaddq <out10=%ymm8,<ta=%ymm12,<out10=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm12
vmovapd 2400(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out10 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out10=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out10=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out10 &= _2p30m1x4
# asm 1: vpand <out10=reg256#9,<_2p30m1x4=reg256#13,<out10=reg256#9
# asm 2: vpand <out10=%ymm8,<_2p30m1x4=%ymm12,<out10=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS7 = out10
# asm 1: vmovapd <out10=reg256#9,>stack_FVGS7=stack256#8
# asm 2: vmovapd <out10=%ymm8,>stack_FVGS7=352(%rsp)
vmovapd %ymm8,352(%rsp)

# qhasm: FVGS11 = stack_FVGS11
# asm 1: vmovapd <stack_FVGS11=stack256#13,>FVGS11=reg256#9
# asm 2: vmovapd <stack_FVGS11=512(%rsp),>FVGS11=%ymm8
vmovapd 512(%rsp),%ymm8

# qhasm: GSFV11 = FVGS11[1,0]
# asm 1: vpermq $0x4e,<FVGS11=reg256#9,>GSFV11=reg256#13
# asm 2: vpermq $0x4e,<FVGS11=%ymm8,>GSFV11=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS10
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS10=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS10=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out11 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out11=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out11=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV10
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV10=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV10=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out11 += tb
# asm 1: vpaddq <out11=reg256#4,<tb=reg256#5,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<tb=%ymm4,<out11=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS11
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS11=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS11=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out11 += ta
# asm 1: vpaddq <out11=reg256#4,<ta=reg256#5,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<ta=%ymm4,<out11=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV11
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV11=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV11=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out11 += tb
# asm 1: vpaddq <out11=reg256#4,<tb=reg256#5,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<tb=%ymm4,<out11=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod11 = stack_mod11
# asm 1: vmovapd <stack_mod11=stack256#48,>mod11=reg256#5
# asm 2: vmovapd <stack_mod11=1632(%rsp),>mod11=%ymm4
vmovapd 1632(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod9
# asm 1: vpmuldq <d2=reg256#10,<mod9=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod9=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out11 += ta
# asm 1: vpaddq <out11=reg256#4,<ta=reg256#8,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<ta=%ymm7,<out11=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod10
# asm 1: vpmuldq <d1=reg256#2,<mod10=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod10=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out11 += tb
# asm 1: vpaddq <out11=reg256#4,<tb=reg256#8,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<tb=%ymm7,<out11=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod11
# asm 1: vpmuldq <d0=reg256#12,<mod11=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod11=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out11 += ta
# asm 1: vpaddq <out11=reg256#4,<ta=reg256#8,<out11=reg256#4
# asm 2: vpaddq <out11=%ymm3,<ta=%ymm7,<out11=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm7
vmovapd 2400(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out11 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out11=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out11=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out11 &= _2p30m1x4
# asm 1: vpand <out11=reg256#4,<_2p30m1x4=reg256#8,<out11=reg256#4
# asm 2: vpand <out11=%ymm3,<_2p30m1x4=%ymm7,<out11=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS8 = out11
# asm 1: vmovapd <out11=reg256#4,>stack_FVGS8=stack256#9
# asm 2: vmovapd <out11=%ymm3,>stack_FVGS8=384(%rsp)
vmovapd %ymm3,384(%rsp)

# qhasm: FVGS12 = stack_FVGS12
# asm 1: vmovapd <stack_FVGS12=stack256#14,>FVGS12=reg256#4
# asm 2: vmovapd <stack_FVGS12=544(%rsp),>FVGS12=%ymm3
vmovapd 544(%rsp),%ymm3

# qhasm: GSFV12 = FVGS12[1,0]
# asm 1: vpermq $0x4e,<FVGS12=reg256#4,>GSFV12=reg256#8
# asm 2: vpermq $0x4e,<FVGS12=%ymm3,>GSFV12=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS11
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS11=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS11=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out12 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out12=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out12=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV11
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV11=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV11=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out12 += tb
# asm 1: vpaddq <out12=reg256#9,<tb=reg256#13,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<tb=%ymm12,<out12=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS12
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS12=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS12=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out12 += ta
# asm 1: vpaddq <out12=reg256#9,<ta=reg256#13,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<ta=%ymm12,<out12=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV12
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV12=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV12=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out12 += tb
# asm 1: vpaddq <out12=reg256#9,<tb=reg256#13,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<tb=%ymm12,<out12=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod12 = stack_mod12
# asm 1: vmovapd <stack_mod12=stack256#49,>mod12=reg256#13
# asm 2: vmovapd <stack_mod12=1664(%rsp),>mod12=%ymm12
vmovapd 1664(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod10
# asm 1: vpmuldq <d2=reg256#10,<mod10=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod10=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out12 += ta
# asm 1: vpaddq <out12=reg256#9,<ta=reg256#11,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<ta=%ymm10,<out12=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod11
# asm 1: vpmuldq <d1=reg256#2,<mod11=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod11=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out12 += tb
# asm 1: vpaddq <out12=reg256#9,<tb=reg256#11,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<tb=%ymm10,<out12=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod12
# asm 1: vpmuldq <d0=reg256#12,<mod12=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod12=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out12 += ta
# asm 1: vpaddq <out12=reg256#9,<ta=reg256#11,<out12=reg256#9
# asm 2: vpaddq <out12=%ymm8,<ta=%ymm10,<out12=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm10
vmovapd 2400(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out12 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out12=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out12=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out12 &= _2p30m1x4
# asm 1: vpand <out12=reg256#9,<_2p30m1x4=reg256#11,<out12=reg256#9
# asm 2: vpand <out12=%ymm8,<_2p30m1x4=%ymm10,<out12=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS9 = out12
# asm 1: vmovapd <out12=reg256#9,>stack_FVGS9=stack256#10
# asm 2: vmovapd <out12=%ymm8,>stack_FVGS9=416(%rsp)
vmovapd %ymm8,416(%rsp)

# qhasm: FVGS13 = stack_FVGS13
# asm 1: vmovapd <stack_FVGS13=stack256#15,>FVGS13=reg256#9
# asm 2: vmovapd <stack_FVGS13=576(%rsp),>FVGS13=%ymm8
vmovapd 576(%rsp),%ymm8

# qhasm: GSFV13 = FVGS13[1,0]
# asm 1: vpermq $0x4e,<FVGS13=reg256#9,>GSFV13=reg256#11
# asm 2: vpermq $0x4e,<FVGS13=%ymm8,>GSFV13=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS12
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS12=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS12=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out13 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out13=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out13=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV12
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV12=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV12=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out13 += tb
# asm 1: vpaddq <out13=reg256#4,<tb=reg256#8,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<tb=%ymm7,<out13=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS13
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS13=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS13=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out13 += ta
# asm 1: vpaddq <out13=reg256#4,<ta=reg256#8,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<ta=%ymm7,<out13=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV13
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV13=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV13=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out13 += tb
# asm 1: vpaddq <out13=reg256#4,<tb=reg256#8,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<tb=%ymm7,<out13=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod13 = stack_mod13
# asm 1: vmovapd <stack_mod13=stack256#50,>mod13=reg256#8
# asm 2: vmovapd <stack_mod13=1696(%rsp),>mod13=%ymm7
vmovapd 1696(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod11
# asm 1: vpmuldq <d2=reg256#10,<mod11=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod11=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out13 += ta
# asm 1: vpaddq <out13=reg256#4,<ta=reg256#5,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<ta=%ymm4,<out13=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod12
# asm 1: vpmuldq <d1=reg256#2,<mod12=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod12=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out13 += tb
# asm 1: vpaddq <out13=reg256#4,<tb=reg256#5,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<tb=%ymm4,<out13=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod13
# asm 1: vpmuldq <d0=reg256#12,<mod13=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod13=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out13 += ta
# asm 1: vpaddq <out13=reg256#4,<ta=reg256#5,<out13=reg256#4
# asm 2: vpaddq <out13=%ymm3,<ta=%ymm4,<out13=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out13 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out13=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out13=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out13 &= _2p30m1x4
# asm 1: vpand <out13=reg256#4,<_2p30m1x4=reg256#5,<out13=reg256#4
# asm 2: vpand <out13=%ymm3,<_2p30m1x4=%ymm4,<out13=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS10 = out13
# asm 1: vmovapd <out13=reg256#4,>stack_FVGS10=stack256#11
# asm 2: vmovapd <out13=%ymm3,>stack_FVGS10=448(%rsp)
vmovapd %ymm3,448(%rsp)

# qhasm: FVGS14 = stack_FVGS14
# asm 1: vmovapd <stack_FVGS14=stack256#16,>FVGS14=reg256#4
# asm 2: vmovapd <stack_FVGS14=608(%rsp),>FVGS14=%ymm3
vmovapd 608(%rsp),%ymm3

# qhasm: GSFV14 = FVGS14[1,0]
# asm 1: vpermq $0x4e,<FVGS14=reg256#4,>GSFV14=reg256#5
# asm 2: vpermq $0x4e,<FVGS14=%ymm3,>GSFV14=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS13
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS13=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS13=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out14 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out14=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out14=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV13
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV13=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV13=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out14 += tb
# asm 1: vpaddq <out14=reg256#9,<tb=reg256#11,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<tb=%ymm10,<out14=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS14
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS14=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS14=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out14 += ta
# asm 1: vpaddq <out14=reg256#9,<ta=reg256#11,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<ta=%ymm10,<out14=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV14
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV14=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV14=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out14 += tb
# asm 1: vpaddq <out14=reg256#9,<tb=reg256#11,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<tb=%ymm10,<out14=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod14 = stack_mod14
# asm 1: vmovapd <stack_mod14=stack256#51,>mod14=reg256#11
# asm 2: vmovapd <stack_mod14=1728(%rsp),>mod14=%ymm10
vmovapd 1728(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod12
# asm 1: vpmuldq <d2=reg256#10,<mod12=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod12=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out14 += ta
# asm 1: vpaddq <out14=reg256#9,<ta=reg256#13,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<ta=%ymm12,<out14=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod13
# asm 1: vpmuldq <d1=reg256#2,<mod13=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod13=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out14 += tb
# asm 1: vpaddq <out14=reg256#9,<tb=reg256#13,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<tb=%ymm12,<out14=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod14
# asm 1: vpmuldq <d0=reg256#12,<mod14=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod14=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out14 += ta
# asm 1: vpaddq <out14=reg256#9,<ta=reg256#13,<out14=reg256#9
# asm 2: vpaddq <out14=%ymm8,<ta=%ymm12,<out14=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm12
vmovapd 2400(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out14 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out14=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out14=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out14 &= _2p30m1x4
# asm 1: vpand <out14=reg256#9,<_2p30m1x4=reg256#13,<out14=reg256#9
# asm 2: vpand <out14=%ymm8,<_2p30m1x4=%ymm12,<out14=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS11 = out14
# asm 1: vmovapd <out14=reg256#9,>stack_FVGS11=stack256#12
# asm 2: vmovapd <out14=%ymm8,>stack_FVGS11=480(%rsp)
vmovapd %ymm8,480(%rsp)

# qhasm: FVGS15 = stack_FVGS15
# asm 1: vmovapd <stack_FVGS15=stack256#17,>FVGS15=reg256#9
# asm 2: vmovapd <stack_FVGS15=640(%rsp),>FVGS15=%ymm8
vmovapd 640(%rsp),%ymm8

# qhasm: GSFV15 = FVGS15[1,0]
# asm 1: vpermq $0x4e,<FVGS15=reg256#9,>GSFV15=reg256#13
# asm 2: vpermq $0x4e,<FVGS15=%ymm8,>GSFV15=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS14
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS14=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS14=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out15 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out15=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out15=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV14
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV14=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV14=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out15 += tb
# asm 1: vpaddq <out15=reg256#4,<tb=reg256#5,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<tb=%ymm4,<out15=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS15
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS15=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS15=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out15 += ta
# asm 1: vpaddq <out15=reg256#4,<ta=reg256#5,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<ta=%ymm4,<out15=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV15
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV15=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV15=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out15 += tb
# asm 1: vpaddq <out15=reg256#4,<tb=reg256#5,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<tb=%ymm4,<out15=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod15 = stack_mod15
# asm 1: vmovapd <stack_mod15=stack256#52,>mod15=reg256#5
# asm 2: vmovapd <stack_mod15=1760(%rsp),>mod15=%ymm4
vmovapd 1760(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod13
# asm 1: vpmuldq <d2=reg256#10,<mod13=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod13=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out15 += ta
# asm 1: vpaddq <out15=reg256#4,<ta=reg256#8,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<ta=%ymm7,<out15=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod14
# asm 1: vpmuldq <d1=reg256#2,<mod14=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod14=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out15 += tb
# asm 1: vpaddq <out15=reg256#4,<tb=reg256#8,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<tb=%ymm7,<out15=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod15
# asm 1: vpmuldq <d0=reg256#12,<mod15=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod15=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out15 += ta
# asm 1: vpaddq <out15=reg256#4,<ta=reg256#8,<out15=reg256#4
# asm 2: vpaddq <out15=%ymm3,<ta=%ymm7,<out15=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm7
vmovapd 2400(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out15 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out15=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out15=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out15 &= _2p30m1x4
# asm 1: vpand <out15=reg256#4,<_2p30m1x4=reg256#8,<out15=reg256#4
# asm 2: vpand <out15=%ymm3,<_2p30m1x4=%ymm7,<out15=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS12 = out15
# asm 1: vmovapd <out15=reg256#4,>stack_FVGS12=stack256#13
# asm 2: vmovapd <out15=%ymm3,>stack_FVGS12=512(%rsp)
vmovapd %ymm3,512(%rsp)

# qhasm: FVGS16 = stack_FVGS16
# asm 1: vmovapd <stack_FVGS16=stack256#18,>FVGS16=reg256#4
# asm 2: vmovapd <stack_FVGS16=672(%rsp),>FVGS16=%ymm3
vmovapd 672(%rsp),%ymm3

# qhasm: GSFV16 = FVGS16[1,0]
# asm 1: vpermq $0x4e,<FVGS16=reg256#4,>GSFV16=reg256#8
# asm 2: vpermq $0x4e,<FVGS16=%ymm3,>GSFV16=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS15
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS15=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS15=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out16 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out16=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out16=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV15
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV15=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV15=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out16 += tb
# asm 1: vpaddq <out16=reg256#9,<tb=reg256#13,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<tb=%ymm12,<out16=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS16
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS16=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS16=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out16 += ta
# asm 1: vpaddq <out16=reg256#9,<ta=reg256#13,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<ta=%ymm12,<out16=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV16
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV16=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV16=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out16 += tb
# asm 1: vpaddq <out16=reg256#9,<tb=reg256#13,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<tb=%ymm12,<out16=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod16 = stack_mod16
# asm 1: vmovapd <stack_mod16=stack256#53,>mod16=reg256#13
# asm 2: vmovapd <stack_mod16=1792(%rsp),>mod16=%ymm12
vmovapd 1792(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod14
# asm 1: vpmuldq <d2=reg256#10,<mod14=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod14=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out16 += ta
# asm 1: vpaddq <out16=reg256#9,<ta=reg256#11,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<ta=%ymm10,<out16=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod15
# asm 1: vpmuldq <d1=reg256#2,<mod15=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod15=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out16 += tb
# asm 1: vpaddq <out16=reg256#9,<tb=reg256#11,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<tb=%ymm10,<out16=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod16
# asm 1: vpmuldq <d0=reg256#12,<mod16=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod16=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out16 += ta
# asm 1: vpaddq <out16=reg256#9,<ta=reg256#11,<out16=reg256#9
# asm 2: vpaddq <out16=%ymm8,<ta=%ymm10,<out16=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm10
vmovapd 2400(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out16 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out16=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out16=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out16 &= _2p30m1x4
# asm 1: vpand <out16=reg256#9,<_2p30m1x4=reg256#11,<out16=reg256#9
# asm 2: vpand <out16=%ymm8,<_2p30m1x4=%ymm10,<out16=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS13 = out16
# asm 1: vmovapd <out16=reg256#9,>stack_FVGS13=stack256#14
# asm 2: vmovapd <out16=%ymm8,>stack_FVGS13=544(%rsp)
vmovapd %ymm8,544(%rsp)

# qhasm: FVGS17 = stack_FVGS17
# asm 1: vmovapd <stack_FVGS17=stack256#19,>FVGS17=reg256#9
# asm 2: vmovapd <stack_FVGS17=704(%rsp),>FVGS17=%ymm8
vmovapd 704(%rsp),%ymm8

# qhasm: GSFV17 = FVGS17[1,0]
# asm 1: vpermq $0x4e,<FVGS17=reg256#9,>GSFV17=reg256#11
# asm 2: vpermq $0x4e,<FVGS17=%ymm8,>GSFV17=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS16
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS16=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS16=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out17 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out17=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out17=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV16
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV16=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV16=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out17 += tb
# asm 1: vpaddq <out17=reg256#4,<tb=reg256#8,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<tb=%ymm7,<out17=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS17
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS17=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS17=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out17 += ta
# asm 1: vpaddq <out17=reg256#4,<ta=reg256#8,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<ta=%ymm7,<out17=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV17
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV17=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV17=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out17 += tb
# asm 1: vpaddq <out17=reg256#4,<tb=reg256#8,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<tb=%ymm7,<out17=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod17 = stack_mod17
# asm 1: vmovapd <stack_mod17=stack256#54,>mod17=reg256#8
# asm 2: vmovapd <stack_mod17=1824(%rsp),>mod17=%ymm7
vmovapd 1824(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod15
# asm 1: vpmuldq <d2=reg256#10,<mod15=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod15=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out17 += ta
# asm 1: vpaddq <out17=reg256#4,<ta=reg256#5,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<ta=%ymm4,<out17=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod16
# asm 1: vpmuldq <d1=reg256#2,<mod16=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod16=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out17 += tb
# asm 1: vpaddq <out17=reg256#4,<tb=reg256#5,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<tb=%ymm4,<out17=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod17
# asm 1: vpmuldq <d0=reg256#12,<mod17=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod17=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out17 += ta
# asm 1: vpaddq <out17=reg256#4,<ta=reg256#5,<out17=reg256#4
# asm 2: vpaddq <out17=%ymm3,<ta=%ymm4,<out17=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out17 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out17=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out17=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out17 &= _2p30m1x4
# asm 1: vpand <out17=reg256#4,<_2p30m1x4=reg256#5,<out17=reg256#4
# asm 2: vpand <out17=%ymm3,<_2p30m1x4=%ymm4,<out17=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS14 = out17
# asm 1: vmovapd <out17=reg256#4,>stack_FVGS14=stack256#15
# asm 2: vmovapd <out17=%ymm3,>stack_FVGS14=576(%rsp)
vmovapd %ymm3,576(%rsp)

# qhasm: FVGS18 = stack_FVGS18
# asm 1: vmovapd <stack_FVGS18=stack256#20,>FVGS18=reg256#4
# asm 2: vmovapd <stack_FVGS18=736(%rsp),>FVGS18=%ymm3
vmovapd 736(%rsp),%ymm3

# qhasm: GSFV18 = FVGS18[1,0]
# asm 1: vpermq $0x4e,<FVGS18=reg256#4,>GSFV18=reg256#5
# asm 2: vpermq $0x4e,<FVGS18=%ymm3,>GSFV18=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS17
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS17=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS17=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out18 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out18=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out18=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV17
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV17=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV17=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out18 += tb
# asm 1: vpaddq <out18=reg256#9,<tb=reg256#11,<out18=reg256#9
# asm 2: vpaddq <out18=%ymm8,<tb=%ymm10,<out18=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS18
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS18=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS18=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out18 += ta
# asm 1: vpaddq <out18=reg256#9,<ta=reg256#11,<out18=reg256#9
# asm 2: vpaddq <out18=%ymm8,<ta=%ymm10,<out18=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV18
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV18=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV18=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out18 += tb
# asm 1: vpaddq <out18=reg256#9,<tb=reg256#11,<out18=reg256#9
# asm 2: vpaddq <out18=%ymm8,<tb=%ymm10,<out18=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod18 = stack_mod18
# asm 1: vmovapd <stack_mod18=stack256#55,>mod18=reg256#11
# asm 2: vmovapd <stack_mod18=1856(%rsp),>mod18=%ymm10
vmovapd 1856(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod16
# asm 1: vpmuldq <d2=reg256#10,<mod16=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod16=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out18 += ta
# asm 1: vpaddq <out18=reg256#9,<ta=reg256#13,<out18=reg256#9
# asm 2: vpaddq <out18=%ymm8,<ta=%ymm12,<out18=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod17
# asm 1: vpmuldq <d1=reg256#2,<mod17=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod17=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out18 += tb
# asm 1: vpaddq <out18=reg256#9,<tb=reg256#13,<out18=reg256#9
# asm 2: vpaddq <out18=%ymm8,<tb=%ymm12,<out18=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod18
# asm 1: vpmuldq <d0=reg256#12,<mod18=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod18=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out18 += ta
# asm 1: vpaddq <out18=reg256#9,<ta=reg256#13,<out18=reg256#9
# asm 2: vpaddq <out18=%ymm8,<ta=%ymm12,<out18=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm12
vmovapd 2400(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out18 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out18=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out18=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out18 &= _2p30m1x4
# asm 1: vpand <out18=reg256#9,<_2p30m1x4=reg256#13,<out18=reg256#9
# asm 2: vpand <out18=%ymm8,<_2p30m1x4=%ymm12,<out18=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS15 = out18
# asm 1: vmovapd <out18=reg256#9,>stack_FVGS15=stack256#16
# asm 2: vmovapd <out18=%ymm8,>stack_FVGS15=608(%rsp)
vmovapd %ymm8,608(%rsp)

# qhasm: FVGS19 = stack_FVGS19
# asm 1: vmovapd <stack_FVGS19=stack256#21,>FVGS19=reg256#9
# asm 2: vmovapd <stack_FVGS19=768(%rsp),>FVGS19=%ymm8
vmovapd 768(%rsp),%ymm8

# qhasm: GSFV19 = FVGS19[1,0]
# asm 1: vpermq $0x4e,<FVGS19=reg256#9,>GSFV19=reg256#13
# asm 2: vpermq $0x4e,<FVGS19=%ymm8,>GSFV19=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS18
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS18=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS18=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out19 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out19=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out19=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV18
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV18=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV18=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out19 += tb
# asm 1: vpaddq <out19=reg256#4,<tb=reg256#5,<out19=reg256#4
# asm 2: vpaddq <out19=%ymm3,<tb=%ymm4,<out19=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS19
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS19=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS19=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out19 += ta
# asm 1: vpaddq <out19=reg256#4,<ta=reg256#5,<out19=reg256#4
# asm 2: vpaddq <out19=%ymm3,<ta=%ymm4,<out19=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV19
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV19=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV19=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out19 += tb
# asm 1: vpaddq <out19=reg256#4,<tb=reg256#5,<out19=reg256#4
# asm 2: vpaddq <out19=%ymm3,<tb=%ymm4,<out19=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod19 = stack_mod19
# asm 1: vmovapd <stack_mod19=stack256#56,>mod19=reg256#5
# asm 2: vmovapd <stack_mod19=1888(%rsp),>mod19=%ymm4
vmovapd 1888(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod17
# asm 1: vpmuldq <d2=reg256#10,<mod17=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod17=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out19 += ta
# asm 1: vpaddq <out19=reg256#4,<ta=reg256#8,<out19=reg256#4
# asm 2: vpaddq <out19=%ymm3,<ta=%ymm7,<out19=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod18
# asm 1: vpmuldq <d1=reg256#2,<mod18=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod18=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out19 += tb
# asm 1: vpaddq <out19=reg256#4,<tb=reg256#8,<out19=reg256#4
# asm 2: vpaddq <out19=%ymm3,<tb=%ymm7,<out19=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod19
# asm 1: vpmuldq <d0=reg256#12,<mod19=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod19=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out19 += ta
# asm 1: vpaddq <out19=reg256#4,<ta=reg256#8,<out19=reg256#4
# asm 2: vpaddq <out19=%ymm3,<ta=%ymm7,<out19=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm7
vmovapd 2400(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out19 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out19=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out19=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out19 &= _2p30m1x4
# asm 1: vpand <out19=reg256#4,<_2p30m1x4=reg256#8,<out19=reg256#4
# asm 2: vpand <out19=%ymm3,<_2p30m1x4=%ymm7,<out19=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS16 = out19
# asm 1: vmovapd <out19=reg256#4,>stack_FVGS16=stack256#17
# asm 2: vmovapd <out19=%ymm3,>stack_FVGS16=640(%rsp)
vmovapd %ymm3,640(%rsp)

# qhasm: FVGS20 = stack_FVGS20
# asm 1: vmovapd <stack_FVGS20=stack256#22,>FVGS20=reg256#4
# asm 2: vmovapd <stack_FVGS20=800(%rsp),>FVGS20=%ymm3
vmovapd 800(%rsp),%ymm3

# qhasm: GSFV20 = FVGS20[1,0]
# asm 1: vpermq $0x4e,<FVGS20=reg256#4,>GSFV20=reg256#8
# asm 2: vpermq $0x4e,<FVGS20=%ymm3,>GSFV20=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS19
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS19=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS19=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out20 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out20=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out20=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV19
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV19=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV19=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out20 += tb
# asm 1: vpaddq <out20=reg256#9,<tb=reg256#13,<out20=reg256#9
# asm 2: vpaddq <out20=%ymm8,<tb=%ymm12,<out20=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS20
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS20=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS20=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out20 += ta
# asm 1: vpaddq <out20=reg256#9,<ta=reg256#13,<out20=reg256#9
# asm 2: vpaddq <out20=%ymm8,<ta=%ymm12,<out20=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV20
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV20=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV20=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out20 += tb
# asm 1: vpaddq <out20=reg256#9,<tb=reg256#13,<out20=reg256#9
# asm 2: vpaddq <out20=%ymm8,<tb=%ymm12,<out20=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod20 = stack_mod20
# asm 1: vmovapd <stack_mod20=stack256#57,>mod20=reg256#13
# asm 2: vmovapd <stack_mod20=1920(%rsp),>mod20=%ymm12
vmovapd 1920(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod18
# asm 1: vpmuldq <d2=reg256#10,<mod18=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod18=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out20 += ta
# asm 1: vpaddq <out20=reg256#9,<ta=reg256#11,<out20=reg256#9
# asm 2: vpaddq <out20=%ymm8,<ta=%ymm10,<out20=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod19
# asm 1: vpmuldq <d1=reg256#2,<mod19=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod19=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out20 += tb
# asm 1: vpaddq <out20=reg256#9,<tb=reg256#11,<out20=reg256#9
# asm 2: vpaddq <out20=%ymm8,<tb=%ymm10,<out20=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod20
# asm 1: vpmuldq <d0=reg256#12,<mod20=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod20=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out20 += ta
# asm 1: vpaddq <out20=reg256#9,<ta=reg256#11,<out20=reg256#9
# asm 2: vpaddq <out20=%ymm8,<ta=%ymm10,<out20=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm10
vmovapd 2400(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out20 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out20=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out20=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out20 &= _2p30m1x4
# asm 1: vpand <out20=reg256#9,<_2p30m1x4=reg256#11,<out20=reg256#9
# asm 2: vpand <out20=%ymm8,<_2p30m1x4=%ymm10,<out20=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS17 = out20
# asm 1: vmovapd <out20=reg256#9,>stack_FVGS17=stack256#18
# asm 2: vmovapd <out20=%ymm8,>stack_FVGS17=672(%rsp)
vmovapd %ymm8,672(%rsp)

# qhasm: FVGS21 = stack_FVGS21
# asm 1: vmovapd <stack_FVGS21=stack256#23,>FVGS21=reg256#9
# asm 2: vmovapd <stack_FVGS21=832(%rsp),>FVGS21=%ymm8
vmovapd 832(%rsp),%ymm8

# qhasm: GSFV21 = FVGS21[1,0]
# asm 1: vpermq $0x4e,<FVGS21=reg256#9,>GSFV21=reg256#11
# asm 2: vpermq $0x4e,<FVGS21=%ymm8,>GSFV21=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS20
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS20=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS20=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out21 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out21=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out21=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV20
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV20=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV20=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out21 += tb
# asm 1: vpaddq <out21=reg256#4,<tb=reg256#8,<out21=reg256#4
# asm 2: vpaddq <out21=%ymm3,<tb=%ymm7,<out21=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS21
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS21=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS21=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out21 += ta
# asm 1: vpaddq <out21=reg256#4,<ta=reg256#8,<out21=reg256#4
# asm 2: vpaddq <out21=%ymm3,<ta=%ymm7,<out21=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV21
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV21=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV21=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out21 += tb
# asm 1: vpaddq <out21=reg256#4,<tb=reg256#8,<out21=reg256#4
# asm 2: vpaddq <out21=%ymm3,<tb=%ymm7,<out21=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod21 = stack_mod21
# asm 1: vmovapd <stack_mod21=stack256#58,>mod21=reg256#8
# asm 2: vmovapd <stack_mod21=1952(%rsp),>mod21=%ymm7
vmovapd 1952(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod19
# asm 1: vpmuldq <d2=reg256#10,<mod19=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod19=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out21 += ta
# asm 1: vpaddq <out21=reg256#4,<ta=reg256#5,<out21=reg256#4
# asm 2: vpaddq <out21=%ymm3,<ta=%ymm4,<out21=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod20
# asm 1: vpmuldq <d1=reg256#2,<mod20=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod20=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out21 += tb
# asm 1: vpaddq <out21=reg256#4,<tb=reg256#5,<out21=reg256#4
# asm 2: vpaddq <out21=%ymm3,<tb=%ymm4,<out21=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod21
# asm 1: vpmuldq <d0=reg256#12,<mod21=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod21=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out21 += ta
# asm 1: vpaddq <out21=reg256#4,<ta=reg256#5,<out21=reg256#4
# asm 2: vpaddq <out21=%ymm3,<ta=%ymm4,<out21=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out21 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out21=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out21=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out21 &= _2p30m1x4
# asm 1: vpand <out21=reg256#4,<_2p30m1x4=reg256#5,<out21=reg256#4
# asm 2: vpand <out21=%ymm3,<_2p30m1x4=%ymm4,<out21=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS18 = out21
# asm 1: vmovapd <out21=reg256#4,>stack_FVGS18=stack256#19
# asm 2: vmovapd <out21=%ymm3,>stack_FVGS18=704(%rsp)
vmovapd %ymm3,704(%rsp)

# qhasm: FVGS22 = stack_FVGS22
# asm 1: vmovapd <stack_FVGS22=stack256#24,>FVGS22=reg256#4
# asm 2: vmovapd <stack_FVGS22=864(%rsp),>FVGS22=%ymm3
vmovapd 864(%rsp),%ymm3

# qhasm: GSFV22 = FVGS22[1,0]
# asm 1: vpermq $0x4e,<FVGS22=reg256#4,>GSFV22=reg256#5
# asm 2: vpermq $0x4e,<FVGS22=%ymm3,>GSFV22=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS21
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS21=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS21=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out22 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out22=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out22=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV21
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV21=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV21=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out22 += tb
# asm 1: vpaddq <out22=reg256#9,<tb=reg256#11,<out22=reg256#9
# asm 2: vpaddq <out22=%ymm8,<tb=%ymm10,<out22=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS22
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS22=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS22=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out22 += ta
# asm 1: vpaddq <out22=reg256#9,<ta=reg256#11,<out22=reg256#9
# asm 2: vpaddq <out22=%ymm8,<ta=%ymm10,<out22=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV22
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV22=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV22=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out22 += tb
# asm 1: vpaddq <out22=reg256#9,<tb=reg256#11,<out22=reg256#9
# asm 2: vpaddq <out22=%ymm8,<tb=%ymm10,<out22=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod22 = stack_mod22
# asm 1: vmovapd <stack_mod22=stack256#59,>mod22=reg256#11
# asm 2: vmovapd <stack_mod22=1984(%rsp),>mod22=%ymm10
vmovapd 1984(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod20
# asm 1: vpmuldq <d2=reg256#10,<mod20=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod20=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out22 += ta
# asm 1: vpaddq <out22=reg256#9,<ta=reg256#13,<out22=reg256#9
# asm 2: vpaddq <out22=%ymm8,<ta=%ymm12,<out22=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod21
# asm 1: vpmuldq <d1=reg256#2,<mod21=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod21=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out22 += tb
# asm 1: vpaddq <out22=reg256#9,<tb=reg256#13,<out22=reg256#9
# asm 2: vpaddq <out22=%ymm8,<tb=%ymm12,<out22=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod22
# asm 1: vpmuldq <d0=reg256#12,<mod22=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod22=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out22 += ta
# asm 1: vpaddq <out22=reg256#9,<ta=reg256#13,<out22=reg256#9
# asm 2: vpaddq <out22=%ymm8,<ta=%ymm12,<out22=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm12
vmovapd 2400(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out22 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out22=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out22=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out22 &= _2p30m1x4
# asm 1: vpand <out22=reg256#9,<_2p30m1x4=reg256#13,<out22=reg256#9
# asm 2: vpand <out22=%ymm8,<_2p30m1x4=%ymm12,<out22=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS19 = out22
# asm 1: vmovapd <out22=reg256#9,>stack_FVGS19=stack256#20
# asm 2: vmovapd <out22=%ymm8,>stack_FVGS19=736(%rsp)
vmovapd %ymm8,736(%rsp)

# qhasm: FVGS23 = stack_FVGS23
# asm 1: vmovapd <stack_FVGS23=stack256#25,>FVGS23=reg256#9
# asm 2: vmovapd <stack_FVGS23=896(%rsp),>FVGS23=%ymm8
vmovapd 896(%rsp),%ymm8

# qhasm: GSFV23 = FVGS23[1,0]
# asm 1: vpermq $0x4e,<FVGS23=reg256#9,>GSFV23=reg256#13
# asm 2: vpermq $0x4e,<FVGS23=%ymm8,>GSFV23=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS22
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS22=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS22=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out23 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out23=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out23=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV22
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV22=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV22=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out23 += tb
# asm 1: vpaddq <out23=reg256#4,<tb=reg256#5,<out23=reg256#4
# asm 2: vpaddq <out23=%ymm3,<tb=%ymm4,<out23=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS23
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS23=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS23=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out23 += ta
# asm 1: vpaddq <out23=reg256#4,<ta=reg256#5,<out23=reg256#4
# asm 2: vpaddq <out23=%ymm3,<ta=%ymm4,<out23=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV23
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV23=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV23=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out23 += tb
# asm 1: vpaddq <out23=reg256#4,<tb=reg256#5,<out23=reg256#4
# asm 2: vpaddq <out23=%ymm3,<tb=%ymm4,<out23=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod23 = stack_mod23
# asm 1: vmovapd <stack_mod23=stack256#60,>mod23=reg256#5
# asm 2: vmovapd <stack_mod23=2016(%rsp),>mod23=%ymm4
vmovapd 2016(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod21
# asm 1: vpmuldq <d2=reg256#10,<mod21=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod21=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out23 += ta
# asm 1: vpaddq <out23=reg256#4,<ta=reg256#8,<out23=reg256#4
# asm 2: vpaddq <out23=%ymm3,<ta=%ymm7,<out23=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod22
# asm 1: vpmuldq <d1=reg256#2,<mod22=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod22=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out23 += tb
# asm 1: vpaddq <out23=reg256#4,<tb=reg256#8,<out23=reg256#4
# asm 2: vpaddq <out23=%ymm3,<tb=%ymm7,<out23=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod23
# asm 1: vpmuldq <d0=reg256#12,<mod23=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod23=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out23 += ta
# asm 1: vpaddq <out23=reg256#4,<ta=reg256#8,<out23=reg256#4
# asm 2: vpaddq <out23=%ymm3,<ta=%ymm7,<out23=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm7
vmovapd 2400(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out23 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out23=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out23=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out23 &= _2p30m1x4
# asm 1: vpand <out23=reg256#4,<_2p30m1x4=reg256#8,<out23=reg256#4
# asm 2: vpand <out23=%ymm3,<_2p30m1x4=%ymm7,<out23=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS20 = out23
# asm 1: vmovapd <out23=reg256#4,>stack_FVGS20=stack256#21
# asm 2: vmovapd <out23=%ymm3,>stack_FVGS20=768(%rsp)
vmovapd %ymm3,768(%rsp)

# qhasm: FVGS24 = stack_FVGS24
# asm 1: vmovapd <stack_FVGS24=stack256#26,>FVGS24=reg256#4
# asm 2: vmovapd <stack_FVGS24=928(%rsp),>FVGS24=%ymm3
vmovapd 928(%rsp),%ymm3

# qhasm: GSFV24 = FVGS24[1,0]
# asm 1: vpermq $0x4e,<FVGS24=reg256#4,>GSFV24=reg256#8
# asm 2: vpermq $0x4e,<FVGS24=%ymm3,>GSFV24=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS23
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS23=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS23=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out24 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out24=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out24=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV23
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV23=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV23=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out24 += tb
# asm 1: vpaddq <out24=reg256#9,<tb=reg256#13,<out24=reg256#9
# asm 2: vpaddq <out24=%ymm8,<tb=%ymm12,<out24=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS24
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS24=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS24=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out24 += ta
# asm 1: vpaddq <out24=reg256#9,<ta=reg256#13,<out24=reg256#9
# asm 2: vpaddq <out24=%ymm8,<ta=%ymm12,<out24=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV24
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV24=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV24=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out24 += tb
# asm 1: vpaddq <out24=reg256#9,<tb=reg256#13,<out24=reg256#9
# asm 2: vpaddq <out24=%ymm8,<tb=%ymm12,<out24=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod24 = stack_mod24
# asm 1: vmovapd <stack_mod24=stack256#61,>mod24=reg256#13
# asm 2: vmovapd <stack_mod24=2048(%rsp),>mod24=%ymm12
vmovapd 2048(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod22
# asm 1: vpmuldq <d2=reg256#10,<mod22=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod22=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out24 += ta
# asm 1: vpaddq <out24=reg256#9,<ta=reg256#11,<out24=reg256#9
# asm 2: vpaddq <out24=%ymm8,<ta=%ymm10,<out24=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod23
# asm 1: vpmuldq <d1=reg256#2,<mod23=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod23=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out24 += tb
# asm 1: vpaddq <out24=reg256#9,<tb=reg256#11,<out24=reg256#9
# asm 2: vpaddq <out24=%ymm8,<tb=%ymm10,<out24=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod24
# asm 1: vpmuldq <d0=reg256#12,<mod24=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod24=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out24 += ta
# asm 1: vpaddq <out24=reg256#9,<ta=reg256#11,<out24=reg256#9
# asm 2: vpaddq <out24=%ymm8,<ta=%ymm10,<out24=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm10
vmovapd 2400(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out24 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out24=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out24=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out24 &= _2p30m1x4
# asm 1: vpand <out24=reg256#9,<_2p30m1x4=reg256#11,<out24=reg256#9
# asm 2: vpand <out24=%ymm8,<_2p30m1x4=%ymm10,<out24=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS21 = out24
# asm 1: vmovapd <out24=reg256#9,>stack_FVGS21=stack256#22
# asm 2: vmovapd <out24=%ymm8,>stack_FVGS21=800(%rsp)
vmovapd %ymm8,800(%rsp)

# qhasm: FVGS25 = stack_FVGS25
# asm 1: vmovapd <stack_FVGS25=stack256#27,>FVGS25=reg256#9
# asm 2: vmovapd <stack_FVGS25=960(%rsp),>FVGS25=%ymm8
vmovapd 960(%rsp),%ymm8

# qhasm: GSFV25 = FVGS25[1,0]
# asm 1: vpermq $0x4e,<FVGS25=reg256#9,>GSFV25=reg256#11
# asm 2: vpermq $0x4e,<FVGS25=%ymm8,>GSFV25=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS24
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS24=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS24=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out25 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out25=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out25=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV24
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV24=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV24=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out25 += tb
# asm 1: vpaddq <out25=reg256#4,<tb=reg256#8,<out25=reg256#4
# asm 2: vpaddq <out25=%ymm3,<tb=%ymm7,<out25=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS25
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS25=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS25=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out25 += ta
# asm 1: vpaddq <out25=reg256#4,<ta=reg256#8,<out25=reg256#4
# asm 2: vpaddq <out25=%ymm3,<ta=%ymm7,<out25=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV25
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV25=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV25=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out25 += tb
# asm 1: vpaddq <out25=reg256#4,<tb=reg256#8,<out25=reg256#4
# asm 2: vpaddq <out25=%ymm3,<tb=%ymm7,<out25=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod25 = stack_mod25
# asm 1: vmovapd <stack_mod25=stack256#62,>mod25=reg256#8
# asm 2: vmovapd <stack_mod25=2080(%rsp),>mod25=%ymm7
vmovapd 2080(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod23
# asm 1: vpmuldq <d2=reg256#10,<mod23=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod23=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out25 += ta
# asm 1: vpaddq <out25=reg256#4,<ta=reg256#5,<out25=reg256#4
# asm 2: vpaddq <out25=%ymm3,<ta=%ymm4,<out25=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod24
# asm 1: vpmuldq <d1=reg256#2,<mod24=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod24=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out25 += tb
# asm 1: vpaddq <out25=reg256#4,<tb=reg256#5,<out25=reg256#4
# asm 2: vpaddq <out25=%ymm3,<tb=%ymm4,<out25=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod25
# asm 1: vpmuldq <d0=reg256#12,<mod25=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod25=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out25 += ta
# asm 1: vpaddq <out25=reg256#4,<ta=reg256#5,<out25=reg256#4
# asm 2: vpaddq <out25=%ymm3,<ta=%ymm4,<out25=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out25 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out25=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out25=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out25 &= _2p30m1x4
# asm 1: vpand <out25=reg256#4,<_2p30m1x4=reg256#5,<out25=reg256#4
# asm 2: vpand <out25=%ymm3,<_2p30m1x4=%ymm4,<out25=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS22 = out25
# asm 1: vmovapd <out25=reg256#4,>stack_FVGS22=stack256#23
# asm 2: vmovapd <out25=%ymm3,>stack_FVGS22=832(%rsp)
vmovapd %ymm3,832(%rsp)

# qhasm: FVGS26 = stack_FVGS26
# asm 1: vmovapd <stack_FVGS26=stack256#28,>FVGS26=reg256#4
# asm 2: vmovapd <stack_FVGS26=992(%rsp),>FVGS26=%ymm3
vmovapd 992(%rsp),%ymm3

# qhasm: GSFV26 = FVGS26[1,0]
# asm 1: vpermq $0x4e,<FVGS26=reg256#4,>GSFV26=reg256#5
# asm 2: vpermq $0x4e,<FVGS26=%ymm3,>GSFV26=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS25
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS25=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS25=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out26 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out26=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out26=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV25
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV25=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV25=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out26 += tb
# asm 1: vpaddq <out26=reg256#9,<tb=reg256#11,<out26=reg256#9
# asm 2: vpaddq <out26=%ymm8,<tb=%ymm10,<out26=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS26
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS26=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS26=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out26 += ta
# asm 1: vpaddq <out26=reg256#9,<ta=reg256#11,<out26=reg256#9
# asm 2: vpaddq <out26=%ymm8,<ta=%ymm10,<out26=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV26
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV26=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV26=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out26 += tb
# asm 1: vpaddq <out26=reg256#9,<tb=reg256#11,<out26=reg256#9
# asm 2: vpaddq <out26=%ymm8,<tb=%ymm10,<out26=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod26 = stack_mod26
# asm 1: vmovapd <stack_mod26=stack256#63,>mod26=reg256#11
# asm 2: vmovapd <stack_mod26=2112(%rsp),>mod26=%ymm10
vmovapd 2112(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod24
# asm 1: vpmuldq <d2=reg256#10,<mod24=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod24=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out26 += ta
# asm 1: vpaddq <out26=reg256#9,<ta=reg256#13,<out26=reg256#9
# asm 2: vpaddq <out26=%ymm8,<ta=%ymm12,<out26=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod25
# asm 1: vpmuldq <d1=reg256#2,<mod25=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod25=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out26 += tb
# asm 1: vpaddq <out26=reg256#9,<tb=reg256#13,<out26=reg256#9
# asm 2: vpaddq <out26=%ymm8,<tb=%ymm12,<out26=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod26
# asm 1: vpmuldq <d0=reg256#12,<mod26=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod26=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out26 += ta
# asm 1: vpaddq <out26=reg256#9,<ta=reg256#13,<out26=reg256#9
# asm 2: vpaddq <out26=%ymm8,<ta=%ymm12,<out26=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm12
vmovapd 2400(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out26 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out26=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out26=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out26 &= _2p30m1x4
# asm 1: vpand <out26=reg256#9,<_2p30m1x4=reg256#13,<out26=reg256#9
# asm 2: vpand <out26=%ymm8,<_2p30m1x4=%ymm12,<out26=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS23 = out26
# asm 1: vmovapd <out26=reg256#9,>stack_FVGS23=stack256#24
# asm 2: vmovapd <out26=%ymm8,>stack_FVGS23=864(%rsp)
vmovapd %ymm8,864(%rsp)

# qhasm: FVGS27 = stack_FVGS27
# asm 1: vmovapd <stack_FVGS27=stack256#29,>FVGS27=reg256#9
# asm 2: vmovapd <stack_FVGS27=1024(%rsp),>FVGS27=%ymm8
vmovapd 1024(%rsp),%ymm8

# qhasm: GSFV27 = FVGS27[1,0]
# asm 1: vpermq $0x4e,<FVGS27=reg256#9,>GSFV27=reg256#13
# asm 2: vpermq $0x4e,<FVGS27=%ymm8,>GSFV27=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS26
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS26=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS26=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out27 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out27=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out27=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV26
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV26=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV26=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out27 += tb
# asm 1: vpaddq <out27=reg256#4,<tb=reg256#5,<out27=reg256#4
# asm 2: vpaddq <out27=%ymm3,<tb=%ymm4,<out27=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS27
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS27=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS27=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out27 += ta
# asm 1: vpaddq <out27=reg256#4,<ta=reg256#5,<out27=reg256#4
# asm 2: vpaddq <out27=%ymm3,<ta=%ymm4,<out27=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV27
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV27=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV27=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out27 += tb
# asm 1: vpaddq <out27=reg256#4,<tb=reg256#5,<out27=reg256#4
# asm 2: vpaddq <out27=%ymm3,<tb=%ymm4,<out27=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod27 = stack_mod27
# asm 1: vmovapd <stack_mod27=stack256#64,>mod27=reg256#5
# asm 2: vmovapd <stack_mod27=2144(%rsp),>mod27=%ymm4
vmovapd 2144(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod25
# asm 1: vpmuldq <d2=reg256#10,<mod25=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod25=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out27 += ta
# asm 1: vpaddq <out27=reg256#4,<ta=reg256#8,<out27=reg256#4
# asm 2: vpaddq <out27=%ymm3,<ta=%ymm7,<out27=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod26
# asm 1: vpmuldq <d1=reg256#2,<mod26=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod26=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out27 += tb
# asm 1: vpaddq <out27=reg256#4,<tb=reg256#8,<out27=reg256#4
# asm 2: vpaddq <out27=%ymm3,<tb=%ymm7,<out27=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod27
# asm 1: vpmuldq <d0=reg256#12,<mod27=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod27=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out27 += ta
# asm 1: vpaddq <out27=reg256#4,<ta=reg256#8,<out27=reg256#4
# asm 2: vpaddq <out27=%ymm3,<ta=%ymm7,<out27=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm7
vmovapd 2400(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out27 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out27=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out27=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out27 &= _2p30m1x4
# asm 1: vpand <out27=reg256#4,<_2p30m1x4=reg256#8,<out27=reg256#4
# asm 2: vpand <out27=%ymm3,<_2p30m1x4=%ymm7,<out27=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS24 = out27
# asm 1: vmovapd <out27=reg256#4,>stack_FVGS24=stack256#25
# asm 2: vmovapd <out27=%ymm3,>stack_FVGS24=896(%rsp)
vmovapd %ymm3,896(%rsp)

# qhasm: FVGS28 = stack_FVGS28
# asm 1: vmovapd <stack_FVGS28=stack256#30,>FVGS28=reg256#4
# asm 2: vmovapd <stack_FVGS28=1056(%rsp),>FVGS28=%ymm3
vmovapd 1056(%rsp),%ymm3

# qhasm: GSFV28 = FVGS28[1,0]
# asm 1: vpermq $0x4e,<FVGS28=reg256#4,>GSFV28=reg256#8
# asm 2: vpermq $0x4e,<FVGS28=%ymm3,>GSFV28=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS27
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS27=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS27=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out28 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out28=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out28=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV27
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV27=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV27=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out28 += tb
# asm 1: vpaddq <out28=reg256#9,<tb=reg256#13,<out28=reg256#9
# asm 2: vpaddq <out28=%ymm8,<tb=%ymm12,<out28=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS28
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS28=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS28=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out28 += ta
# asm 1: vpaddq <out28=reg256#9,<ta=reg256#13,<out28=reg256#9
# asm 2: vpaddq <out28=%ymm8,<ta=%ymm12,<out28=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV28
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV28=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV28=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out28 += tb
# asm 1: vpaddq <out28=reg256#9,<tb=reg256#13,<out28=reg256#9
# asm 2: vpaddq <out28=%ymm8,<tb=%ymm12,<out28=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod28 = stack_mod28
# asm 1: vmovapd <stack_mod28=stack256#65,>mod28=reg256#13
# asm 2: vmovapd <stack_mod28=2176(%rsp),>mod28=%ymm12
vmovapd 2176(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod26
# asm 1: vpmuldq <d2=reg256#10,<mod26=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod26=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out28 += ta
# asm 1: vpaddq <out28=reg256#9,<ta=reg256#11,<out28=reg256#9
# asm 2: vpaddq <out28=%ymm8,<ta=%ymm10,<out28=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod27
# asm 1: vpmuldq <d1=reg256#2,<mod27=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod27=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out28 += tb
# asm 1: vpaddq <out28=reg256#9,<tb=reg256#11,<out28=reg256#9
# asm 2: vpaddq <out28=%ymm8,<tb=%ymm10,<out28=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod28
# asm 1: vpmuldq <d0=reg256#12,<mod28=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod28=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out28 += ta
# asm 1: vpaddq <out28=reg256#9,<ta=reg256#11,<out28=reg256#9
# asm 2: vpaddq <out28=%ymm8,<ta=%ymm10,<out28=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm10
vmovapd 2400(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out28 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out28=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out28=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out28 &= _2p30m1x4
# asm 1: vpand <out28=reg256#9,<_2p30m1x4=reg256#11,<out28=reg256#9
# asm 2: vpand <out28=%ymm8,<_2p30m1x4=%ymm10,<out28=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS25 = out28
# asm 1: vmovapd <out28=reg256#9,>stack_FVGS25=stack256#26
# asm 2: vmovapd <out28=%ymm8,>stack_FVGS25=928(%rsp)
vmovapd %ymm8,928(%rsp)

# qhasm: FVGS29 = stack_FVGS29
# asm 1: vmovapd <stack_FVGS29=stack256#31,>FVGS29=reg256#9
# asm 2: vmovapd <stack_FVGS29=1088(%rsp),>FVGS29=%ymm8
vmovapd 1088(%rsp),%ymm8

# qhasm: GSFV29 = FVGS29[1,0]
# asm 1: vpermq $0x4e,<FVGS29=reg256#9,>GSFV29=reg256#11
# asm 2: vpermq $0x4e,<FVGS29=%ymm8,>GSFV29=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS28
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS28=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS28=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out29 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out29=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out29=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV28
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV28=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV28=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out29 += tb
# asm 1: vpaddq <out29=reg256#4,<tb=reg256#8,<out29=reg256#4
# asm 2: vpaddq <out29=%ymm3,<tb=%ymm7,<out29=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS29
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS29=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS29=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out29 += ta
# asm 1: vpaddq <out29=reg256#4,<ta=reg256#8,<out29=reg256#4
# asm 2: vpaddq <out29=%ymm3,<ta=%ymm7,<out29=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV29
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV29=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV29=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out29 += tb
# asm 1: vpaddq <out29=reg256#4,<tb=reg256#8,<out29=reg256#4
# asm 2: vpaddq <out29=%ymm3,<tb=%ymm7,<out29=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod29 = stack_mod29
# asm 1: vmovapd <stack_mod29=stack256#66,>mod29=reg256#8
# asm 2: vmovapd <stack_mod29=2208(%rsp),>mod29=%ymm7
vmovapd 2208(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod27
# asm 1: vpmuldq <d2=reg256#10,<mod27=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod27=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out29 += ta
# asm 1: vpaddq <out29=reg256#4,<ta=reg256#5,<out29=reg256#4
# asm 2: vpaddq <out29=%ymm3,<ta=%ymm4,<out29=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod28
# asm 1: vpmuldq <d1=reg256#2,<mod28=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod28=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out29 += tb
# asm 1: vpaddq <out29=reg256#4,<tb=reg256#5,<out29=reg256#4
# asm 2: vpaddq <out29=%ymm3,<tb=%ymm4,<out29=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod29
# asm 1: vpmuldq <d0=reg256#12,<mod29=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod29=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out29 += ta
# asm 1: vpaddq <out29=reg256#4,<ta=reg256#5,<out29=reg256#4
# asm 2: vpaddq <out29=%ymm3,<ta=%ymm4,<out29=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out29 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out29=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out29=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out29 &= _2p30m1x4
# asm 1: vpand <out29=reg256#4,<_2p30m1x4=reg256#5,<out29=reg256#4
# asm 2: vpand <out29=%ymm3,<_2p30m1x4=%ymm4,<out29=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS26 = out29
# asm 1: vmovapd <out29=reg256#4,>stack_FVGS26=stack256#27
# asm 2: vmovapd <out29=%ymm3,>stack_FVGS26=960(%rsp)
vmovapd %ymm3,960(%rsp)

# qhasm: FVGS30 = stack_FVGS30
# asm 1: vmovapd <stack_FVGS30=stack256#32,>FVGS30=reg256#4
# asm 2: vmovapd <stack_FVGS30=1120(%rsp),>FVGS30=%ymm3
vmovapd 1120(%rsp),%ymm3

# qhasm: GSFV30 = FVGS30[1,0]
# asm 1: vpermq $0x4e,<FVGS30=reg256#4,>GSFV30=reg256#5
# asm 2: vpermq $0x4e,<FVGS30=%ymm3,>GSFV30=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS29
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS29=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS29=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out30 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out30=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out30=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV29
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV29=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV29=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out30 += tb
# asm 1: vpaddq <out30=reg256#9,<tb=reg256#11,<out30=reg256#9
# asm 2: vpaddq <out30=%ymm8,<tb=%ymm10,<out30=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS30
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS30=reg256#4,>ta=reg256#11
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS30=%ymm3,>ta=%ymm10
vpmuldq %ymm5,%ymm3,%ymm10

# qhasm: 4x out30 += ta
# asm 1: vpaddq <out30=reg256#9,<ta=reg256#11,<out30=reg256#9
# asm 2: vpaddq <out30=%ymm8,<ta=%ymm10,<out30=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV30
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV30=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV30=%ymm4,>tb=%ymm10
vpmuldq %ymm6,%ymm4,%ymm10

# qhasm: 4x out30 += tb
# asm 1: vpaddq <out30=reg256#9,<tb=reg256#11,<out30=reg256#9
# asm 2: vpaddq <out30=%ymm8,<tb=%ymm10,<out30=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: mod30 = stack_mod30
# asm 1: vmovapd <stack_mod30=stack256#67,>mod30=reg256#11
# asm 2: vmovapd <stack_mod30=2240(%rsp),>mod30=%ymm10
vmovapd 2240(%rsp),%ymm10

# qhasm: 4x ta = int32 d2 * int32 mod28
# asm 1: vpmuldq <d2=reg256#10,<mod28=reg256#13,>ta=reg256#13
# asm 2: vpmuldq <d2=%ymm9,<mod28=%ymm12,>ta=%ymm12
vpmuldq %ymm9,%ymm12,%ymm12

# qhasm: 4x out30 += ta
# asm 1: vpaddq <out30=reg256#9,<ta=reg256#13,<out30=reg256#9
# asm 2: vpaddq <out30=%ymm8,<ta=%ymm12,<out30=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod29
# asm 1: vpmuldq <d1=reg256#2,<mod29=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <d1=%ymm1,<mod29=%ymm7,>tb=%ymm12
vpmuldq %ymm1,%ymm7,%ymm12

# qhasm: 4x out30 += tb
# asm 1: vpaddq <out30=reg256#9,<tb=reg256#13,<out30=reg256#9
# asm 2: vpaddq <out30=%ymm8,<tb=%ymm12,<out30=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod30
# asm 1: vpmuldq <d0=reg256#12,<mod30=reg256#11,>ta=reg256#13
# asm 2: vpmuldq <d0=%ymm11,<mod30=%ymm10,>ta=%ymm12
vpmuldq %ymm11,%ymm10,%ymm12

# qhasm: 4x out30 += ta
# asm 1: vpaddq <out30=reg256#9,<ta=reg256#13,<out30=reg256#9
# asm 2: vpaddq <out30=%ymm8,<ta=%ymm12,<out30=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#13
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm12
vmovapd 2400(%rsp),%ymm12

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out30 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out30=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out30=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out30 &= _2p30m1x4
# asm 1: vpand <out30=reg256#9,<_2p30m1x4=reg256#13,<out30=reg256#9
# asm 2: vpand <out30=%ymm8,<_2p30m1x4=%ymm12,<out30=%ymm8
vpand %ymm8,%ymm12,%ymm8

# qhasm: stack_FVGS27 = out30
# asm 1: vmovapd <out30=reg256#9,>stack_FVGS27=stack256#28
# asm 2: vmovapd <out30=%ymm8,>stack_FVGS27=992(%rsp)
vmovapd %ymm8,992(%rsp)

# qhasm: FVGS31 = stack_FVGS31
# asm 1: vmovapd <stack_FVGS31=stack256#33,>FVGS31=reg256#9
# asm 2: vmovapd <stack_FVGS31=1152(%rsp),>FVGS31=%ymm8
vmovapd 1152(%rsp),%ymm8

# qhasm: GSFV31 = FVGS31[1,0]
# asm 1: vpermq $0x4e,<FVGS31=reg256#9,>GSFV31=reg256#13
# asm 2: vpermq $0x4e,<FVGS31=%ymm8,>GSFV31=%ymm12
vpermq $0x4e,%ymm8,%ymm12

# qhasm: 4x ta = int32 uuss1 * int32 FVGS30
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS30=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS30=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out31 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out31=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out31=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV30
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV30=reg256#5,>tb=reg256#5
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV30=%ymm4,>tb=%ymm4
vpmuldq %ymm0,%ymm4,%ymm4

# qhasm: 4x out31 += tb
# asm 1: vpaddq <out31=reg256#4,<tb=reg256#5,<out31=reg256#4
# asm 2: vpaddq <out31=%ymm3,<tb=%ymm4,<out31=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS31
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS31=reg256#9,>ta=reg256#5
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS31=%ymm8,>ta=%ymm4
vpmuldq %ymm5,%ymm8,%ymm4

# qhasm: 4x out31 += ta
# asm 1: vpaddq <out31=reg256#4,<ta=reg256#5,<out31=reg256#4
# asm 2: vpaddq <out31=%ymm3,<ta=%ymm4,<out31=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV31
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV31=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV31=%ymm12,>tb=%ymm4
vpmuldq %ymm6,%ymm12,%ymm4

# qhasm: 4x out31 += tb
# asm 1: vpaddq <out31=reg256#4,<tb=reg256#5,<out31=reg256#4
# asm 2: vpaddq <out31=%ymm3,<tb=%ymm4,<out31=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: mod31 = stack_mod31
# asm 1: vmovapd <stack_mod31=stack256#68,>mod31=reg256#5
# asm 2: vmovapd <stack_mod31=2272(%rsp),>mod31=%ymm4
vmovapd 2272(%rsp),%ymm4

# qhasm: 4x ta = int32 d2 * int32 mod29
# asm 1: vpmuldq <d2=reg256#10,<mod29=reg256#8,>ta=reg256#8
# asm 2: vpmuldq <d2=%ymm9,<mod29=%ymm7,>ta=%ymm7
vpmuldq %ymm9,%ymm7,%ymm7

# qhasm: 4x out31 += ta
# asm 1: vpaddq <out31=reg256#4,<ta=reg256#8,<out31=reg256#4
# asm 2: vpaddq <out31=%ymm3,<ta=%ymm7,<out31=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod30
# asm 1: vpmuldq <d1=reg256#2,<mod30=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <d1=%ymm1,<mod30=%ymm10,>tb=%ymm7
vpmuldq %ymm1,%ymm10,%ymm7

# qhasm: 4x out31 += tb
# asm 1: vpaddq <out31=reg256#4,<tb=reg256#8,<out31=reg256#4
# asm 2: vpaddq <out31=%ymm3,<tb=%ymm7,<out31=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod31
# asm 1: vpmuldq <d0=reg256#12,<mod31=reg256#5,>ta=reg256#8
# asm 2: vpmuldq <d0=%ymm11,<mod31=%ymm4,>ta=%ymm7
vpmuldq %ymm11,%ymm4,%ymm7

# qhasm: 4x out31 += ta
# asm 1: vpaddq <out31=reg256#4,<ta=reg256#8,<out31=reg256#4
# asm 2: vpaddq <out31=%ymm3,<ta=%ymm7,<out31=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#8
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm7
vmovapd 2400(%rsp),%ymm7

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out31 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out31=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out31=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out31 &= _2p30m1x4
# asm 1: vpand <out31=reg256#4,<_2p30m1x4=reg256#8,<out31=reg256#4
# asm 2: vpand <out31=%ymm3,<_2p30m1x4=%ymm7,<out31=%ymm3
vpand %ymm3,%ymm7,%ymm3

# qhasm: stack_FVGS28 = out31
# asm 1: vmovapd <out31=reg256#4,>stack_FVGS28=stack256#29
# asm 2: vmovapd <out31=%ymm3,>stack_FVGS28=1024(%rsp)
vmovapd %ymm3,1024(%rsp)

# qhasm: FVGS32 = stack_FVGS32
# asm 1: vmovapd <stack_FVGS32=stack256#34,>FVGS32=reg256#4
# asm 2: vmovapd <stack_FVGS32=1184(%rsp),>FVGS32=%ymm3
vmovapd 1184(%rsp),%ymm3

# qhasm: GSFV32 = FVGS32[1,0]
# asm 1: vpermq $0x4e,<FVGS32=reg256#4,>GSFV32=reg256#8
# asm 2: vpermq $0x4e,<FVGS32=%ymm3,>GSFV32=%ymm7
vpermq $0x4e,%ymm3,%ymm7

# qhasm: 4x ta = int32 uuss1 * int32 FVGS31
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS31=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS31=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out32 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out32=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out32=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV31
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV31=reg256#13,>tb=reg256#13
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV31=%ymm12,>tb=%ymm12
vpmuldq %ymm0,%ymm12,%ymm12

# qhasm: 4x out32 += tb
# asm 1: vpaddq <out32=reg256#9,<tb=reg256#13,<out32=reg256#9
# asm 2: vpaddq <out32=%ymm8,<tb=%ymm12,<out32=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS32
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS32=reg256#4,>ta=reg256#13
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS32=%ymm3,>ta=%ymm12
vpmuldq %ymm5,%ymm3,%ymm12

# qhasm: 4x out32 += ta
# asm 1: vpaddq <out32=reg256#9,<ta=reg256#13,<out32=reg256#9
# asm 2: vpaddq <out32=%ymm8,<ta=%ymm12,<out32=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV32
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV32=reg256#8,>tb=reg256#13
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV32=%ymm7,>tb=%ymm12
vpmuldq %ymm6,%ymm7,%ymm12

# qhasm: 4x out32 += tb
# asm 1: vpaddq <out32=reg256#9,<tb=reg256#13,<out32=reg256#9
# asm 2: vpaddq <out32=%ymm8,<tb=%ymm12,<out32=%ymm8
vpaddq %ymm8,%ymm12,%ymm8

# qhasm: mod32 = stack_mod32
# asm 1: vmovapd <stack_mod32=stack256#69,>mod32=reg256#13
# asm 2: vmovapd <stack_mod32=2304(%rsp),>mod32=%ymm12
vmovapd 2304(%rsp),%ymm12

# qhasm: 4x ta = int32 d2 * int32 mod30
# asm 1: vpmuldq <d2=reg256#10,<mod30=reg256#11,>ta=reg256#11
# asm 2: vpmuldq <d2=%ymm9,<mod30=%ymm10,>ta=%ymm10
vpmuldq %ymm9,%ymm10,%ymm10

# qhasm: 4x out32 += ta
# asm 1: vpaddq <out32=reg256#9,<ta=reg256#11,<out32=reg256#9
# asm 2: vpaddq <out32=%ymm8,<ta=%ymm10,<out32=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod31
# asm 1: vpmuldq <d1=reg256#2,<mod31=reg256#5,>tb=reg256#11
# asm 2: vpmuldq <d1=%ymm1,<mod31=%ymm4,>tb=%ymm10
vpmuldq %ymm1,%ymm4,%ymm10

# qhasm: 4x out32 += tb
# asm 1: vpaddq <out32=reg256#9,<tb=reg256#11,<out32=reg256#9
# asm 2: vpaddq <out32=%ymm8,<tb=%ymm10,<out32=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod32
# asm 1: vpmuldq <d0=reg256#12,<mod32=reg256#13,>ta=reg256#11
# asm 2: vpmuldq <d0=%ymm11,<mod32=%ymm12,>ta=%ymm10
vpmuldq %ymm11,%ymm12,%ymm10

# qhasm: 4x out32 += ta
# asm 1: vpaddq <out32=reg256#9,<ta=reg256#11,<out32=reg256#9
# asm 2: vpaddq <out32=%ymm8,<ta=%ymm10,<out32=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#11
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm10
vmovapd 2400(%rsp),%ymm10

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out32 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out32=reg256#9,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out32=%ymm8,>carryy=%ymm13
vpaddq %ymm13,%ymm8,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out32 &= _2p30m1x4
# asm 1: vpand <out32=reg256#9,<_2p30m1x4=reg256#11,<out32=reg256#9
# asm 2: vpand <out32=%ymm8,<_2p30m1x4=%ymm10,<out32=%ymm8
vpand %ymm8,%ymm10,%ymm8

# qhasm: stack_FVGS29 = out32
# asm 1: vmovapd <out32=reg256#9,>stack_FVGS29=stack256#30
# asm 2: vmovapd <out32=%ymm8,>stack_FVGS29=1056(%rsp)
vmovapd %ymm8,1056(%rsp)

# qhasm: FVGS33 = stack_FVGS33
# asm 1: vmovapd <stack_FVGS33=stack256#35,>FVGS33=reg256#9
# asm 2: vmovapd <stack_FVGS33=1216(%rsp),>FVGS33=%ymm8
vmovapd 1216(%rsp),%ymm8

# qhasm: GSFV33 = FVGS33[1,0]
# asm 1: vpermq $0x4e,<FVGS33=reg256#9,>GSFV33=reg256#11
# asm 2: vpermq $0x4e,<FVGS33=%ymm8,>GSFV33=%ymm10
vpermq $0x4e,%ymm8,%ymm10

# qhasm: 4x ta = int32 uuss1 * int32 FVGS32
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS32=reg256#4,>ta=reg256#4
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS32=%ymm3,>ta=%ymm3
vpmuldq %ymm2,%ymm3,%ymm3

# qhasm: 4x out33 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#4,>out33=reg256#4
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm3,>out33=%ymm3
vpaddq %ymm13,%ymm3,%ymm3

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV32
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV32=reg256#8,>tb=reg256#8
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV32=%ymm7,>tb=%ymm7
vpmuldq %ymm0,%ymm7,%ymm7

# qhasm: 4x out33 += tb
# asm 1: vpaddq <out33=reg256#4,<tb=reg256#8,<out33=reg256#4
# asm 2: vpaddq <out33=%ymm3,<tb=%ymm7,<out33=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x ta = int32 uuss0 * int32 FVGS33
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS33=reg256#9,>ta=reg256#8
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS33=%ymm8,>ta=%ymm7
vpmuldq %ymm5,%ymm8,%ymm7

# qhasm: 4x out33 += ta
# asm 1: vpaddq <out33=reg256#4,<ta=reg256#8,<out33=reg256#4
# asm 2: vpaddq <out33=%ymm3,<ta=%ymm7,<out33=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV33
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV33=reg256#11,>tb=reg256#8
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV33=%ymm10,>tb=%ymm7
vpmuldq %ymm6,%ymm10,%ymm7

# qhasm: 4x out33 += tb
# asm 1: vpaddq <out33=reg256#4,<tb=reg256#8,<out33=reg256#4
# asm 2: vpaddq <out33=%ymm3,<tb=%ymm7,<out33=%ymm3
vpaddq %ymm3,%ymm7,%ymm3

# qhasm: mod33 = stack_mod33
# asm 1: vmovapd <stack_mod33=stack256#70,>mod33=reg256#8
# asm 2: vmovapd <stack_mod33=2336(%rsp),>mod33=%ymm7
vmovapd 2336(%rsp),%ymm7

# qhasm: 4x ta = int32 d2 * int32 mod31
# asm 1: vpmuldq <d2=reg256#10,<mod31=reg256#5,>ta=reg256#5
# asm 2: vpmuldq <d2=%ymm9,<mod31=%ymm4,>ta=%ymm4
vpmuldq %ymm9,%ymm4,%ymm4

# qhasm: 4x out33 += ta
# asm 1: vpaddq <out33=reg256#4,<ta=reg256#5,<out33=reg256#4
# asm 2: vpaddq <out33=%ymm3,<ta=%ymm4,<out33=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x tb = int32 d1 * int32 mod32
# asm 1: vpmuldq <d1=reg256#2,<mod32=reg256#13,>tb=reg256#5
# asm 2: vpmuldq <d1=%ymm1,<mod32=%ymm12,>tb=%ymm4
vpmuldq %ymm1,%ymm12,%ymm4

# qhasm: 4x out33 += tb
# asm 1: vpaddq <out33=reg256#4,<tb=reg256#5,<out33=reg256#4
# asm 2: vpaddq <out33=%ymm3,<tb=%ymm4,<out33=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: 4x ta = int32 d0 * int32 mod33
# asm 1: vpmuldq <d0=reg256#12,<mod33=reg256#8,>ta=reg256#5
# asm 2: vpmuldq <d0=%ymm11,<mod33=%ymm7,>ta=%ymm4
vpmuldq %ymm11,%ymm7,%ymm4

# qhasm: 4x out33 += ta
# asm 1: vpaddq <out33=reg256#4,<ta=reg256#5,<out33=reg256#4
# asm 2: vpaddq <out33=%ymm3,<ta=%ymm4,<out33=%ymm3
vpaddq %ymm3,%ymm4,%ymm3

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#5
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm4
vmovapd 2400(%rsp),%ymm4

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#14
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm13
vmovapd 2496(%rsp),%ymm13

# qhasm: 4x carryy = out33 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#14,<out33=reg256#4,>carryy=reg256#14
# asm 2: vpaddq <_2p63m2p33x4=%ymm13,<out33=%ymm3,>carryy=%ymm13
vpaddq %ymm13,%ymm3,%ymm13

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#14,<carryy=reg256#14
# asm 2: vpsrlq $30,<carryy=%ymm13,<carryy=%ymm13
vpsrlq $30,%ymm13,%ymm13

# qhasm: out33 &= _2p30m1x4
# asm 1: vpand <out33=reg256#4,<_2p30m1x4=reg256#5,<out33=reg256#4
# asm 2: vpand <out33=%ymm3,<_2p30m1x4=%ymm4,<out33=%ymm3
vpand %ymm3,%ymm4,%ymm3

# qhasm: stack_FVGS30 = out33
# asm 1: vmovapd <out33=reg256#4,>stack_FVGS30=stack256#31
# asm 2: vmovapd <out33=%ymm3,>stack_FVGS30=1088(%rsp)
vmovapd %ymm3,1088(%rsp)

# qhasm: FVGS34 = stack_FVGS34
# asm 1: vmovapd <stack_FVGS34=stack256#36,>FVGS34=reg256#4
# asm 2: vmovapd <stack_FVGS34=1248(%rsp),>FVGS34=%ymm3
vmovapd 1248(%rsp),%ymm3

# qhasm: GSFV34 = FVGS34[1,0]
# asm 1: vpermq $0x4e,<FVGS34=reg256#4,>GSFV34=reg256#5
# asm 2: vpermq $0x4e,<FVGS34=%ymm3,>GSFV34=%ymm4
vpermq $0x4e,%ymm3,%ymm4

# qhasm: 4x ta = int32 uuss1 * int32 FVGS33
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS33=reg256#9,>ta=reg256#9
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS33=%ymm8,>ta=%ymm8
vpmuldq %ymm2,%ymm8,%ymm8

# qhasm: 4x out34 = ta + carryy
# asm 1: vpaddq <carryy=reg256#14,<ta=reg256#9,>out34=reg256#9
# asm 2: vpaddq <carryy=%ymm13,<ta=%ymm8,>out34=%ymm8
vpaddq %ymm13,%ymm8,%ymm8

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV33
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV33=reg256#11,>tb=reg256#11
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV33=%ymm10,>tb=%ymm10
vpmuldq %ymm0,%ymm10,%ymm10

# qhasm: 4x out34 += tb
# asm 1: vpaddq <out34=reg256#9,<tb=reg256#11,<out34=reg256#9
# asm 2: vpaddq <out34=%ymm8,<tb=%ymm10,<out34=%ymm8
vpaddq %ymm8,%ymm10,%ymm8

# qhasm: 4x ta = int32 uuss0 * int32 FVGS34
# asm 1: vpmuldq <uuss0=reg256#6,<FVGS34=reg256#4,>ta=reg256#6
# asm 2: vpmuldq <uuss0=%ymm5,<FVGS34=%ymm3,>ta=%ymm5
vpmuldq %ymm5,%ymm3,%ymm5

# qhasm: 4x out34 += ta
# asm 1: vpaddq <out34=reg256#9,<ta=reg256#6,<out34=reg256#9
# asm 2: vpaddq <out34=%ymm8,<ta=%ymm5,<out34=%ymm8
vpaddq %ymm8,%ymm5,%ymm8

# qhasm: 4x tb = int32 vvrr0 * int32 GSFV34
# asm 1: vpmuldq <vvrr0=reg256#7,<GSFV34=reg256#5,>tb=reg256#6
# asm 2: vpmuldq <vvrr0=%ymm6,<GSFV34=%ymm4,>tb=%ymm5
vpmuldq %ymm6,%ymm4,%ymm5

# qhasm: 4x out34 += tb
# asm 1: vpaddq <out34=reg256#9,<tb=reg256#6,<out34=reg256#9
# asm 2: vpaddq <out34=%ymm8,<tb=%ymm5,<out34=%ymm8
vpaddq %ymm8,%ymm5,%ymm8

# qhasm: mod34 = stack_mod34
# asm 1: vmovapd <stack_mod34=stack256#71,>mod34=reg256#6
# asm 2: vmovapd <stack_mod34=2368(%rsp),>mod34=%ymm5
vmovapd 2368(%rsp),%ymm5

# qhasm: 4x ta = int32 d2 * int32 mod32
# asm 1: vpmuldq <d2=reg256#10,<mod32=reg256#13,>ta=reg256#7
# asm 2: vpmuldq <d2=%ymm9,<mod32=%ymm12,>ta=%ymm6
vpmuldq %ymm9,%ymm12,%ymm6

# qhasm: 4x out34 += ta
# asm 1: vpaddq <out34=reg256#9,<ta=reg256#7,<out34=reg256#9
# asm 2: vpaddq <out34=%ymm8,<ta=%ymm6,<out34=%ymm8
vpaddq %ymm8,%ymm6,%ymm8

# qhasm: 4x tb = int32 d1 * int32 mod33
# asm 1: vpmuldq <d1=reg256#2,<mod33=reg256#8,>tb=reg256#7
# asm 2: vpmuldq <d1=%ymm1,<mod33=%ymm7,>tb=%ymm6
vpmuldq %ymm1,%ymm7,%ymm6

# qhasm: 4x out34 += tb
# asm 1: vpaddq <out34=reg256#9,<tb=reg256#7,<out34=reg256#9
# asm 2: vpaddq <out34=%ymm8,<tb=%ymm6,<out34=%ymm8
vpaddq %ymm8,%ymm6,%ymm8

# qhasm: 4x ta = int32 d0 * int32 mod34
# asm 1: vpmuldq <d0=reg256#12,<mod34=reg256#6,>ta=reg256#7
# asm 2: vpmuldq <d0=%ymm11,<mod34=%ymm5,>ta=%ymm6
vpmuldq %ymm11,%ymm5,%ymm6

# qhasm: 4x out34 += ta
# asm 1: vpaddq <out34=reg256#9,<ta=reg256#7,<out34=reg256#9
# asm 2: vpaddq <out34=%ymm8,<ta=%ymm6,<out34=%ymm8
vpaddq %ymm8,%ymm6,%ymm8

# qhasm: _2p30m1x4 = stack_2p30m1x4
# asm 1: vmovapd <stack_2p30m1x4=stack256#72,>_2p30m1x4=reg256#7
# asm 2: vmovapd <stack_2p30m1x4=2400(%rsp),>_2p30m1x4=%ymm6
vmovapd 2400(%rsp),%ymm6

# qhasm: _2p63m2p33x4 = stack_2p63m2p33x4
# asm 1: vmovapd <stack_2p63m2p33x4=stack256#75,>_2p63m2p33x4=reg256#11
# asm 2: vmovapd <stack_2p63m2p33x4=2496(%rsp),>_2p63m2p33x4=%ymm10
vmovapd 2496(%rsp),%ymm10

# qhasm: 4x carryy = out34 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#11,<out34=reg256#9,>carryy=reg256#12
# asm 2: vpaddq <_2p63m2p33x4=%ymm10,<out34=%ymm8,>carryy=%ymm11
vpaddq %ymm10,%ymm8,%ymm11

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#12,<carryy=reg256#12
# asm 2: vpsrlq $30,<carryy=%ymm11,<carryy=%ymm11
vpsrlq $30,%ymm11,%ymm11

# qhasm: out34 &= _2p30m1x4
# asm 1: vpand <out34=reg256#9,<_2p30m1x4=reg256#7,<out34=reg256#9
# asm 2: vpand <out34=%ymm8,<_2p30m1x4=%ymm6,<out34=%ymm8
vpand %ymm8,%ymm6,%ymm8

# qhasm: stack_FVGS31 = out34
# asm 1: vmovapd <out34=reg256#9,>stack_FVGS31=stack256#32
# asm 2: vmovapd <out34=%ymm8,>stack_FVGS31=1120(%rsp)
vmovapd %ymm8,1120(%rsp)

# qhasm: 4x ta = int32 uuss1 * int32 FVGS34
# asm 1: vpmuldq <uuss1=reg256#3,<FVGS34=reg256#4,>ta=reg256#3
# asm 2: vpmuldq <uuss1=%ymm2,<FVGS34=%ymm3,>ta=%ymm2
vpmuldq %ymm2,%ymm3,%ymm2

# qhasm: 4x tb = int32 vvrr1 * int32 GSFV34
# asm 1: vpmuldq <vvrr1=reg256#1,<GSFV34=reg256#5,>tb=reg256#1
# asm 2: vpmuldq <vvrr1=%ymm0,<GSFV34=%ymm4,>tb=%ymm0
vpmuldq %ymm0,%ymm4,%ymm0

# qhasm: 4x out35plus = ta + tb
# asm 1: vpaddq <tb=reg256#1,<ta=reg256#3,>out35plus=reg256#1
# asm 2: vpaddq <tb=%ymm0,<ta=%ymm2,>out35plus=%ymm0
vpaddq %ymm0,%ymm2,%ymm0

# qhasm: 4x ta = int32 mod34 * int32 d1
# asm 1: vpmuldq <mod34=reg256#6,<d1=reg256#2,>ta=reg256#2
# asm 2: vpmuldq <mod34=%ymm5,<d1=%ymm1,>ta=%ymm1
vpmuldq %ymm5,%ymm1,%ymm1

# qhasm: 4x tb = int32 mod33 * int32 d2
# asm 1: vpmuldq <mod33=reg256#8,<d2=reg256#10,>tb=reg256#3
# asm 2: vpmuldq <mod33=%ymm7,<d2=%ymm9,>tb=%ymm2
vpmuldq %ymm7,%ymm9,%ymm2

# qhasm: 4x tb += carryy
# asm 1: vpaddq <tb=reg256#3,<carryy=reg256#12,<tb=reg256#3
# asm 2: vpaddq <tb=%ymm2,<carryy=%ymm11,<tb=%ymm2
vpaddq %ymm2,%ymm11,%ymm2

# qhasm: 4x out35 = ta + tb
# asm 1: vpaddq <tb=reg256#3,<ta=reg256#2,>out35=reg256#2
# asm 2: vpaddq <tb=%ymm2,<ta=%ymm1,>out35=%ymm1
vpaddq %ymm2,%ymm1,%ymm1

# qhasm: 4x out35 += out35plus
# asm 1: vpaddq <out35=reg256#2,<out35plus=reg256#1,<out35=reg256#2
# asm 2: vpaddq <out35=%ymm1,<out35plus=%ymm0,<out35=%ymm1
vpaddq %ymm1,%ymm0,%ymm1

# qhasm: 4x carryy = out35 + _2p63m2p33x4 
# asm 1: vpaddq <_2p63m2p33x4=reg256#11,<out35=reg256#2,>carryy=reg256#1
# asm 2: vpaddq <_2p63m2p33x4=%ymm10,<out35=%ymm1,>carryy=%ymm0
vpaddq %ymm10,%ymm1,%ymm0

# qhasm: 4x carryy unsigned>>= 30
# asm 1: vpsrlq $30,<carryy=reg256#1,<carryy=reg256#1
# asm 2: vpsrlq $30,<carryy=%ymm0,<carryy=%ymm0
vpsrlq $30,%ymm0,%ymm0

# qhasm: out35 &= _2p30m1x4
# asm 1: vpand <out35=reg256#2,<_2p30m1x4=reg256#7,<out35=reg256#2
# asm 2: vpand <out35=%ymm1,<_2p30m1x4=%ymm6,<out35=%ymm1
vpand %ymm1,%ymm6,%ymm1

# qhasm: stack_FVGS32 = out35
# asm 1: vmovapd <out35=reg256#2,>stack_FVGS32=stack256#33
# asm 2: vmovapd <out35=%ymm1,>stack_FVGS32=1152(%rsp)
vmovapd %ymm1,1152(%rsp)

# qhasm: _2p33x4 = stack_2p33x4
# asm 1: vmovapd <stack_2p33x4=stack256#73,>_2p33x4=reg256#2
# asm 2: vmovapd <stack_2p33x4=2432(%rsp),>_2p33x4=%ymm1
vmovapd 2432(%rsp),%ymm1

# qhasm: 4x tb = int32 mod34 * int32 d2
# asm 1: vpmuldq <mod34=reg256#6,<d2=reg256#10,>tb=reg256#3
# asm 2: vpmuldq <mod34=%ymm5,<d2=%ymm9,>tb=%ymm2
vpmuldq %ymm5,%ymm9,%ymm2

# qhasm: 4x out36 = tb + carryy
# asm 1: vpaddq <carryy=reg256#1,<tb=reg256#3,>out36=reg256#1
# asm 2: vpaddq <carryy=%ymm0,<tb=%ymm2,>out36=%ymm0
vpaddq %ymm0,%ymm2,%ymm0

# qhasm: 4x out37 = out36 + _2p63m2p33x4
# asm 1: vpaddq <_2p63m2p33x4=reg256#11,<out36=reg256#1,>out37=reg256#3
# asm 2: vpaddq <_2p63m2p33x4=%ymm10,<out36=%ymm0,>out37=%ymm2
vpaddq %ymm10,%ymm0,%ymm2

# qhasm: 4x out37 unsigned >>= 30
# asm 1: vpsrlq $30,<out37=reg256#3,<out37=reg256#3
# asm 2: vpsrlq $30,<out37=%ymm2,<out37=%ymm2
vpsrlq $30,%ymm2,%ymm2

# qhasm: 4x out37 -= _2p33x4
# asm 1: vpsubq <_2p33x4=reg256#2,<out37=reg256#3,<out37=reg256#3
# asm 2: vpsubq <_2p33x4=%ymm1,<out37=%ymm2,<out37=%ymm2
vpsubq %ymm1,%ymm2,%ymm2

# qhasm: out36 &= _2p30m1x4
# asm 1: vpand <out36=reg256#1,<_2p30m1x4=reg256#7,<out36=reg256#1
# asm 2: vpand <out36=%ymm0,<_2p30m1x4=%ymm6,<out36=%ymm0
vpand %ymm0,%ymm6,%ymm0

# qhasm: stack_FVGS34 = out37
# asm 1: vmovapd <out37=reg256#3,>stack_FVGS34=stack256#34
# asm 2: vmovapd <out37=%ymm2,>stack_FVGS34=1184(%rsp)
vmovapd %ymm2,1184(%rsp)

# qhasm: z = stack_FVGS34[1]
# asm 1: movq <stack_FVGS34=stack256#34,>z=int64#1
# asm 2: movq <stack_FVGS34=1192(%rsp),>z=%rdi
movq 1192(%rsp),%rdi

# qhasm: (int64) z >>= 63
# asm 1: sar  $63,<z=int64#1
# asm 2: sar  $63,<z=%rdi
sar  $63,%rdi

# qhasm: stack_FVGS33 = out36
# asm 1: vmovapd <out36=reg256#1,>stack_FVGS33=stack256#35
# asm 2: vmovapd <out36=%ymm0,>stack_FVGS33=1216(%rsp)
vmovapd %ymm0,1216(%rsp)

# qhasm: table = stack_out
# asm 1: movq <stack_out=stack64#1,>table=int64#2
# asm 2: movq <stack_out=0(%rsp),>table=%rsi
movq 0(%rsp),%rsi

# qhasm: a0 = stack_FVGS0[1]
# asm 1: movq <stack_FVGS0=stack256#1,>a0=int64#3
# asm 2: movq <stack_FVGS0=136(%rsp),>a0=%rdx
movq 136(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod0[0]
# asm 1: andq <stack_mod0=stack256#37,<h=int64#4
# asm 2: andq <stack_mod0=1280(%rsp),<h=%rcx
andq 1280(%rsp),%rcx

# qhasm: a0 += h
# asm 1: add  <h=int64#4,<a0=int64#3
# asm 2: add  <h=%rcx,<a0=%rdx
add  %rcx,%rdx

# qhasm: t1 = stack_FVGS1[1]
# asm 1: movq <stack_FVGS1=stack256#2,>t1=int64#4
# asm 2: movq <stack_FVGS1=168(%rsp),>t1=%rcx
movq 168(%rsp),%rcx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod1[0]
# asm 1: andq <stack_mod1=stack256#38,<h=int64#5
# asm 2: andq <stack_mod1=1312(%rsp),<h=%r8
andq 1312(%rsp),%r8

# qhasm: t1 += h
# asm 1: add  <h=int64#5,<t1=int64#4
# asm 2: add  <h=%r8,<t1=%rcx
add  %r8,%rcx

# qhasm: t1 <<= 30
# asm 1: shl  $30,<t1=int64#4
# asm 2: shl  $30,<t1=%rcx
shl  $30,%rcx

# qhasm: a0 += t1
# asm 1: add  <t1=int64#4,<a0=int64#3
# asm 2: add  <t1=%rcx,<a0=%rdx
add  %rcx,%rdx

# qhasm: t2 = stack_FVGS2[1]
# asm 1: movq <stack_FVGS2=stack256#3,>t2=int64#4
# asm 2: movq <stack_FVGS2=200(%rsp),>t2=%rcx
movq 200(%rsp),%rcx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod2[0]
# asm 1: andq <stack_mod2=stack256#39,<h=int64#5
# asm 2: andq <stack_mod2=1344(%rsp),<h=%r8
andq 1344(%rsp),%r8

# qhasm: t2 += h
# asm 1: add  <h=int64#5,<t2=int64#4
# asm 2: add  <h=%r8,<t2=%rcx
add  %r8,%rcx

# qhasm: a1 = t2
# asm 1: mov  <t2=int64#4,>a1=int64#5
# asm 2: mov  <t2=%rcx,>a1=%r8
mov  %rcx,%r8

# qhasm: t2 <<= 60
# asm 1: shl  $60,<t2=int64#4
# asm 2: shl  $60,<t2=%rcx
shl  $60,%rcx

# qhasm: (int64) a1 >>= 4
# asm 1: sar  $4,<a1=int64#5
# asm 2: sar  $4,<a1=%r8
sar  $4,%r8

# qhasm: carry? a0 += t2
# asm 1: add  <t2=int64#4,<a0=int64#3
# asm 2: add  <t2=%rcx,<a0=%rdx
add  %rcx,%rdx

# qhasm: a1 += 0 + carry
# asm 1: adc $0,<a1=int64#5
# asm 2: adc $0,<a1=%r8
adc $0,%r8

# qhasm: mem64[table +  0] = a0
# asm 1: movq   <a0=int64#3,0(<table=int64#2)
# asm 2: movq   <a0=%rdx,0(<table=%rsi)
movq   %rdx,0(%rsi)

# qhasm: t3 = stack_FVGS3[1]
# asm 1: movq <stack_FVGS3=stack256#4,>t3=int64#3
# asm 2: movq <stack_FVGS3=232(%rsp),>t3=%rdx
movq 232(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod3[0]
# asm 1: andq <stack_mod3=stack256#40,<h=int64#4
# asm 2: andq <stack_mod3=1376(%rsp),<h=%rcx
andq 1376(%rsp),%rcx

# qhasm: t3 += h
# asm 1: add  <h=int64#4,<t3=int64#3
# asm 2: add  <h=%rcx,<t3=%rdx
add  %rcx,%rdx

# qhasm: t3 <<= 26
# asm 1: shl  $26,<t3=int64#3
# asm 2: shl  $26,<t3=%rdx
shl  $26,%rdx

# qhasm: a1 += t3
# asm 1: add  <t3=int64#3,<a1=int64#5
# asm 2: add  <t3=%rdx,<a1=%r8
add  %rdx,%r8

# qhasm: t4 = stack_FVGS4[1]
# asm 1: movq <stack_FVGS4=stack256#5,>t4=int64#3
# asm 2: movq <stack_FVGS4=264(%rsp),>t4=%rdx
movq 264(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod4[0]
# asm 1: andq <stack_mod4=stack256#41,<h=int64#4
# asm 2: andq <stack_mod4=1408(%rsp),<h=%rcx
andq 1408(%rsp),%rcx

# qhasm: t4 += h
# asm 1: add  <h=int64#4,<t4=int64#3
# asm 2: add  <h=%rcx,<t4=%rdx
add  %rcx,%rdx

# qhasm: a2 = t4
# asm 1: mov  <t4=int64#3,>a2=int64#4
# asm 2: mov  <t4=%rdx,>a2=%rcx
mov  %rdx,%rcx

# qhasm: t4 <<= 56
# asm 1: shl  $56,<t4=int64#3
# asm 2: shl  $56,<t4=%rdx
shl  $56,%rdx

# qhasm: (int64) a2 >>= 8
# asm 1: sar  $8,<a2=int64#4
# asm 2: sar  $8,<a2=%rcx
sar  $8,%rcx

# qhasm: carry? a1 += t4
# asm 1: add  <t4=int64#3,<a1=int64#5
# asm 2: add  <t4=%rdx,<a1=%r8
add  %rdx,%r8

# qhasm: a2 += 0 + carry
# asm 1: adc $0,<a2=int64#4
# asm 2: adc $0,<a2=%rcx
adc $0,%rcx

# qhasm: mem64[table +  8] = a1
# asm 1: movq   <a1=int64#5,8(<table=int64#2)
# asm 2: movq   <a1=%r8,8(<table=%rsi)
movq   %r8,8(%rsi)

# qhasm: t5 = stack_FVGS5[1]
# asm 1: movq <stack_FVGS5=stack256#6,>t5=int64#3
# asm 2: movq <stack_FVGS5=296(%rsp),>t5=%rdx
movq 296(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod5[0]
# asm 1: andq <stack_mod5=stack256#42,<h=int64#5
# asm 2: andq <stack_mod5=1440(%rsp),<h=%r8
andq 1440(%rsp),%r8

# qhasm: t5 += h
# asm 1: add  <h=int64#5,<t5=int64#3
# asm 2: add  <h=%r8,<t5=%rdx
add  %r8,%rdx

# qhasm: t5 <<= 22
# asm 1: shl  $22,<t5=int64#3
# asm 2: shl  $22,<t5=%rdx
shl  $22,%rdx

# qhasm: a2 += t5
# asm 1: add  <t5=int64#3,<a2=int64#4
# asm 2: add  <t5=%rdx,<a2=%rcx
add  %rdx,%rcx

# qhasm: t6 = stack_FVGS6[1]
# asm 1: movq <stack_FVGS6=stack256#7,>t6=int64#3
# asm 2: movq <stack_FVGS6=328(%rsp),>t6=%rdx
movq 328(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod6[0]
# asm 1: andq <stack_mod6=stack256#43,<h=int64#5
# asm 2: andq <stack_mod6=1472(%rsp),<h=%r8
andq 1472(%rsp),%r8

# qhasm: t6 += h
# asm 1: add  <h=int64#5,<t6=int64#3
# asm 2: add  <h=%r8,<t6=%rdx
add  %r8,%rdx

# qhasm: a3 = t6
# asm 1: mov  <t6=int64#3,>a3=int64#5
# asm 2: mov  <t6=%rdx,>a3=%r8
mov  %rdx,%r8

# qhasm: t6 <<= 52
# asm 1: shl  $52,<t6=int64#3
# asm 2: shl  $52,<t6=%rdx
shl  $52,%rdx

# qhasm: (int64) a3 >>= 12
# asm 1: sar  $12,<a3=int64#5
# asm 2: sar  $12,<a3=%r8
sar  $12,%r8

# qhasm: carry? a2 += t6
# asm 1: add  <t6=int64#3,<a2=int64#4
# asm 2: add  <t6=%rdx,<a2=%rcx
add  %rdx,%rcx

# qhasm: a3 += 0 + carry
# asm 1: adc $0,<a3=int64#5
# asm 2: adc $0,<a3=%r8
adc $0,%r8

# qhasm: mem64[table + 16] = a2
# asm 1: movq   <a2=int64#4,16(<table=int64#2)
# asm 2: movq   <a2=%rcx,16(<table=%rsi)
movq   %rcx,16(%rsi)

# qhasm: t7 = stack_FVGS7[1]
# asm 1: movq <stack_FVGS7=stack256#8,>t7=int64#3
# asm 2: movq <stack_FVGS7=360(%rsp),>t7=%rdx
movq 360(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod7[0]
# asm 1: andq <stack_mod7=stack256#44,<h=int64#4
# asm 2: andq <stack_mod7=1504(%rsp),<h=%rcx
andq 1504(%rsp),%rcx

# qhasm: t7 += h
# asm 1: add  <h=int64#4,<t7=int64#3
# asm 2: add  <h=%rcx,<t7=%rdx
add  %rcx,%rdx

# qhasm: t7 <<= 18
# asm 1: shl  $18,<t7=int64#3
# asm 2: shl  $18,<t7=%rdx
shl  $18,%rdx

# qhasm: a3 += t7
# asm 1: add  <t7=int64#3,<a3=int64#5
# asm 2: add  <t7=%rdx,<a3=%r8
add  %rdx,%r8

# qhasm: t8 = stack_FVGS8[1]
# asm 1: movq <stack_FVGS8=stack256#9,>t8=int64#3
# asm 2: movq <stack_FVGS8=392(%rsp),>t8=%rdx
movq 392(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod8[0]
# asm 1: andq <stack_mod8=stack256#45,<h=int64#4
# asm 2: andq <stack_mod8=1536(%rsp),<h=%rcx
andq 1536(%rsp),%rcx

# qhasm: t8 += h
# asm 1: add  <h=int64#4,<t8=int64#3
# asm 2: add  <h=%rcx,<t8=%rdx
add  %rcx,%rdx

# qhasm: a4 = t8
# asm 1: mov  <t8=int64#3,>a4=int64#4
# asm 2: mov  <t8=%rdx,>a4=%rcx
mov  %rdx,%rcx

# qhasm: t8 <<= 48
# asm 1: shl  $48,<t8=int64#3
# asm 2: shl  $48,<t8=%rdx
shl  $48,%rdx

# qhasm: (int64) a4 >>= 16
# asm 1: sar  $16,<a4=int64#4
# asm 2: sar  $16,<a4=%rcx
sar  $16,%rcx

# qhasm: carry? a3 += t8
# asm 1: add  <t8=int64#3,<a3=int64#5
# asm 2: add  <t8=%rdx,<a3=%r8
add  %rdx,%r8

# qhasm: a4 += 0 + carry
# asm 1: adc $0,<a4=int64#4
# asm 2: adc $0,<a4=%rcx
adc $0,%rcx

# qhasm: mem64[table + 24] = a3
# asm 1: movq   <a3=int64#5,24(<table=int64#2)
# asm 2: movq   <a3=%r8,24(<table=%rsi)
movq   %r8,24(%rsi)

# qhasm: t9 = stack_FVGS9[1]
# asm 1: movq <stack_FVGS9=stack256#10,>t9=int64#3
# asm 2: movq <stack_FVGS9=424(%rsp),>t9=%rdx
movq 424(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod9[0]
# asm 1: andq <stack_mod9=stack256#46,<h=int64#5
# asm 2: andq <stack_mod9=1568(%rsp),<h=%r8
andq 1568(%rsp),%r8

# qhasm: t9 += h
# asm 1: add  <h=int64#5,<t9=int64#3
# asm 2: add  <h=%r8,<t9=%rdx
add  %r8,%rdx

# qhasm: t9 <<= 14
# asm 1: shl  $14,<t9=int64#3
# asm 2: shl  $14,<t9=%rdx
shl  $14,%rdx

# qhasm: a4 += t9
# asm 1: add  <t9=int64#3,<a4=int64#4
# asm 2: add  <t9=%rdx,<a4=%rcx
add  %rdx,%rcx

# qhasm: t10 = stack_FVGS10[1]
# asm 1: movq <stack_FVGS10=stack256#11,>t10=int64#3
# asm 2: movq <stack_FVGS10=456(%rsp),>t10=%rdx
movq 456(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod10[0]
# asm 1: andq <stack_mod10=stack256#47,<h=int64#5
# asm 2: andq <stack_mod10=1600(%rsp),<h=%r8
andq 1600(%rsp),%r8

# qhasm: t10 += h
# asm 1: add  <h=int64#5,<t10=int64#3
# asm 2: add  <h=%r8,<t10=%rdx
add  %r8,%rdx

# qhasm: a5 = t10
# asm 1: mov  <t10=int64#3,>a5=int64#5
# asm 2: mov  <t10=%rdx,>a5=%r8
mov  %rdx,%r8

# qhasm: t10 <<= 44
# asm 1: shl  $44,<t10=int64#3
# asm 2: shl  $44,<t10=%rdx
shl  $44,%rdx

# qhasm: (int64) a5 >>= 20
# asm 1: sar  $20,<a5=int64#5
# asm 2: sar  $20,<a5=%r8
sar  $20,%r8

# qhasm: carry? a4 += t10
# asm 1: add  <t10=int64#3,<a4=int64#4
# asm 2: add  <t10=%rdx,<a4=%rcx
add  %rdx,%rcx

# qhasm: a5 += 0 + carry
# asm 1: adc $0,<a5=int64#5
# asm 2: adc $0,<a5=%r8
adc $0,%r8

# qhasm: mem64[table + 32] = a4
# asm 1: movq   <a4=int64#4,32(<table=int64#2)
# asm 2: movq   <a4=%rcx,32(<table=%rsi)
movq   %rcx,32(%rsi)

# qhasm: t11 = stack_FVGS11[1]
# asm 1: movq <stack_FVGS11=stack256#12,>t11=int64#3
# asm 2: movq <stack_FVGS11=488(%rsp),>t11=%rdx
movq 488(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod11[0]
# asm 1: andq <stack_mod11=stack256#48,<h=int64#4
# asm 2: andq <stack_mod11=1632(%rsp),<h=%rcx
andq 1632(%rsp),%rcx

# qhasm: t11 += h
# asm 1: add  <h=int64#4,<t11=int64#3
# asm 2: add  <h=%rcx,<t11=%rdx
add  %rcx,%rdx

# qhasm: t11 <<= 10
# asm 1: shl  $10,<t11=int64#3
# asm 2: shl  $10,<t11=%rdx
shl  $10,%rdx

# qhasm: a5 += t11
# asm 1: add  <t11=int64#3,<a5=int64#5
# asm 2: add  <t11=%rdx,<a5=%r8
add  %rdx,%r8

# qhasm: t12 = stack_FVGS12[1]
# asm 1: movq <stack_FVGS12=stack256#13,>t12=int64#3
# asm 2: movq <stack_FVGS12=520(%rsp),>t12=%rdx
movq 520(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod12[0]
# asm 1: andq <stack_mod12=stack256#49,<h=int64#4
# asm 2: andq <stack_mod12=1664(%rsp),<h=%rcx
andq 1664(%rsp),%rcx

# qhasm: t12 += h
# asm 1: add  <h=int64#4,<t12=int64#3
# asm 2: add  <h=%rcx,<t12=%rdx
add  %rcx,%rdx

# qhasm: a6 = t12
# asm 1: mov  <t12=int64#3,>a6=int64#4
# asm 2: mov  <t12=%rdx,>a6=%rcx
mov  %rdx,%rcx

# qhasm: t12 <<= 40
# asm 1: shl  $40,<t12=int64#3
# asm 2: shl  $40,<t12=%rdx
shl  $40,%rdx

# qhasm: (int64) a6 >>= 24
# asm 1: sar  $24,<a6=int64#4
# asm 2: sar  $24,<a6=%rcx
sar  $24,%rcx

# qhasm: carry? a5 += t12
# asm 1: add  <t12=int64#3,<a5=int64#5
# asm 2: add  <t12=%rdx,<a5=%r8
add  %rdx,%r8

# qhasm: a6 += 0 + carry
# asm 1: adc $0,<a6=int64#4
# asm 2: adc $0,<a6=%rcx
adc $0,%rcx

# qhasm: mem64[table + 40] = a5
# asm 1: movq   <a5=int64#5,40(<table=int64#2)
# asm 2: movq   <a5=%r8,40(<table=%rsi)
movq   %r8,40(%rsi)

# qhasm: t13 = stack_FVGS13[1]
# asm 1: movq <stack_FVGS13=stack256#14,>t13=int64#3
# asm 2: movq <stack_FVGS13=552(%rsp),>t13=%rdx
movq 552(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod13[0]
# asm 1: andq <stack_mod13=stack256#50,<h=int64#5
# asm 2: andq <stack_mod13=1696(%rsp),<h=%r8
andq 1696(%rsp),%r8

# qhasm: t13 += h
# asm 1: add  <h=int64#5,<t13=int64#3
# asm 2: add  <h=%r8,<t13=%rdx
add  %r8,%rdx

# qhasm: t13 <<= 6
# asm 1: shl  $6,<t13=int64#3
# asm 2: shl  $6,<t13=%rdx
shl  $6,%rdx

# qhasm: a6 += t13
# asm 1: add  <t13=int64#3,<a6=int64#4
# asm 2: add  <t13=%rdx,<a6=%rcx
add  %rdx,%rcx

# qhasm: t14 = stack_FVGS14[1]
# asm 1: movq <stack_FVGS14=stack256#15,>t14=int64#3
# asm 2: movq <stack_FVGS14=584(%rsp),>t14=%rdx
movq 584(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod14[0]
# asm 1: andq <stack_mod14=stack256#51,<h=int64#5
# asm 2: andq <stack_mod14=1728(%rsp),<h=%r8
andq 1728(%rsp),%r8

# qhasm: t14 += h
# asm 1: add  <h=int64#5,<t14=int64#3
# asm 2: add  <h=%r8,<t14=%rdx
add  %r8,%rdx

# qhasm: a7 = t14
# asm 1: mov  <t14=int64#3,>a7=int64#5
# asm 2: mov  <t14=%rdx,>a7=%r8
mov  %rdx,%r8

# qhasm: t14 <<= 36
# asm 1: shl  $36,<t14=int64#3
# asm 2: shl  $36,<t14=%rdx
shl  $36,%rdx

# qhasm: (int64) a7 >>= 28
# asm 1: sar  $28,<a7=int64#5
# asm 2: sar  $28,<a7=%r8
sar  $28,%r8

# qhasm: carry? a6 += t14
# asm 1: add  <t14=int64#3,<a6=int64#4
# asm 2: add  <t14=%rdx,<a6=%rcx
add  %rdx,%rcx

# qhasm: a7 += 0 + carry
# asm 1: adc $0,<a7=int64#5
# asm 2: adc $0,<a7=%r8
adc $0,%r8

# qhasm: mem64[table + 48] = a6
# asm 1: movq   <a6=int64#4,48(<table=int64#2)
# asm 2: movq   <a6=%rcx,48(<table=%rsi)
movq   %rcx,48(%rsi)

# qhasm: t15 = stack_FVGS15[1]
# asm 1: movq <stack_FVGS15=stack256#16,>t15=int64#3
# asm 2: movq <stack_FVGS15=616(%rsp),>t15=%rdx
movq 616(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod15[0]
# asm 1: andq <stack_mod15=stack256#52,<h=int64#4
# asm 2: andq <stack_mod15=1760(%rsp),<h=%rcx
andq 1760(%rsp),%rcx

# qhasm: t15 += h
# asm 1: add  <h=int64#4,<t15=int64#3
# asm 2: add  <h=%rcx,<t15=%rdx
add  %rcx,%rdx

# qhasm: t15 <<= 2
# asm 1: shl  $2,<t15=int64#3
# asm 2: shl  $2,<t15=%rdx
shl  $2,%rdx

# qhasm: a7 += t15
# asm 1: add  <t15=int64#3,<a7=int64#5
# asm 2: add  <t15=%rdx,<a7=%r8
add  %rdx,%r8

# qhasm: t16 = stack_FVGS16[1]
# asm 1: movq <stack_FVGS16=stack256#17,>t16=int64#3
# asm 2: movq <stack_FVGS16=648(%rsp),>t16=%rdx
movq 648(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod16[0]
# asm 1: andq <stack_mod16=stack256#53,<h=int64#4
# asm 2: andq <stack_mod16=1792(%rsp),<h=%rcx
andq 1792(%rsp),%rcx

# qhasm: t16 += h
# asm 1: add  <h=int64#4,<t16=int64#3
# asm 2: add  <h=%rcx,<t16=%rdx
add  %rcx,%rdx

# qhasm: t16 <<= 32
# asm 1: shl  $32,<t16=int64#3
# asm 2: shl  $32,<t16=%rdx
shl  $32,%rdx

# qhasm: a7 += t16
# asm 1: add  <t16=int64#3,<a7=int64#5
# asm 2: add  <t16=%rdx,<a7=%r8
add  %rdx,%r8

# qhasm: t17 = stack_FVGS17[1]
# asm 1: movq <stack_FVGS17=stack256#18,>t17=int64#3
# asm 2: movq <stack_FVGS17=680(%rsp),>t17=%rdx
movq 680(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod17[0]
# asm 1: andq <stack_mod17=stack256#54,<h=int64#4
# asm 2: andq <stack_mod17=1824(%rsp),<h=%rcx
andq 1824(%rsp),%rcx

# qhasm: t17 += h
# asm 1: add  <h=int64#4,<t17=int64#3
# asm 2: add  <h=%rcx,<t17=%rdx
add  %rcx,%rdx

# qhasm: a8 = t17
# asm 1: mov  <t17=int64#3,>a8=int64#4
# asm 2: mov  <t17=%rdx,>a8=%rcx
mov  %rdx,%rcx

# qhasm: t17 <<= 62
# asm 1: shl  $62,<t17=int64#3
# asm 2: shl  $62,<t17=%rdx
shl  $62,%rdx

# qhasm: (int64) a8 >>= 2
# asm 1: sar  $2,<a8=int64#4
# asm 2: sar  $2,<a8=%rcx
sar  $2,%rcx

# qhasm: carry? a7 += t17
# asm 1: add  <t17=int64#3,<a7=int64#5
# asm 2: add  <t17=%rdx,<a7=%r8
add  %rdx,%r8

# qhasm: a8 += 0 + carry
# asm 1: adc $0,<a8=int64#4
# asm 2: adc $0,<a8=%rcx
adc $0,%rcx

# qhasm: mem64[table + 56] = a7
# asm 1: movq   <a7=int64#5,56(<table=int64#2)
# asm 2: movq   <a7=%r8,56(<table=%rsi)
movq   %r8,56(%rsi)

# qhasm: t18 = stack_FVGS18[1]
# asm 1: movq <stack_FVGS18=stack256#19,>t18=int64#3
# asm 2: movq <stack_FVGS18=712(%rsp),>t18=%rdx
movq 712(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod18[0]
# asm 1: andq <stack_mod18=stack256#55,<h=int64#5
# asm 2: andq <stack_mod18=1856(%rsp),<h=%r8
andq 1856(%rsp),%r8

# qhasm: t18 += h
# asm 1: add  <h=int64#5,<t18=int64#3
# asm 2: add  <h=%r8,<t18=%rdx
add  %r8,%rdx

# qhasm: t18 <<= 28
# asm 1: shl  $28,<t18=int64#3
# asm 2: shl  $28,<t18=%rdx
shl  $28,%rdx

# qhasm: a8 += t18
# asm 1: add  <t18=int64#3,<a8=int64#4
# asm 2: add  <t18=%rdx,<a8=%rcx
add  %rdx,%rcx

# qhasm: t19 = stack_FVGS19[1]
# asm 1: movq <stack_FVGS19=stack256#20,>t19=int64#3
# asm 2: movq <stack_FVGS19=744(%rsp),>t19=%rdx
movq 744(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod19[0]
# asm 1: andq <stack_mod19=stack256#56,<h=int64#5
# asm 2: andq <stack_mod19=1888(%rsp),<h=%r8
andq 1888(%rsp),%r8

# qhasm: t19 += h
# asm 1: add  <h=int64#5,<t19=int64#3
# asm 2: add  <h=%r8,<t19=%rdx
add  %r8,%rdx

# qhasm: a9 = t19
# asm 1: mov  <t19=int64#3,>a9=int64#5
# asm 2: mov  <t19=%rdx,>a9=%r8
mov  %rdx,%r8

# qhasm: t19 <<= 58
# asm 1: shl  $58,<t19=int64#3
# asm 2: shl  $58,<t19=%rdx
shl  $58,%rdx

# qhasm: (int64) a9 >>= 6
# asm 1: sar  $6,<a9=int64#5
# asm 2: sar  $6,<a9=%r8
sar  $6,%r8

# qhasm: carry? a8 += t19
# asm 1: add  <t19=int64#3,<a8=int64#4
# asm 2: add  <t19=%rdx,<a8=%rcx
add  %rdx,%rcx

# qhasm: a9 += 0 + carry
# asm 1: adc $0,<a9=int64#5
# asm 2: adc $0,<a9=%r8
adc $0,%r8

# qhasm: mem64[table + 64] = a8
# asm 1: movq   <a8=int64#4,64(<table=int64#2)
# asm 2: movq   <a8=%rcx,64(<table=%rsi)
movq   %rcx,64(%rsi)

# qhasm: t20 = stack_FVGS20[1]
# asm 1: movq <stack_FVGS20=stack256#21,>t20=int64#3
# asm 2: movq <stack_FVGS20=776(%rsp),>t20=%rdx
movq 776(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod20[0]
# asm 1: andq <stack_mod20=stack256#57,<h=int64#4
# asm 2: andq <stack_mod20=1920(%rsp),<h=%rcx
andq 1920(%rsp),%rcx

# qhasm: t20 += h
# asm 1: add  <h=int64#4,<t20=int64#3
# asm 2: add  <h=%rcx,<t20=%rdx
add  %rcx,%rdx

# qhasm: t20 <<= 24
# asm 1: shl  $24,<t20=int64#3
# asm 2: shl  $24,<t20=%rdx
shl  $24,%rdx

# qhasm: a9 += t20
# asm 1: add  <t20=int64#3,<a9=int64#5
# asm 2: add  <t20=%rdx,<a9=%r8
add  %rdx,%r8

# qhasm: t21 = stack_FVGS21[1]
# asm 1: movq <stack_FVGS21=stack256#22,>t21=int64#3
# asm 2: movq <stack_FVGS21=808(%rsp),>t21=%rdx
movq 808(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod21[0]
# asm 1: andq <stack_mod21=stack256#58,<h=int64#4
# asm 2: andq <stack_mod21=1952(%rsp),<h=%rcx
andq 1952(%rsp),%rcx

# qhasm: t21 += h
# asm 1: add  <h=int64#4,<t21=int64#3
# asm 2: add  <h=%rcx,<t21=%rdx
add  %rcx,%rdx

# qhasm: a10 = t21
# asm 1: mov  <t21=int64#3,>a10=int64#4
# asm 2: mov  <t21=%rdx,>a10=%rcx
mov  %rdx,%rcx

# qhasm: t21 <<= 54
# asm 1: shl  $54,<t21=int64#3
# asm 2: shl  $54,<t21=%rdx
shl  $54,%rdx

# qhasm: (int64) a10 >>= 10
# asm 1: sar  $10,<a10=int64#4
# asm 2: sar  $10,<a10=%rcx
sar  $10,%rcx

# qhasm: carry? a9 += t21
# asm 1: add  <t21=int64#3,<a9=int64#5
# asm 2: add  <t21=%rdx,<a9=%r8
add  %rdx,%r8

# qhasm: a10 += 0 + carry
# asm 1: adc $0,<a10=int64#4
# asm 2: adc $0,<a10=%rcx
adc $0,%rcx

# qhasm: mem64[table + 72] = a9
# asm 1: movq   <a9=int64#5,72(<table=int64#2)
# asm 2: movq   <a9=%r8,72(<table=%rsi)
movq   %r8,72(%rsi)

# qhasm: t22 = stack_FVGS22[1]
# asm 1: movq <stack_FVGS22=stack256#23,>t22=int64#3
# asm 2: movq <stack_FVGS22=840(%rsp),>t22=%rdx
movq 840(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod22[0]
# asm 1: andq <stack_mod22=stack256#59,<h=int64#5
# asm 2: andq <stack_mod22=1984(%rsp),<h=%r8
andq 1984(%rsp),%r8

# qhasm: t22 += h
# asm 1: add  <h=int64#5,<t22=int64#3
# asm 2: add  <h=%r8,<t22=%rdx
add  %r8,%rdx

# qhasm: t22 <<= 20
# asm 1: shl  $20,<t22=int64#3
# asm 2: shl  $20,<t22=%rdx
shl  $20,%rdx

# qhasm: a10 += t22
# asm 1: add  <t22=int64#3,<a10=int64#4
# asm 2: add  <t22=%rdx,<a10=%rcx
add  %rdx,%rcx

# qhasm: t23 = stack_FVGS23[1]
# asm 1: movq <stack_FVGS23=stack256#24,>t23=int64#3
# asm 2: movq <stack_FVGS23=872(%rsp),>t23=%rdx
movq 872(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod23[0]
# asm 1: andq <stack_mod23=stack256#60,<h=int64#5
# asm 2: andq <stack_mod23=2016(%rsp),<h=%r8
andq 2016(%rsp),%r8

# qhasm: t23 += h
# asm 1: add  <h=int64#5,<t23=int64#3
# asm 2: add  <h=%r8,<t23=%rdx
add  %r8,%rdx

# qhasm: a11 = t23
# asm 1: mov  <t23=int64#3,>a11=int64#5
# asm 2: mov  <t23=%rdx,>a11=%r8
mov  %rdx,%r8

# qhasm: t23 <<= 50
# asm 1: shl  $50,<t23=int64#3
# asm 2: shl  $50,<t23=%rdx
shl  $50,%rdx

# qhasm: (int64) a11 >>= 14
# asm 1: sar  $14,<a11=int64#5
# asm 2: sar  $14,<a11=%r8
sar  $14,%r8

# qhasm: carry? a10 += t23
# asm 1: add  <t23=int64#3,<a10=int64#4
# asm 2: add  <t23=%rdx,<a10=%rcx
add  %rdx,%rcx

# qhasm: a11 += 0 + carry
# asm 1: adc $0,<a11=int64#5
# asm 2: adc $0,<a11=%r8
adc $0,%r8

# qhasm: mem64[table + 80] = a10
# asm 1: movq   <a10=int64#4,80(<table=int64#2)
# asm 2: movq   <a10=%rcx,80(<table=%rsi)
movq   %rcx,80(%rsi)

# qhasm: t24 = stack_FVGS24[1]
# asm 1: movq <stack_FVGS24=stack256#25,>t24=int64#3
# asm 2: movq <stack_FVGS24=904(%rsp),>t24=%rdx
movq 904(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod24[0]
# asm 1: andq <stack_mod24=stack256#61,<h=int64#4
# asm 2: andq <stack_mod24=2048(%rsp),<h=%rcx
andq 2048(%rsp),%rcx

# qhasm: t24 += h
# asm 1: add  <h=int64#4,<t24=int64#3
# asm 2: add  <h=%rcx,<t24=%rdx
add  %rcx,%rdx

# qhasm: t24 <<= 16
# asm 1: shl  $16,<t24=int64#3
# asm 2: shl  $16,<t24=%rdx
shl  $16,%rdx

# qhasm: a11 += t24
# asm 1: add  <t24=int64#3,<a11=int64#5
# asm 2: add  <t24=%rdx,<a11=%r8
add  %rdx,%r8

# qhasm: t25 = stack_FVGS25[1]
# asm 1: movq <stack_FVGS25=stack256#26,>t25=int64#3
# asm 2: movq <stack_FVGS25=936(%rsp),>t25=%rdx
movq 936(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod25[0]
# asm 1: andq <stack_mod25=stack256#62,<h=int64#4
# asm 2: andq <stack_mod25=2080(%rsp),<h=%rcx
andq 2080(%rsp),%rcx

# qhasm: t25 += h
# asm 1: add  <h=int64#4,<t25=int64#3
# asm 2: add  <h=%rcx,<t25=%rdx
add  %rcx,%rdx

# qhasm: a12 = t25
# asm 1: mov  <t25=int64#3,>a12=int64#4
# asm 2: mov  <t25=%rdx,>a12=%rcx
mov  %rdx,%rcx

# qhasm: t25 <<= 46
# asm 1: shl  $46,<t25=int64#3
# asm 2: shl  $46,<t25=%rdx
shl  $46,%rdx

# qhasm: (int64) a12 >>= 18
# asm 1: sar  $18,<a12=int64#4
# asm 2: sar  $18,<a12=%rcx
sar  $18,%rcx

# qhasm: carry? a11 += t25
# asm 1: add  <t25=int64#3,<a11=int64#5
# asm 2: add  <t25=%rdx,<a11=%r8
add  %rdx,%r8

# qhasm: a12 += 0 + carry
# asm 1: adc $0,<a12=int64#4
# asm 2: adc $0,<a12=%rcx
adc $0,%rcx

# qhasm: mem64[table + 88] = a11
# asm 1: movq   <a11=int64#5,88(<table=int64#2)
# asm 2: movq   <a11=%r8,88(<table=%rsi)
movq   %r8,88(%rsi)

# qhasm: t26 = stack_FVGS26[1]
# asm 1: movq <stack_FVGS26=stack256#27,>t26=int64#3
# asm 2: movq <stack_FVGS26=968(%rsp),>t26=%rdx
movq 968(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod26[0]
# asm 1: andq <stack_mod26=stack256#63,<h=int64#5
# asm 2: andq <stack_mod26=2112(%rsp),<h=%r8
andq 2112(%rsp),%r8

# qhasm: t26 += h
# asm 1: add  <h=int64#5,<t26=int64#3
# asm 2: add  <h=%r8,<t26=%rdx
add  %r8,%rdx

# qhasm: t26 <<= 12
# asm 1: shl  $12,<t26=int64#3
# asm 2: shl  $12,<t26=%rdx
shl  $12,%rdx

# qhasm: a12 += t26
# asm 1: add  <t26=int64#3,<a12=int64#4
# asm 2: add  <t26=%rdx,<a12=%rcx
add  %rdx,%rcx

# qhasm: t27 = stack_FVGS27[1]
# asm 1: movq <stack_FVGS27=stack256#28,>t27=int64#3
# asm 2: movq <stack_FVGS27=1000(%rsp),>t27=%rdx
movq 1000(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod27[0]
# asm 1: andq <stack_mod27=stack256#64,<h=int64#5
# asm 2: andq <stack_mod27=2144(%rsp),<h=%r8
andq 2144(%rsp),%r8

# qhasm: t27 += h
# asm 1: add  <h=int64#5,<t27=int64#3
# asm 2: add  <h=%r8,<t27=%rdx
add  %r8,%rdx

# qhasm: a13 = t27
# asm 1: mov  <t27=int64#3,>a13=int64#5
# asm 2: mov  <t27=%rdx,>a13=%r8
mov  %rdx,%r8

# qhasm: t27 <<= 42
# asm 1: shl  $42,<t27=int64#3
# asm 2: shl  $42,<t27=%rdx
shl  $42,%rdx

# qhasm: (int64) a13 >>= 22
# asm 1: sar  $22,<a13=int64#5
# asm 2: sar  $22,<a13=%r8
sar  $22,%r8

# qhasm: carry? a12 += t27
# asm 1: add  <t27=int64#3,<a12=int64#4
# asm 2: add  <t27=%rdx,<a12=%rcx
add  %rdx,%rcx

# qhasm: a13 += 0 + carry
# asm 1: adc $0,<a13=int64#5
# asm 2: adc $0,<a13=%r8
adc $0,%r8

# qhasm: mem64[table + 96] = a12
# asm 1: movq   <a12=int64#4,96(<table=int64#2)
# asm 2: movq   <a12=%rcx,96(<table=%rsi)
movq   %rcx,96(%rsi)

# qhasm: t28 = stack_FVGS28[1]
# asm 1: movq <stack_FVGS28=stack256#29,>t28=int64#3
# asm 2: movq <stack_FVGS28=1032(%rsp),>t28=%rdx
movq 1032(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod28[0]
# asm 1: andq <stack_mod28=stack256#65,<h=int64#4
# asm 2: andq <stack_mod28=2176(%rsp),<h=%rcx
andq 2176(%rsp),%rcx

# qhasm: t28 += h
# asm 1: add  <h=int64#4,<t28=int64#3
# asm 2: add  <h=%rcx,<t28=%rdx
add  %rcx,%rdx

# qhasm: t28 <<= 8
# asm 1: shl  $8,<t28=int64#3
# asm 2: shl  $8,<t28=%rdx
shl  $8,%rdx

# qhasm: a13 += t28
# asm 1: add  <t28=int64#3,<a13=int64#5
# asm 2: add  <t28=%rdx,<a13=%r8
add  %rdx,%r8

# qhasm: t29 = stack_FVGS29[1]
# asm 1: movq <stack_FVGS29=stack256#30,>t29=int64#3
# asm 2: movq <stack_FVGS29=1064(%rsp),>t29=%rdx
movq 1064(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod29[0]
# asm 1: andq <stack_mod29=stack256#66,<h=int64#4
# asm 2: andq <stack_mod29=2208(%rsp),<h=%rcx
andq 2208(%rsp),%rcx

# qhasm: t29 += h
# asm 1: add  <h=int64#4,<t29=int64#3
# asm 2: add  <h=%rcx,<t29=%rdx
add  %rcx,%rdx

# qhasm: a14 = t29
# asm 1: mov  <t29=int64#3,>a14=int64#4
# asm 2: mov  <t29=%rdx,>a14=%rcx
mov  %rdx,%rcx

# qhasm: t29 <<= 38
# asm 1: shl  $38,<t29=int64#3
# asm 2: shl  $38,<t29=%rdx
shl  $38,%rdx

# qhasm: (int64) a14 >>= 26
# asm 1: sar  $26,<a14=int64#4
# asm 2: sar  $26,<a14=%rcx
sar  $26,%rcx

# qhasm: carry? a13 += t29
# asm 1: add  <t29=int64#3,<a13=int64#5
# asm 2: add  <t29=%rdx,<a13=%r8
add  %rdx,%r8

# qhasm: a14 += 0 + carry
# asm 1: adc $0,<a14=int64#4
# asm 2: adc $0,<a14=%rcx
adc $0,%rcx

# qhasm: mem64[table + 104] = a13
# asm 1: movq   <a13=int64#5,104(<table=int64#2)
# asm 2: movq   <a13=%r8,104(<table=%rsi)
movq   %r8,104(%rsi)

# qhasm: t30 = stack_FVGS30[1]
# asm 1: movq <stack_FVGS30=stack256#31,>t30=int64#3
# asm 2: movq <stack_FVGS30=1096(%rsp),>t30=%rdx
movq 1096(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod30[0]
# asm 1: andq <stack_mod30=stack256#67,<h=int64#5
# asm 2: andq <stack_mod30=2240(%rsp),<h=%r8
andq 2240(%rsp),%r8

# qhasm: t30 += h
# asm 1: add  <h=int64#5,<t30=int64#3
# asm 2: add  <h=%r8,<t30=%rdx
add  %r8,%rdx

# qhasm: t30 <<= 4
# asm 1: shl  $4,<t30=int64#3
# asm 2: shl  $4,<t30=%rdx
shl  $4,%rdx

# qhasm: a14 += t30
# asm 1: add  <t30=int64#3,<a14=int64#4
# asm 2: add  <t30=%rdx,<a14=%rcx
add  %rdx,%rcx

# qhasm: t31 = stack_FVGS31[1]
# asm 1: movq <stack_FVGS31=stack256#32,>t31=int64#3
# asm 2: movq <stack_FVGS31=1128(%rsp),>t31=%rdx
movq 1128(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#5
# asm 2: mov  <z=%rdi,>h=%r8
mov  %rdi,%r8

# qhasm: h &= stack_mod31[0]
# asm 1: andq <stack_mod31=stack256#68,<h=int64#5
# asm 2: andq <stack_mod31=2272(%rsp),<h=%r8
andq 2272(%rsp),%r8

# qhasm: t31 += h
# asm 1: add  <h=int64#5,<t31=int64#3
# asm 2: add  <h=%r8,<t31=%rdx
add  %r8,%rdx

# qhasm: a15 = t31
# asm 1: mov  <t31=int64#3,>a15=int64#5
# asm 2: mov  <t31=%rdx,>a15=%r8
mov  %rdx,%r8

# qhasm: t31 <<= 34
# asm 1: shl  $34,<t31=int64#3
# asm 2: shl  $34,<t31=%rdx
shl  $34,%rdx

# qhasm: (int64) a15 >>= 30
# asm 1: sar  $30,<a15=int64#5
# asm 2: sar  $30,<a15=%r8
sar  $30,%r8

# qhasm: carry? a14 += t31
# asm 1: add  <t31=int64#3,<a14=int64#4
# asm 2: add  <t31=%rdx,<a14=%rcx
add  %rdx,%rcx

# qhasm: a15 += 0 + carry
# asm 1: adc $0,<a15=int64#5
# asm 2: adc $0,<a15=%r8
adc $0,%r8

# qhasm: mem64[table + 112] = a14
# asm 1: movq   <a14=int64#4,112(<table=int64#2)
# asm 2: movq   <a14=%rcx,112(<table=%rsi)
movq   %rcx,112(%rsi)

# qhasm: t32 = stack_FVGS32[1]
# asm 1: movq <stack_FVGS32=stack256#33,>t32=int64#3
# asm 2: movq <stack_FVGS32=1160(%rsp),>t32=%rdx
movq 1160(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod32[0]
# asm 1: andq <stack_mod32=stack256#69,<h=int64#4
# asm 2: andq <stack_mod32=2304(%rsp),<h=%rcx
andq 2304(%rsp),%rcx

# qhasm: t32 += h
# asm 1: add  <h=int64#4,<t32=int64#3
# asm 2: add  <h=%rcx,<t32=%rdx
add  %rcx,%rdx

# qhasm: a15 += t32
# asm 1: add  <t32=int64#3,<a15=int64#5
# asm 2: add  <t32=%rdx,<a15=%r8
add  %rdx,%r8

# qhasm: t33 = stack_FVGS33[1]
# asm 1: movq <stack_FVGS33=stack256#35,>t33=int64#3
# asm 2: movq <stack_FVGS33=1224(%rsp),>t33=%rdx
movq 1224(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#4
# asm 2: mov  <z=%rdi,>h=%rcx
mov  %rdi,%rcx

# qhasm: h &= stack_mod33[0]
# asm 1: andq <stack_mod33=stack256#70,<h=int64#4
# asm 2: andq <stack_mod33=2336(%rsp),<h=%rcx
andq 2336(%rsp),%rcx

# qhasm: t33 += h
# asm 1: add  <h=int64#4,<t33=int64#3
# asm 2: add  <h=%rcx,<t33=%rdx
add  %rcx,%rdx

# qhasm: t33 <<= 30
# asm 1: shl  $30,<t33=int64#3
# asm 2: shl  $30,<t33=%rdx
shl  $30,%rdx

# qhasm: a15 += t33
# asm 1: add  <t33=int64#3,<a15=int64#5
# asm 2: add  <t33=%rdx,<a15=%r8
add  %rdx,%r8

# qhasm: t34 = stack_FVGS34[1]
# asm 1: movq <stack_FVGS34=stack256#34,>t34=int64#3
# asm 2: movq <stack_FVGS34=1192(%rsp),>t34=%rdx
movq 1192(%rsp),%rdx

# qhasm: h = z
# asm 1: mov  <z=int64#1,>h=int64#1
# asm 2: mov  <z=%rdi,>h=%rdi
mov  %rdi,%rdi

# qhasm: h &= stack_mod34[0]
# asm 1: andq <stack_mod34=stack256#71,<h=int64#1
# asm 2: andq <stack_mod34=2368(%rsp),<h=%rdi
andq 2368(%rsp),%rdi

# qhasm: t34 += h
# asm 1: add  <h=int64#1,<t34=int64#3
# asm 2: add  <h=%rdi,<t34=%rdx
add  %rdi,%rdx

# qhasm: t34 <<= 60
# asm 1: shl  $60,<t34=int64#3
# asm 2: shl  $60,<t34=%rdx
shl  $60,%rdx

# qhasm: a15 += t34
# asm 1: add  <t34=int64#3,<a15=int64#5
# asm 2: add  <t34=%rdx,<a15=%r8
add  %rdx,%r8

# qhasm: mem64[table + 120] = a15
# asm 1: movq   <a15=int64#5,120(<table=int64#2)
# asm 2: movq   <a15=%r8,120(<table=%rsi)
movq   %r8,120(%rsi)

# qhasm: caller_r11 = stack_r11
# asm 1: movq <stack_r11=stack64#2,>caller_r11=int64#9
# asm 2: movq <stack_r11=8(%rsp),>caller_r11=%r11
movq 8(%rsp),%r11

# qhasm: caller_r12 = stack_r12
# asm 1: movq <stack_r12=stack64#3,>caller_r12=int64#10
# asm 2: movq <stack_r12=16(%rsp),>caller_r12=%r12
movq 16(%rsp),%r12

# qhasm: caller_r13 = stack_r13
# asm 1: movq <stack_r13=stack64#4,>caller_r13=int64#11
# asm 2: movq <stack_r13=24(%rsp),>caller_r13=%r13
movq 24(%rsp),%r13

# qhasm: caller_r14 = stack_r14
# asm 1: movq <stack_r14=stack64#5,>caller_r14=int64#12
# asm 2: movq <stack_r14=32(%rsp),>caller_r14=%r14
movq 32(%rsp),%r14

# qhasm: caller_r15 = stack_r15
# asm 1: movq <stack_r15=stack64#6,>caller_r15=int64#13
# asm 2: movq <stack_r15=40(%rsp),>caller_r15=%r15
movq 40(%rsp),%r15

# qhasm: caller_rbx = stack_rbx
# asm 1: movq <stack_rbx=stack64#7,>caller_rbx=int64#14
# asm 2: movq <stack_rbx=48(%rsp),>caller_rbx=%rbx
movq 48(%rsp),%rbx

# qhasm: caller_rbp = stack_rbp
# asm 1: movq <stack_rbp=stack64#8,>caller_rbp=int64#15
# asm 2: movq <stack_rbp=56(%rsp),>caller_rbp=%rbp
movq 56(%rsp),%rbp

# qhasm: return
add %r11,%rsp
ret
